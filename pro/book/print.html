<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>pro笔记</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">介绍</a></li><li class="chapter-item expanded "><a href="1. 基础知识/_index.html"><strong aria-hidden="true">1.</strong> 基础知识</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="1. 基础知识/1.1 正则表达式/_index.html"><strong aria-hidden="true">1.1.</strong> 正则表达式</a></li></ol></li><li class="chapter-item expanded "><a href="2. 网络/_index.html"><strong aria-hidden="true">2.</strong> 网络</a></li><li class="chapter-item expanded "><a href="3. 操作系统/_index.html"><strong aria-hidden="true">3.</strong> 操作系统</a></li><li class="chapter-item expanded "><a href="4. 数据结构/_index.html"><strong aria-hidden="true">4.</strong> 数据结构</a></li><li class="chapter-item expanded "><a href="5. 数据挖掘/_index.html"><strong aria-hidden="true">5.</strong> 数据挖掘</a></li><li class="chapter-item expanded "><a href="6. 软件架构/_index.html"><strong aria-hidden="true">6.</strong> 软件架构</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="6. 软件架构/6.1 SOA.html"><strong aria-hidden="true">6.1.</strong> 6.1 SOA</a></li><li class="chapter-item expanded "><a href="6. 软件架构/6.2 RESTful.html"><strong aria-hidden="true">6.2.</strong> 6.2 RESTful</a></li><li class="chapter-item expanded "><a href="6. 软件架构/6.3 架构.html"><strong aria-hidden="true">6.3.</strong> 6.3 架构</a></li><li class="chapter-item expanded "><a href="6. 软件架构/6.4 版本管理.html"><strong aria-hidden="true">6.4.</strong> 6.4 版本管理</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/_index.html"><strong aria-hidden="true">7.</strong> 项目</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/_index.html"><strong aria-hidden="true">7.1.</strong> Yaws</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.1 yaws.conf.html"><strong aria-hidden="true">7.1.1.</strong> 7.1.1 yaws.conf</a></li><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.2 API.html"><strong aria-hidden="true">7.1.2.</strong> 7.1.2 API</a></li><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.3 Session用法.html"><strong aria-hidden="true">7.1.3.</strong> 7.1.3 Session用法</a></li><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.4 页面传值.html"><strong aria-hidden="true">7.1.4.</strong> 7.1.4 页面传值</a></li><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.5 Ehtml.html"><strong aria-hidden="true">7.1.5.</strong> 7.1.5 Ehtml</a></li><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.6 SSIbindings.html"><strong aria-hidden="true">7.1.6.</strong> 7.1.6 SSIbindings</a></li><li class="chapter-item expanded "><a href="7. 项目/7.1 Yaws/7.1.7 Bug.html"><strong aria-hidden="true">7.1.7.</strong> 7.1.7 Bug</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/_index.html"><strong aria-hidden="true">7.2.</strong> Mnesia</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.1 操作.html"><strong aria-hidden="true">7.2.1.</strong> 7.10.1 操作</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.2 增删改查.html"><strong aria-hidden="true">7.2.2.</strong> 7.10.2 增删改查</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.3 表分片.html"><strong aria-hidden="true">7.2.3.</strong> 7.10.3 表分片</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.4 锁.html"><strong aria-hidden="true">7.2.4.</strong> 7.10.4 锁</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.5 分布式.html"><strong aria-hidden="true">7.2.5.</strong> 7.10.5 分布式</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.6 高级特性.html"><strong aria-hidden="true">7.2.6.</strong> 7.10.6 高级特性</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.7 ets.html"><strong aria-hidden="true">7.2.7.</strong> 7.10.7 ets</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.8 dets.html"><strong aria-hidden="true">7.2.8.</strong> 7.10.8 dets</a></li><li class="chapter-item expanded "><a href="7. 项目/7.10 Mnesia/7.10.9 过载分析.html"><strong aria-hidden="true">7.2.9.</strong> 7.10.9 过载分析</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.11 Riak/_index.html"><strong aria-hidden="true">7.3.</strong> Riak</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.11 Riak/7.11.1 代码片段/_index.html"><strong aria-hidden="true">7.3.1.</strong> 代码片段</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.11 Riak/7.11.1 代码片段/7.11.1.1 命令.html"><strong aria-hidden="true">7.3.1.1.</strong> 7.11.1.1 命令</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.11 Riak/7.11.2 配置/_index.html"><strong aria-hidden="true">7.3.2.</strong> 配置</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.11 Riak/7.11.2 配置/7.11.2.1 配置.html"><strong aria-hidden="true">7.3.2.1.</strong> 7.11.2.1 配置</a></li><li class="chapter-item expanded "><a href="7. 项目/7.11 Riak/7.11.3 异常情况/_index.html"><strong aria-hidden="true">7.3.2.2.</strong> 异常情况</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/_index.html"><strong aria-hidden="true">7.4.</strong> Mysql</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.1 SQL片段/_index.html"><strong aria-hidden="true">7.4.1.</strong> SQL片段</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.1 SQL片段/7.12.1.1关键字.html"><strong aria-hidden="true">7.4.1.1.</strong> 7.12.1.1关键字</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.1 SQL片段/7.12.1.2常用语句.html"><strong aria-hidden="true">7.4.1.2.</strong> 7.12.1.2常用语句</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.2 配置/_index.html"><strong aria-hidden="true">7.4.2.</strong> 配置</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.2 配置/7.12.2.1my.cnf.html"><strong aria-hidden="true">7.4.2.1.</strong> 7.12.2.1my.cnf</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.2 配置/7.12.2.2日志.html"><strong aria-hidden="true">7.4.2.2.</strong> 7.12.2.2日志</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.2 配置/7.12.2.3主从.html"><strong aria-hidden="true">7.4.2.3.</strong> 7.12.2.3主从</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.2 配置/7.12.2.4存储引擎.html"><strong aria-hidden="true">7.4.2.4.</strong> 7.12.2.4存储引擎</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.3安装.html"><strong aria-hidden="true">7.4.3.</strong> 7.12.3安装</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.5 msyqldump.html"><strong aria-hidden="true">7.4.4.</strong> 7.12.5 msyqldump</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.6 查询计划Explain.html"><strong aria-hidden="true">7.4.5.</strong> 7.12.6 查询计划Explain</a></li><li class="chapter-item expanded "><a href="7. 项目/7.12 Mysql/7.12.8 命令操作.html"><strong aria-hidden="true">7.4.6.</strong> 7.12.8 命令操作</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.13 SQLite/_index.html"><strong aria-hidden="true">7.5.</strong> SQLite</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.13 SQLite/7.13.1安装.html"><strong aria-hidden="true">7.5.1.</strong> 7.13.1安装</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/_index.html"><strong aria-hidden="true">7.6.</strong> PostgreSQL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.1 SQL片段/_index.html"><strong aria-hidden="true">7.6.1.</strong> SQL片段</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.1 SQL片段/7.14.1.1pg管理.html"><strong aria-hidden="true">7.6.1.1.</strong> 7.14.1.1pg管理</a></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.1 SQL片段/7.14.1.2create.html"><strong aria-hidden="true">7.6.1.2.</strong> 7.14.1.2create</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.2 配置/_index.html"><strong aria-hidden="true">7.6.2.</strong> 配置</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.2 配置/7.14.2.1 配置.html"><strong aria-hidden="true">7.6.2.1.</strong> 7.14.2.1 配置</a></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.2 配置/7.14.2.2自定义数据库路径.html"><strong aria-hidden="true">7.6.2.2.</strong> 7.14.2.2自定义数据库路径</a></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.2 配置/7.14.2.3时序数据库.html"><strong aria-hidden="true">7.6.2.3.</strong> 7.14.2.3时序数据库</a></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.2 配置/7.14.2.4外部表.html"><strong aria-hidden="true">7.6.2.4.</strong> 7.14.2.4外部表</a></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.2 配置/7.14.2.5pg_hba.conf.html"><strong aria-hidden="true">7.6.2.5.</strong> 7.14.2.5pg_hba.conf</a></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.4问题/7.14.4.1EXISTS IN.html"><strong aria-hidden="true">7.6.2.6.</strong> 7.14.4.1EXISTS IN</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.14 PostgreSQL/7.14.3postgresql安装.html"><strong aria-hidden="true">7.6.3.</strong> 7.14.3postgresql安装</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.15 elk/_index.html"><strong aria-hidden="true">7.7.</strong> elk</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.15 elk/install.html"><strong aria-hidden="true">7.7.1.</strong> Install</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.16 clickhouse/_index.html"><strong aria-hidden="true">7.8.</strong> clickhouse</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.16 clickhouse/http.html"><strong aria-hidden="true">7.8.1.</strong> Http</a></li><li class="chapter-item expanded "><a href="7. 项目/7.16 clickhouse/install.html"><strong aria-hidden="true">7.8.2.</strong> Install</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.17 hugo/_index.html"><strong aria-hidden="true">7.9.</strong> hugo</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.17 hugo/first-content.html"><strong aria-hidden="true">7.9.1.</strong> First Content</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.18 minio/_index.html"><strong aria-hidden="true">7.10.</strong> minio</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.18 minio/minio.html"><strong aria-hidden="true">7.10.1.</strong> Minio</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.2 Leofs/_index.html"><strong aria-hidden="true">7.11.</strong> Leofs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.2 Leofs/7.2.1 安装.html"><strong aria-hidden="true">7.11.1.</strong> 7.2.1 安装</a></li><li class="chapter-item expanded "><a href="7. 项目/7.2 Leofs/7.2.2 端口占用.html"><strong aria-hidden="true">7.11.2.</strong> 7.2.2 端口占用</a></li><li class="chapter-item expanded "><a href="7. 项目/7.2 Leofs/7.2.3 Shell命令.html"><strong aria-hidden="true">7.11.3.</strong> 7.2.3 Shell命令</a></li><li class="chapter-item expanded "><a href="7. 项目/7.2 Leofs/7.2.4 storageShell.html"><strong aria-hidden="true">7.11.4.</strong> 7.2.4 storageShell</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.3 Ejabberd/_index.html"><strong aria-hidden="true">7.12.</strong> Ejabberd</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.3 Ejabberd/Eventslist.html"><strong aria-hidden="true">7.12.1.</strong> Eventslist</a></li><li class="chapter-item expanded "><a href="7. 项目/7.3 Ejabberd/hooksformoduledevelopers.html"><strong aria-hidden="true">7.12.2.</strong> Hooksformoduledevelopers</a></li><li class="chapter-item expanded "><a href="7. 项目/7.3 Ejabberd/mod_echo.erl.html"><strong aria-hidden="true">7.12.3.</strong> mod_echo.erl</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.4 Cowboy/_index.html"><strong aria-hidden="true">7.13.</strong> Cowboy</a></li><li class="chapter-item expanded "><a href="7. 项目/7.5 kbengine/_index.html"><strong aria-hidden="true">7.14.</strong> kbengine</a></li><li class="chapter-item expanded "><a href="7. 项目/7.6 Rebar/_index.html"><strong aria-hidden="true">7.15.</strong> Rebar</a></li><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/_index.html"><strong aria-hidden="true">7.16.</strong> GraphicsMagick</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/7.7.1 代码片段/_index.html"><strong aria-hidden="true">7.16.1.</strong> GraphicsMagick</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/7.7.1 代码片段/7.7.1.1 convert.html"><strong aria-hidden="true">7.16.1.1.</strong> 7.7.1.1 convert</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/7.7.2 配置/_index.html"><strong aria-hidden="true">7.16.2.</strong> 配置</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/7.7.2 配置/7.7.2.1 安装.html"><strong aria-hidden="true">7.16.2.1.</strong> 7.7.2.1 安装</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/7.7.3 异常情况/_index.html"><strong aria-hidden="true">7.16.3.</strong> 异常情况</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.7 GraphicsMagick/7.7.3 异常情况/7.7.3.1 运行警告1.html"><strong aria-hidden="true">7.16.3.1.</strong> 7.7.3.1 运行警告1</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.8 MongoDB/_index.html"><strong aria-hidden="true">7.17.</strong> MongoDB</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.8 MongoDB/7.8.1 代码片段/_index.html"><strong aria-hidden="true">7.17.1.</strong> MongoDB</a></li><li class="chapter-item expanded "><a href="7. 项目/7.8 MongoDB/7.8.2 配置/_index.html"><strong aria-hidden="true">7.17.2.</strong> 配置</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="7. 项目/7.8 MongoDB/7.8.2 配置/7.8.2.1 分布式.html"><strong aria-hidden="true">7.17.2.1.</strong> 7.8.2.1 分布式</a></li></ol></li><li class="chapter-item expanded "><a href="7. 项目/7.9 Redis/_index.html"><strong aria-hidden="true">7.17.3.</strong> Redis</a></li></ol></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">pro笔记</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/yujian1018/yujian1018.github.io/tree/master/pro" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="介绍"><a class="header" href="#介绍">介绍</a></h1>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>![<a href="http://baike.baidu.com/view/453197.htm">http://baike.baidu.com/view/453197.htm</a> ]</p>
<div style="break-before: page; page-break-before: always;"></div><p>gitAPI:
<a href="https://developer.github.com/">https://developer.github.com/</a></p>
<p>域名</p>
<p><a href="https://example.org/api/">https://example.org/api/</a></p>
<p>版本</p>
<p>Accept: vnd.example-com.foo+json; version=1.0</p>
<p>路径（Endpoint）</p>
<p><a href="https://api.example.com/v1/zoos">https://api.example.com/v1/zoos</a>
<a href="https://api.example.com/v1/animals">https://api.example.com/v1/animals</a>
<a href="https://api.example.com/v1/employees">https://api.example.com/v1/employees</a></p>
<p>HTTP动词</p>
<p>GET（SELECT）：从服务器取出资源（一项或多项）。
POST（CREATE）：在服务器新建一个资源。
PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。
PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。
DELETE（DELETE）：从服务器删除资源。
HEAD：获取资源的元数据。
OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。</p>
<p>GET /zoos：列出所有动物园
POST /zoos：新建一个动物园
GET /zoos/ID：获取某个指定动物园的信息
PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息）
PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息）
DELETE /zoos/ID：删除某个动物园
GET /zoos/ID/animals：列出某个指定动物园的所有动物
DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物</p>
<p>过滤信息（Filtering）</p>
<p>?limit=10：指定返回记录的数量
?offset=10：指定返回记录的开始位置。
?page=2&amp;per_page=100：指定第几页，以及每页的记录数。
?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。
?animal_type_id=1：指定筛选条件</p>
<p>状态码</p>
<p>200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。
201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。
202 Accepted - [<em>]：表示一个请求已经进入后台排队（异步任务）
204 NO CONTENT - [DELETE]：用户删除数据成功。
400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。
401 Unauthorized - [</em>]：表示用户没有权限（令牌、用户名、密码错误）。
403 Forbidden - [<em>] 表示用户得到授权（与401错误相对），但是访问是被禁止的。
404 NOT FOUND - [</em>]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。
406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。
410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。
422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。
500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。</p>
<p>返回结果</p>
<p>GET /collection：返回资源对象的列表（数组）
GET /collection/resource：返回单个资源对象
POST /collection：返回新生成的资源对象
PUT /collection/resource：返回完整的资源对象
PATCH /collection/resource：返回完整的资源对象
DELETE /collection/resource：返回一个空文档</p>
<p>最常见的一种设计错误，就是URI包含动词。因为&quot;资源&quot;表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。
POST /transaction HTTP/1.1
Host: 127.0.0.1
from=1&amp;to=2&amp;amount=500.00</p>
<div style="break-before: page; page-break-before: always;"></div><p>1．问题领域——我们的架构是为解决什么类型的问题而设计的？软件架构 一定不是通用的，而是为解决某一类特定问题而设计的。缺少了关于用 来解决哪类问题的描述的架构是不完整的。
2．哲学—— 软件构造方法背后的原理是什么？架构的核心思想是什么？
3．软件构造指南——我们如何来规划一个系统？我们需要一个明确的软件 构造指南集。我们的系统将由一个程序员团队来编写和维护——所以对 所有的程序员和系统设计者来说，理解系统的架构和它的潜在哲学是很 重要的。从实用性的角度来讲，这些知识以软件构造指南的方式表现出 来更便于维持。一个完整的软件构造指南集包括编程规则集、例子程序 和培训资料等等。
4．预先定义好的部件——以“从一组预先定义好的部件中选择”的方式进 行设计远比“从头设计”的方式要来得容易。Erlang 的 OTP 库包含了一 个完整的现成部件集（称之 behaviour 库），一些常用的系统都可以使用 这些部件构建起来。例如 gen_server 这种 behaviour 就可以用来构建 client-server 系统，gen_event 这种 behaviour 可以用来构建基于事件 （event-based）的程序。关于预定义部件的更完整的讨论见 6.1 节。6.2.2 节将给出一个关于如何使用 gen_server 这种 behaviour 来编写一个服务器 软件的简单例子。
5．描述方式——我们如何描述某一部件的接口？我们如何描述系统中两个 部件之间的通信协议？我们如何来描述系统中的静态和动态结构？为了 回答这些问题，我们将介绍一些专门的符号。其中一些用来描述程序的 API，而其他的则用来描述协议和系统结构。
6．配置方式——我们如何来启动、停止和配置我们的系统？我们可以在系 统工作过程中进行重配置吗？</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li>速度</li>
<li>简单的设计
  对非线性开发模式的强力支持（允许上千个并行开发的分支）</li>
<li>完全分布式
  有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p><a href="http://yaws.hyber.org/yman.yaws?page=yaws.conf">http://yaws.hyber.org/yman.yaws?page=yaws.conf</a></p>
<pre><code class="language-config">yaws默认上传文件大小为：2048
partial_post_size = nolimit 上传的文件无限大
post限制
partial_post_size = 2048

缓存机制
max_num_cached_files
max_num_cached_bytes
max_size_cached_file
cache_refresh_secs

max_connections

list_dir
errormod_crash = Module
errormod_401 = Module
errormod_404 = Module Module:out404(Arg, GC, SC)

Arg - a #arg{} record
GC - a #gconf{} record (defined in yaws.hrl)
SC - a #sconf{} record (defined in yaws.hrl)

url重写
appmods = &lt;Path1, Module1&gt; &lt;Path2, Modules2&gt;
appmods = &lt;cgi-bin, yaws_appmod_cgi&gt;

session 存活时间
keepalive_timeout = 1*3600*8*1000

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>1.check_cookie( A ) -&gt;
H = A#arg.headers,
case yaws_api:find_cookie_val( ?Cook, H#headers.cookie ) of
Val when Val /= [] -&gt;
case yaws_api:cookieval_to_opaque( Val ) of
{ok, Sess} -&gt;
{ok, Sess, Val};
{ error, { has_session, Sess }} -&gt;
{ok, Sess};
Else -&gt;
Else
end;
[] -&gt;
{error, nocookie}
end.
2.{ok, _Sess, Cookie} -&gt; yaws_api:delete_cookie_session( Cookie ); 删除session
3.yaws_api:new_cookie_session( Sess ). 新建session
yaws_api:new_cookie_session( Sess, TTL ).
yaws_api:new_cookie_session( Sess, TTL, CleanupPid ).
4.yaws_api:setcookie(&quot;haowenjiao&quot;,Cookie)  -&gt; 估计默认权限为当前文件夹下的所有目录
yaws_api:setcookie( &quot;haowenjiao&quot;, Cookie, Path ). Path -&gt; session在站点中的权限范围
5.yaws_api:cookieval_to_opaque( CookieVal ).
6.yaws_api:print_cookie_sessions().
7.yaws_api:replace_cookie_session(Cookie, NewCookie). 替换session</p>
<p>页面的值的传递
<erl>
ID = yaws_api:binding(&quot;B&quot;)
</erl></p>
<p>%%A%%</p>在页面中使用变量A
<p>P = yaws_api:parse_query(A),
    L = case lists:keysearch(page, 1, P) of
              {value, {page, Page}} -&gt;
                   .....
当form表单没用method时默认？传值</p>
<p>1.yaws_api:url_decode(Url),
yaws_api:url_encode(Url),
2. out(_Arg) -&gt;
L=&quot;http://www.google.com/search?num=20&amp;hl=en&amp;lr=lang_en%7Clang_sv&amp;q=yaws&quot;,
{redirect, L}.
out(_Arg) -&gt;
{redirect_local, &quot;/redirect2.yaws&quot;}.本服务器上
out(_Arg) -&gt;
{redirect_local, {any_path, &quot;redirect2.yaws&quot;}}.
[yaws_api:redirect(&quot;/userLogin.yaws&quot;)]</p>
<p>3.yaws_api:binding(&quot;A&quot;)</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.1%20Yaws//images/screenshot_1527428590053.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>设置session时，需要运行
1.</p>
<p>Url = &quot;/&quot;,
        [{&quot;action&quot;, Action}|Data] = yaws_api:parse_query( A ),
        case Action of
            &quot;reg&quot; -&gt;
                [ {&quot;userlogin&quot;, UserName},
                  {&quot;password&quot;, _Pwd},
                  {&quot;passwordtoo&quot;, Pwd},
                  {&quot;Email&quot;, Email},
{&quot;val&quot;,_Val} ] = yaws_api:parse_post( A ),
                try myuser_mod_manager:reg_user( UserName, erlang:md5( Pwd ), Email ) of
                    Name -&gt;
                        Cookie = yaws_api:new_cookie_session(Name),
                        [ yaws_api:redirect(Url), yaws_api:setcookie(&quot;haowenjiao&quot;,Cookie) ]
                catch
                    _:_Why -&gt;
                        mnesiaDBA_pub_function:log( _Why, &quot;../doc/logs/myuser.access&quot; ),
                        {redirect, &quot;/userLogin/userLogin.yaws&quot;}
                end;
            &quot;login&quot; -&gt;
                [ {&quot;userlogin&quot;, UserName}, {&quot;password&quot;, Pwd} ] = yaws_api:parse_post( A ),
                case myuser_mod_manager:login_user( UserName, erlang:md5( Pwd ) ) of
                    true -&gt;
                        {redirect, &quot;/&quot;};
                    false -&gt;
                        {redirect, &quot;/userLogin/userLogin.yaws?name=&quot;++UserName++&quot;&amp;msg=账户名或密码错误&quot;}
                end
        end.
2.</p>
<erl>
out( A ) ->
Action =
case transfar_ctrl_cookie:check_cookie( A, "transfarHaowenjiao" ) of
{error, Other} ->
case transfar_ctrl_cookie:weixinOpenId( A ) of
{ok, SetCookie, OpenId} -> {ok, OpenId, SetCookie};
{error, "no code"} -> {error, "no code"};
{url, Url} -> {url, Url}
end;
{ok, OpenId, SetCookie1} ->
{ok, OpenId, SetCookie1}
end,
case Action of
{url, WeixinUrl} -> [{redirect, WeixinUrl}, {bindings, [{"openId", ""}]}];
{ok, WexinOpenId, Cookie} -> [{bindings, [{"openId", WexinOpenId}]}, yaws_api:setcookie("transfarHaowenjiao", Cookie), {ssi, "inc/meta.inc", "", ""}];
{error, "no code"} -> [{bindings, [{"openId", ""}]}, {html, "<script type=\"text/javascript\">window.location='error.yaws?action=OAuthError'</script>"}]
end.
</erl>
![pic](/images/screenshot_1527428601812.png)
<div style="break-before: page; page-break-before: always;"></div><p>Post传值
Post = yaws_api:parse_post( A ),
         Data =[ X|| {<em>, X} &lt;-Post ]。
query 可以接受问好
<erl>
out(A) -&gt;
       [{&quot;name&quot;,Name}|</em>] = yaws_api:parse_query( A ),
       {bindings, [{&quot;A&quot;, Name}]}.
</erl>
Post和？都可以使用 case postvar(A,&quot;lang&quot;) of
                  undefined -&gt; &quot;None&quot;;
                  {ok, Val} -&gt; Val
              end
yaws_api:queryvar( A, &quot;lang&quot; )
lang代表form表单的一个name
        case    yaws_api:queryvar(A, &quot;userlogin&quot;) of
                    undefined -&gt; &quot;None&quot;;
                    {ok, Val} -&gt; Val</p>
<p>userlogin代表form表单的一个name</p>
<p>case postvar(A,&quot;lang&quot;) of
                  undefined -&gt; &quot;None&quot;;
                  {ok, Val} -&gt; Val</p>
<p>页面的值的传递
<erl>
ID = yaws_api:binding(&quot;B&quot;)
</erl></p>
<p>%%A%%</p>在页面中使用变量A
<p>P = yaws_api:parse_query(A),
    L = case lists:keysearch(page, 1, P) of
              {value, {page, Page}} -&gt;
                   .....
当form表单没用method时默认？传值
<img src="7.%20%E9%A1%B9%E7%9B%AE/7.1%20Yaws//images/screenshot_1527428621649.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><erl>
    out( A ) ->
        %L = talk_mod_init:geturlpage(),
        %{html, L  }.
        {ehtml,
         [{'div',[{style,"display:none"},{id,right}],["我有一头小毛驴"]
         }]}.
</erl>
<p>Data1 ={p, [{style, &quot;display:none&quot;},{id,&quot;nowpage&quot;}],[Page]},
 {ehtml, Data1}
{ehtml,
  {table, [],
    {tr, [],
       [{td, [{width, &quot;30%&quot;}],
          {table,[{border, &quot;1&quot;}, {bgcolor, beige},{bordercolor, black}],
           [{tr, [], {td, [], pb(&quot;User: ~s&quot;, [User])}}]
          }
        },
        {td, [{align, right}], {img, [{src, &quot;junk.jpg&quot;}]}
       }]
     }
  }
}.
<img src="7.%20%E9%A1%B9%E7%9B%AE/7.1%20Yaws//images/screenshot_1527428652492.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>test.yaws
<erl>
out( A ) -&gt;
 {ehtml,[{ssi,&quot;ssi_ex1.txt&quot;,&quot;@&quot;,[{&quot;a&quot;,&quot;zippo&quot;},{&quot;b&quot;,&quot;我有一头小毛驴&quot;}]}]}.
</erl>
ssi_ex1.txt
variable a = @a@,b=@b@
test.yaws
variable a = zippo,b=我有一头小毛驴</p>
<p>{ssi, &quot;/inc/health_text.inc&quot;, &quot;%&quot;,[{&quot;embed&quot;, &quot;choosen&quot;}]};
{ssi, &quot;/inc/health_text.inc&quot;, &quot;&quot;,[{&quot;&quot;, &quot;&quot;}]};</p>
<erl>
    out(A) -> {bindings, [{"A", "foo"}, {"B", "baz"}]}.
</erl>
Value = yaws_api:binding("A").
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.1%20Yaws//images/screenshot_1527428611174.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>1  Failed to load setuid_drv (from &quot;/httx/yaws/lib/yaws/priv/lib&quot;) : &quot;Driver compiled with incorrect version of erl_driver.h&quot;  疑似原因：
1.It looks like you've compiled on one version of Erlang and are trying
to run it with different version.（由A版本编译，由B版本运行）
2.安装Aerlang版本，卸载不全，由安装B版本
环境：
1.Erlang版本：R15B01（安装成功）
2.yaws：1.91（安装失败）
目前解决办法：安装yaws1.96版本成功</p>
<p>2  epam.c:2:22: fatal error: pam_appl.h: 没有那个文件或目录  yum -y install pam-devel</p>
<p>下载 openpam
wget <a href="http://nchc.dl.sourceforge.net/sourceforge/openpam/openpam-20130907.tar.gz">http://nchc.dl.sourceforge.net/sourceforge/openpam/openpam-20130907.tar.gz</a>
编译/安装 openpam
tar zxvf openpam-20130907.tar.gz
cd openpam-20130907
./configure
sudo make install
修改 YAWS
cd yaws-1.97/c_src
vim epam.c
修改#include &lt;pam_appl.h&gt; 为 #include &lt;security/pam_appl.h&gt;
./configure
sudo make install</p>
<div style="break-before: page; page-break-before: always;"></div><p>schema -&gt; 分布式信息</p>
<pre><code class="language-erlang">mnesia:create_schema(NodeList). 该函数用来初始化一个新的空模式,在 Mnesia
 启动之前这是一个强制性的必要步骤。
 Mnesia 是一个真正分布式的数据库管理系统,而模式是一个系统表,它被复制到 Mnesia 系统的所有节点上。
 如果 NodeList 中某一个节点已经有模式,则该函数会失败。该函数需要 NodeList 中所有节点上的 Mnesia 都停止之后才执行。应用程序只需调用该函数一次,因为通常只需要初始化数据库模式一次
mnesia:delete_schema(DiscNodeList) 该函数在 DiscNodeList 节点上删除旧的模式,
 它也删除所有旧的表和数据。
 该函数需要在所有数据库节点(db_nodes)上的Mnesia 都停止后才能执行
mnesia:delete_table(Tab). 该函数永久删除表 Tab 的所有副本 。
mnesia:clear_table(Tab). 该函数永久删除表 Tab 的全部记录
mnesia:move_table_copy(Tab, From, To). 该函数将表 Tab 的拷贝从 From 节点移动到 To 节点。表的存储类型{type}被保留,这样当移动一个 RAM 表到另一个节点时,在新节点上也维持一个 RAM 表。在表移动的过程中仍然可以有事务执行读和写操作 。
mnesia:add_table_copy(Tab, Node, Type). 该函数在 Node 节点上创建 Tab 表的
 备份。Type 参数必须是 ram_copies 、 disc_copies 或者是 disc_only_copies。如果我们加一个系统表 schema 的拷贝到某个节点上,这意味着我们要 Mnesia 模式也驻留在那里。这个
 动作扩展了组成特定 Mnesia 系统节点的集合 。
mnesia:del_table_copy(Tab, Node). 该函数在 Node 节点上删除 Tab 表的备份,当
 最后一个备份被删除后,表本身也被删除。
mnesia:transform_table(Tab, Fun,NewAttributeList, NewRecordName). 该函数改变表 Tab 中所有记录的格式。它对表里所有记录调用参数 Fun 指明的函数进行处理,从表中取得旧的记录类型处理后返回新的纪录类型,表的键(key)可以不被改变。
 
 T= fun({test, A1,A2::test所有记录}) -&gt;  
     { test， A1,A2,&quot;add_clumn&quot;::对每一个记录进行修改|添加|删除 } end. 
 mnesia:transform_table(test,T,[id,name,age]--新的字段).  
  
  
 Fun = fun({person, Name, Age})  -&gt; {person, Name, Age, 0} end, 
 NewAttr = [name, age, money], 
 mnesia:transform_table(person, Fun, NewAttr, person).
 
change_table_copy_type(Tab, Node, ToType). 该函数改变表的存储类型。例如,将在 Node 节点上指定的内存类型的表 Tab 改为磁盘类型的表
 disc_only_copies -&gt;建立磁盘表  
 disc_copies -&gt; 磁盘加内存表  
 ram_copies -&gt; 内存表
mnesia:change_config (extra_db_nodes, NodeList) 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-erlang">mnesia:create_table(Name, Opts).
[
  {type, bag||set||ordered_set|| duplicate bag},  %默认值 set
*{disc_only_copies||disc_copies||ram_copies, NodeList},  %默认值是 [node()],可以同时新建三种类型的表
  {index,AttributeNameList},  %AttributeNameList 是一个原子类型的属性名列表
  {snmp, SnmpStruct} %SnmpStruct 在 SNMP 用户指南中描述，表示该表可以立即通过简单网络管理协议(SNMP)来访问
  {local_content, true} %表名对所有 Mnesia 点可见,但是内容对每个节点都是唯一的。这种类型的表只能在本地进行存取
*{attributes, record_info( fields, itemGene )},  
  {record_name, Name},  %指定表中所有记录的通用名
  [{frag_properties,
                     [{n_fragments, 20}, {n_disc_copies, 1},
                     {node_pool, [node()]}]},
  ]

set -&gt; 每一个元组的键值都不能相同 
ordered_set -&gt; 元组会进行排序 
bag -&gt; 多个元组可以有相同的键值,一条记录确定唯一性 
 duplicate_bag -&gt; 多个元组可以有相同的键值，同一个元组可以在表中出现多次 

local_content -&gt; 应用需要一个其内容对每个节点来说在本地都是唯一的表，这种类型的表只能在本地进行存取

frag_properties %分片属性

mnesia:create_table( table_name, [{ram_copies, [a@yujian,b@yujian]}] ).建表
mnesia:system_info().
mnesia:table_info(Tab, Attr)
mnesia:system_info( running_db_nodes ). 
mnesia:table_info( table_name, frag_properties ).
 


mnesia:dump_to_textfile(Filename)  
mnesia:load_textfile/1
mnesia:backup(&quot;./backup.log&quot;).%二进制数据创建检查点，不受后面写数据影响 
mnesia:restore(&quot;./backup.log&quot;, Args).%表写锁,必须要存在表 

mnesia:install_fallback(Opaque, Args) -&gt; ok | {error,Reason} 
mnesia:uninstall_fallback(Args) -&gt; ok | {error,Reason}
mnesia:dump_tables(TabList).
ets转储到磁盘上
Mnesia 事件处理
mnesia:subscribe(Event-Category) %确保所有 Event-Category 类型事件的副本会发送给调用进程
mnesia:unsubscribe(Event-Category) %删除对 Event-Category 类型事件的订阅

Event-Category 可以是原子 system 或元组{{table, Tab, simple}或{table, Tab, detailed}二者之一。
旧的事件类别{table, Tab}与事件类别{table, Tab, simple}是一样的。订阅函数激活对事件的订阅。
对函数 mnesia:subscribe/1 求值即将事件作为消息发送给进程。
系统事件的语法是{mnesia_system_event, Event},表事件的语法是{mnesia_table_event, Event}。
系统事件和表事件的含义描述如下:所有的系统事件通过 Mnesia 的通用事件处理器(gen_event handler)来订阅,
默认的通用事件处理器是 mnesia_event,但可通过应用参数 event_module 来改变。
这个参数的值必须是一个模块名,该模块是使用标准库(STDLIB)的 gen_event 模块来实现的完整的事件处理模块。

mnesia:system_info(subscribers) 和 mnesia:table_info(Tab, subscribers)用来确定哪些进程订阅了何种事件。
文件
FALLBACK.BUP %这个文件被称为备份文件,包含一个初始模式。如果我们在 mnesia:create_schema/1 函数中指定了一个以上的节点,同一个备份文件将在所有这些节点上被创建

Schema.DAT %在备份文件 FALLBACK.BUP 中的模式被用来生成文件 schema.DAT

Table.DCL %Mnesia 插入此操作到 foo.DCL 中,随后在 Mnesia 认为.DCL 文件已经变得太大时,再将数据移入.DCD 文件 
Table.DCD %写到 foo 表中的所有数据最终将存储在这个文件中

LATEST.LOG %被 Mnesia 用来对基于磁盘的事务做日志
PREVIOUS.LOG %在日志被转储之前,文件 LATEST.LOG 改名为 PREVIOUS.LOG,并且创建一个新的LATEST.LOG 文件

在默认状态下,只要日志中写入了 100 条记录或者过去了 3 分钟这两种情况之一出现,Mnesia 即转储日志。
可用两个应用程序参数-mnesia dump_log_write_threshold WriteOperations 和-mnesia dump_log_time_threshold MilliSecs 来对此进行控制

.DAT %是建有索引的文件,可用指定的键在这些文件中高效地插入和搜索记录
mnesia:set_master_nodes(Tab,
Nodes)
mnesia:set_master_nodes(Nodes)
如果应用程序发现由于通信失败导致数据库的不一致，设定从哪个节点更新数据
mnesia:force_load_table(Tab)
可用来强行加载表而无视其被激活的加载机制
数据备份、操作备份数据
mnesia:backup_checkpoint(Name, Opaque, [Mod])。这个函数执行一个包含在检查点中的表备份。

mnesia:backup(Opaque, [Mod]) 。 这个函数激活一个覆盖全部 Mnesia 表的新检查点并且执行一次备份。备份以最大冗余度执行 (也可参见函数

mnesia:activate_checkpoint(Args), {max, MaxTabs} and {min, MinTabs})。

 mnesia:traverse_backup(Source,[SourceMod,]Target,[TargetMod,]Fun,Ac)。这个函数能用来读存在的备份,从一个现存的备份创建一个新的备份,或者在不同介质之间拷贝备份。

 mnesia:uninstall_fallback()。这个函数移除先前安装的回滚文件。

 mnesia:restore(Opaque, Args)这个函数从先前的备份恢复表。

mnesia:install_fallback(Opaque, [Mod])这个函数能够配置成从一个现存的备份重启 Mnesia并且重新加载数据库表以及可能的模式表。当数据或模式表损毁时,此函数被用于灾难恢复。

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-erlang">查询
mnesia:add_table_index( test, name). 
mnesia:del_table_index( test, name). 
mnesia:index_read(Table, Arg, Attr).
建表时，为该表建立索引使用元组{index, [attr1, attr2,....}
mnesia:index_match_object( alias, Pattern, #alias.alias_name, read ).

fun() -&gt; mnesia:write( New ) end 
fun() -&gt; mnesia:read( { table, Id } ) end 
fun() -&gt; mnesia:delete( {product, Id} ) end 
fun() -&gt;  [R] = mnesia:read( table, Id, write ), 
               New = R#table{ Id = Ids }, 
               mnesia:write( New ) 
end.  先做读取操作，参数write为下面的mnesia:write做准备

do:q 
-include_lib( &quot;stdlib/include/qlc.hrl&quot; ). 
select(StringBin )-&gt; 
         Fun = fun( Key ) -&gt; binary:match( Key, StringBin ) =/= nomatch end, 
        do( qlc:q([ UUID||#test_select{key= UUID} &lt;- mnesia:table( test_select ), Fun(UUID)]) ). 

do( Q ) -&gt; 
    F = fun() -&gt; qlc:e( Q ) end, 
    mnesia:transaction( F ). 


指定的选项为 {lock, Lock} 、{n_objects,Integer} 和{ traverse, SelMethod}
lock 选项指定 Mnesia 是否应该请求一个读或写锁,
n_objects 指定在每个部分(chunk)应该返回多少结果给 QLC。
traverse,其指定哪一个函数 mnesia 应该用来遍历表,默认用 select。
但对 mnesia:table/2 使用{traverse, {select,MatchSpecification}}作为选项用户能够指定属于自己的表视图
mnesia:table( Tab, [{n_objects,100}, {lock,read},{traverse, select}] ).
如果没有指定选项,默认将会请求一个读锁,每部分返回 100 个结果,select 被用于遍历表

mnesia:delete_table(Tab) 
mnesia:dirty_all_keys(Tab) 
mnesia:clear_table(Tab). 
mnesia:all_keys( table ). 


mnesia:select/2, /4 


   
mnesia:select(wordItem, [{ {'$0','$1','$2','$3'}, [{'==','$1', Id}], ['$$'] }], Len, read). 

{Res, Cout} = mnesia:select(test, [{'$1', [], ['$1']}], 5000, read|write).
{Res1, Cout1} = mnesia:select(Cout).

mnesia:select(test, [{ #test{id='$1',name=Name, _ = '_' }, [], ['$1'] }]). 

mnesia:select(Tab,[{MatchHead, [Guard], [Result]}]).
 MatchHead = #person{name='$1', sex=male, age='$2', _='_'}, 
 Guard = {'&gt;', '$2', 30},      $2中所有大于30的记录 
 Result = '$1',      选出匹配记录的name字段 

ets:fun2ms( fun( #test_select{key= Key} ) 
     when ( Key &gt;= StrBin) andalso ( Key =&lt; &lt;&lt; StrBin/binary, 255&gt;&gt;) -&gt; Key end  ), 

mnesia: match_object ( Record ) 
mnesia:delete_object(Record)
mnesia:match_object(person, #person{ id = 36, _ = '_'}, read)         
mnesia:match_object(person, {'_', 36, '_'},read)

mnesia:dirty_slot(Tab, N). 
返回第N块数据




mnesia:dirty_update_counter(Table, Key, 1).
1.创建如下结构的mnesia数据库表-record(unique_id, {item, uid}); 

2.每为feature表加入一条新记录时,需要得到新的id值: 
     mnesia:dirty_update_counter(unique_id, feature, 1), 
  注意：请在建立unique_id表的时候，往里面插入数据，表名，初始值，{feature,0}

mnesia:foldl(Fun, Acc0, Tab)
mnesia:foldr(Fun, Acc0, Tab)
mnesia:foldl(Fun, Acc0, Tab, LockType)
mnesia:foldr(Fun, Acc0, Tab, LockType)
LockType 默认是读锁， 如果在迭代时写入或删除记录,那么就应该请求写锁

mnesia:first(Tab) -&gt; Key | transaction abort
mnesia:last(Tab) -&gt; Key | transaction abort
mnesia:next(Tab,Key) -&gt; Key | transaction abort
mnesia:prev(Tab,Key) -&gt; Key | transaction abort
mnesia:snmp_get_next_index(Tab,Index) -&gt; {ok, NextIndex} | endOfTable
mnesia:write_lock_table/1
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-erlang">数据分片：本质把一张表分成多张表，
当使用mnesia:activity/4操作数据时，分片属性被使用，会到多张表中进程操作

mnesia:activity/4
WriteFun = fun( Keys ) -&gt; [ mnesia:write( {table_name, K, -K} ) || K&lt;- Keys] end.
mnesia:activity( sync_dirty, WriteFun, [ lists:seq(1,256) ], mnesia_frag ). %写入数据，[ lists:seq(1,256) ]是数据内容
mnesia:change_table_frag(Tab, Change)
{activate, FragProps} %激活一个现存表的分片属性,FragProps 应为 {node_pool, Nodes} 或是空
deactivate %解除表的分片属性, 片断的数量必须是 1 。没有其它表在其外键中引用此表
{add_frag, NodesOrDist} %加一个新的片断到分片表。
在老的片断中的全部记录将被重新处理并且其中一半的记录将被移送到新(最后的)片断。
所有通过外键引用此表的其它分片表将自动获得新的片断,其记录也将用与主表相同的方式动态重新处理。
NodesOrDist 参数可以是一个节点列表或者是来自于 mnesia:table_info(Tab,frag_dist)函数的结果 。
NodesOrDist 参数被看作是一个根据新副本首先 进 入的主机为最优来排序的有序节点列表。
新片断将获得与第一个片断同样数量的副本(看n_ram_copies , n_disc_copies 和 n_disc_only_copies)。
NodesOrDist 列表必须至少包含一个需要为每个副本分配的单元。
del_frag %从分片表删除一个片断。在最后这个片断的所有记录将被移到其它片断之一。所有通过其外键引用此表的其它分片表将自动丢失其最后的片断,其记录也将用与主表相同的方式动态重新处理。
{add_node, Node} %增加一个新节点到节点池 node_pool 。 新的节点池将影响从函数.mnesia:table_info(Tab, frag_dist)返回的列表。
{del_node, Node} %从节点池 node_pool 删除一个节点。新的节点池将影响从函数mnesia:table_info(Tab, frag_dist)返回的列表
[{frag_properties,
[{n_fragments, 20},
 {n_disc_copies, 1},
 {node_pool, [node()]}]}]
分片属性
{n_fragments, Int} %n_fragments 控制这个表当前有多少个片断。
这个属性可在创建表的时候设置,也可以在后来用{add_frag,NodesOrDist} 或 del_frag 改变。n_fragments 默认为 1
{node_pool, List} %节点池包含一个节点列表,可以在创建表的时候显式指定,也可以在后来用{add_node,Node}或{del_node, Node}来改变。
在创建表的时候 Mnesia 尝试将每个片断的副本均匀地分布到节点池中的所有节点,期望所有节点都有同样数量的副本来结束。
node_pool 默认从 mnesia:system_info(db_nodes) 返回值。
{n_ram_copies, Int} %控制每个片断应该有多少 ram_copies 副本。这个属性可在创建表时显式指定。 默认值是 0 ,  
但如果 n_disc_copies 和 n_disc_only_copies 也是 0 ,则n_ram_copies将默认置为 1
{n_disc_copies, Int}
{n_disc_only_copies, Int}
{foreign_key, ForeignKey}
{hash_module, Atom}
{hash_state, Term}
mnesia:table_info/2
在使用 mnesia_frag 模块的作业上下文中调用函数 mnesia:table_info/2,可获得一些新项目的信息
base_table %分片表的名字
n_fragments %片断的实际数量
node_pool %节点池
n_ram_copies
n_disc_copies
n_disc_only_copies
存储类型 ram_copies, disc_copies 和 disc_only_copies 各自的副本数量。源自于第一个片断的实际值是动态的。实际值通过计算每种存储类型的每个副本的数量来确定,当需要计算实际值的时候(如在增加一个新片断时),第一个片断的类型将作为计算的依
据。这表明当函数 mnesia:add_table_copy/3 , mnesia:del_table_copy/2 和mnesia:change_table_copy_type/2 被应用于第一个片断时,将会影响到n_ram_copies , n_disc_copies 和 n_disc_only_copies 的设置。
foreign_key %外键
foreigners %通过其外键引用该表的所有其它表。
frag_names所有片断的名字。
frag_dist
一个按 Count 增序排列的{Node, Count} 元组的有序列表。Count 是分片表副本所在主机节点 Node 的总数。这个列表至少包含了节点池 node_pool 中的全部节点 。 不属于节点池 node_pool 的节点即使其 Count 值较低也将被放在列表的最后。
frag_size %{Name, Size}元组列表,Name 是片断名称,Size 是其包含了多少条记录。
frag_memory %{Name, Memory} 元组列表, Name 是片断名称, Memory 是被占用内存数。
size %所有片断的总尺寸
memory %所有片断的总内存

Info = fun( Item ) -&gt; mnesia:table_info( table_name, Item ) end.
Dist = mnesia:activity( sync_dirty, Info, [frag_dist], mnesia_frag).
mnesia:change_table_frag( table_name, {add_frag, Dist} ). %分表，把整个表分开。

mnesia:change_table_frag( table_name, {add_frag, Dist} ).---继续分
已连接

来自 &lt;https://www.kancloud.cn/book/yujian/erlang/edit&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-erlang">读锁。在记录的副本能被读取之前设置读锁。.
写锁。当事务写一条记录时,首先在这条记录的所有副本上设置写锁。
读表锁。如果事务要扫描整张表来搜索一条记录,那么,对表里的记录一条一条的加锁效率很低也很耗内存(如果表很大,读锁本身会消耗很多空间)。因此,Mnesia 可以对表设
置读锁。
写表锁。如果事务要写大量的记录到表里,则可以对整张表设置写锁。
粘(Sticky)锁。即使设置锁的事务终止后,这些写锁也会一直保留在节点上。

mnesia的锁机制：
读锁、写锁、读表锁、写表锁、粘锁 
mnesia:transactionm( fun() -&gt; mnesia:s_write( #test{ id=123 } ) end)  s_write/1函数用粘锁来代替write/1普通的锁 
在本地节点上该粘锁效果和普通的锁一样，但是在多节点上，该表被复制后，粘锁一直存在，使用普通的锁需要在其他节点上新建 
mnesia:read_lock_table(Tab)  在表Tab上加读锁     
mnesia:lock( {table, Tab}, read||write ) 
mnesia:write_lock_table(Tab) 在表Tab上加写锁
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-erlang">
解决方案：erl -name a@yujian
1.在两台机器上分别建立各自一个节点，我使用我的电脑和我后面的电脑

    我的机器                                                            test机器




这时运行：
     mnesia:create_schema( [ yujian@yujian, test@DP-201001010138 ]).出现错误

我猜测可能是test@DP-201001010138这个名称的问题，把这个名称修改掉，修改成test@test
    然后重新试验下
    2台机器之间有错误了    

该问题，出现原因未知
第二次试验信息：a机器：erl -name a@yujian -setcookie abc
                b机器:erl -name b@yujian -setcookie abc
此次解决方案：a机器代码修改：erl -sname a -setcookie abc
              b不变化

这时我准备在我的机器上启2个节点

ok
  这时mnesia:start().需要注意
然后创建表
    mnesia:create_table( baikefileRecord, [{disc_only_copies, [ yujian@yujian, test@yujian ]},
 {attributes, record_info( fields, baikefileRecord )}]).
mnesia:start().
mnesia:system_info().

以task_to_file表为例，首先确保2个节点上的这张表都为空，



然后向一个节点的表中插入数据，我想yujian@yujian这个节点中插入了10条数据，选择出来

然后再test@yujian节点上查看这个节点上现在是否有数据  

悲剧了同步更新了
在没有插入数据的节点上删除操作，更新操作，都会同步更新所有的节点

好吧现在的结论是：分布式的节点中每一张的数据都会更新成同样的数据
细节
关闭已经打开的yaws服务器
第一台机器(hz-ejabberd-web1)
进入到/home/project/文件夹下
yaws --sname computera --mnesiadir /httx/project/Mnesia.nonode@nohost --erlarg &quot;-setcookie wexin&quot;
进入yaws后，前缀
执行下面函数
mnesia:stop().
mnesia:delete_schema( [computera@yujian] ).

测试 http://127.0.0.1:8081/down.yaws,可以打开
在另一台机器
进入到/home/project/文件夹下
yaws --sname computerb --mnesiadir /httx/project/Mnesia.nonode@nohost --erlarg &quot;-setcookie wexin&quot;
进入yaws后，前缀
执行下面函数
mnesia:stop().
mnesia:delete_schema( [computerb@server] ).

测试 http://127.0.0.1:8081/down.yaws,可以打开
运行
mnesia:create_schema( [computera@yujian, computerb@server]).

运行
mnesia:system_info().

如图所示stopped db nodes 包括两项第四步才算成功
运行
分别在两台机器上运行：
mnesia:start().
运行完成后，在第一台机器上执行：
mnesia:system_info().

如图所示running db nodes 包括两项才算成功
在第一台机器上运行
mnesiaDBA_init:init( computerb@server,computera@yujian ).

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>原文链接：<a href="http://hideto.iteye.com/blog/235413">http://hideto.iteye.com/blog/235413</a></p>
<p>本章描述了构建分布式、容错的Mnesia数据库相关的高级特性：
1）索引
2）分布和容错
3）表分片
4）本地内容表
5）无盘节点
6）更多的schema管理
7）Mnesia事件处理
8）Mnesia应用调试
9）Mnesia里的并发进程
10）原型</p>
<p>1，索引
如果我们知道record的key，那么数据获取和匹配在执行起来都很高效
相反如果不知道record的key，那么表里所有的record都必须搜索
当表越来越大时，表的搜索就越来越耗时
Mnesia的索引就是用来解决这个问题的
下面的两个方法对已有的表操作索引：</p>
<ol>
<li>mnesia:add_table_index(Tab, AttributeName) -&gt; {aborted, R} | {atomic, ok}</li>
<li>mnesia:del_table_index(Tab, AttributeName) -&gt; {aborted, R} | {atomic, ok}</li>
</ol>
<p>这两个方法对AttributeName定义的域加索引和删除索引：</p>
<ol>
<li>mnesia:add_table_index(employee, salary)</li>
</ol>
<p>Mnesia的索引用于以下3个方法：
1）mnesia:index_read(Tab, SecondaryKey, AttributeName) -&gt; transaction abort | RecordList
通过在索引里查询SecondaryKey来找到primary key，这样就能避免对整张表穷举搜索
2）mnesia:index_match_object(Pattern, AttributeName) -&gt; transaction abort | RecordList
通过Pattern里的AttributeName域查找secondary key，然后找到primary key
3）mnesia:match_object(Pattern) -&gt; transaction abort | RecordList
该方法可以使用任何索引
2，分布和容错
Mnesia是分布式、容错的DBMS，可以以多种方式在Erlang节点上备份表
Mnesia程序员不需要了解不同的表位于哪里，只用在程序里指定表的名字
这就是“位置透明”：
1）数据位于本地节点还是远程节点对程序员没有影响，只不过远程节点会慢些
2）数据库可以重新配置，表可以在节点之间移动，这些操作不影响用户程序
每张表有许多系统属性，如index和type
在表创建之时表属性就指定了，例如创建拥有两个RAM备份的新表：</p>
<ol>
<li>mnesia:create_table(foo,</li>
<li>[{ramp_copies, [N1, N2]},</li>
<li>{attribtues, record_info(fields, foo)}]).
表可以有如下属性，每个属性使用一个Erlang节点list
1）ram_copies
表的RAM备份会存在于Erlang节点list中的每个节点上
对于RAM备份，写操作不会写到硬盘里
但是如果RAM备份需要持久化时可以这样做：
i）mnesia:dump_tables/1方法用来将RAM表备份导入到硬盘
ii）表副本可以备份
2）disc_copies
表会位于RAM中，而且表的副本会存在于Erlang节点list中的每个节点的硬盘上
对该表的写操作会同时写入到RAM和硬盘备份里
3）disc_only_copies
表的副本只会位于Erlang节点list中每个节点的硬盘上
这种类型的表副本的缺点是访问速度，优点主要是不占内存
简单的说，ram_copies表示本地节点和list中节点都会存RAM表
disc_copies则本地存RAM表，list中存硬盘表
disc_only_copies则只会list中存硬盘表
使用表副本有两个原因：容错和速度
值得注意的是，表备份对这两个系统需求都提供了解决方案
如果有两个表副本，则一旦一个表崩溃了，还有另一个可以工作
如果有两个节点上的表副本，则两个节点上的应用可以直接从本地读数据而不用访问网络
对于读频繁而写很少的分布式应用，表副本就会大大加速读的速度，因为直接在本地节点读取数据
而这样做的缺点写速度减慢了，因为执行一个写操作时要花更多代价来更新表副本
3，表分片
为了处理超大型的表，表分片的概念引入，基本原理是将表分成多个可以管理的片断
每个片断都实现为一等Mnesia表，它们可以像其他表一样备份，可以拥有索引等等，但是不能有local_content和snmp连接
为了从片断表里访问数据，Mnesia必须决定该record属于哪张表，这通过mnesia_frag模块来实现mnesia_access callback行为
（略）
4，本地内容表
所有节点上的表副本的内容一样，但是有时候不同节点的内容不同有优点
如果我们创建表时指定{local_content, true}属性，则写操作只在本地副本上执行
而且，当在启动时初始化表，则表只会在本地初始化而表内容不会复制到其他节点
5，无盘节点
可以在无盘的节点上运行Mnesia，当然在这些节点上不可能拥有disc_copies或disc_only_copies类型的备份
最麻烦的是schema表，因为Mnesia需要schema来初始化自己
schema表可以位于一个或多个节点上
schema表的存储类型可以为disc_copies或ram_copies(不能是disc_only_copies)
Mnesia启动时使用schema表来决定应该和哪些节点建立联系
如果其他节点已经启动，则启动节点将其他节点的表定义和自己的表定义合并
参数extra_db_nodes包含一个节点list，Mnesia除了schema里的节点，还要和该参数的节点建立联系，默认值为[]
因此，当无盘节点需要从网络上的一个远程节点找到schema定义，则我们需要从-mnesia extra_db_nodes参数节点列表支持该信息
如果没有这个配置参数，Mnesia会以一个单节点系统启动
可以使用mnesia:change_config/2来给'extra_db_node'赋值并且强制建立一个连接，即mnesia:change_config(extra_db_nodes, NodeList)
应用参数schema_location控制Mnesia在哪里搜索schema：
1）disc
强制硬盘，schema假设位于Mnesia目录，如果找不到，则Mnesia拒绝启动
2）ram
强制ram，schema只位于ram中，启动时会生成一个很小的新schema
这个默认schema只包含schema表的定义并且只位于本地节点
3）opt_disc
可选的硬盘，schema可能只位于硬盘或ram
如果硬盘上找不到schema，Mnesia启动一个无盘节点（schema表的存储类型为ram_copies）
如果schema_location设置为opt_disc，则方法mnesia:change_table_copy_type/3可以用来改变schema的存储类型：</li>
<li>1&gt; mneisa:start().</li>
<li>ok</li>
<li>2&gt; mnesia:change_table_copy_type(schema, node(), disc_copies).</li>
<li>{atomic, ok}
6，更多的Schema管理
可以从Mnesia添加和删除节点，这可以通过添加schema副本到这些节点来完成
mnesia:add_table_copy/3和mnesia:del_table_copy/2可以用来添加和删除schema表副本
添加一个节点会影响两点：1，允许其他表备份到该节点；2，它会在启动时连接硬盘节点
mnesia:del_table_copy(schema, mynode@host)从Mnesia系统删除'mynode@host'节点
mnesia:system_info(schema_location)和mnesia:system_info(extra_db_notes)用来决定schema_location和extra_db_nodes的值
mnesia:info/0用来打印出系统信息，可以在Mnesia启动之前就运行此方法
7，Mnesia事件处理
Mnesia可能生成系统事件和表事件这两种事件
用户进程可以订阅这些事件：
mneisa:subscribe(Event-Category)保证符合Event-Category类型的事件副本会发送给调用进程
mnesia:unsubscribe(Event-Category)对符合Event-Category类型的事件删除订阅
Event-Category可以为system或{table, Tab, simple}/{table, Tab, detailed}
系统事件语法为{mnesia_system_event, Event}，表事件语法为{mnesia_table_event, Event}
所有的系统事件有Mnesia的gen_event handler来订阅，默认为mnesia_event
mnesia:system_info(subscribers)和mnesia:table_info(Tab, subscribers)用来决定哪个进程订阅了事件
系统事件
{mnesia_up, Node}
{mnesia_down, Node}
{mnesia_checkpoint_activated, Checkpoint}
{mnesia_checkpoint_deactivated, Checkpoint}
{mnesia_overload, Details}
{inconsistent_database, Context, Node}
{mnesia_fatal, Format, Args, BinaryCode}
{mnesia_info, Format, Args}
{mnesia_error, Format, Args}
{mnesia_user, Event}
表事件
{write, NewRecord, ActivityId}
{delete_object, OldRecord, ActivityId}
{delete, {Tab, Key}, ActivityId}
{write, Table, NewRecord, [OldRecords], ActivityId}
{delete, Table, What, [OldRecords], ActivityId}
9，Mnesia应用调试
Mnesia应用调试比较麻烦，因为理解事务和表加载工作机制很难，而且嵌套事务的语义也比较令人混淆
我们可以设置Mnesia的debug level:</li>
<li>mnesia:set_debug_level(Level)
参数Level为none、verbose、debug、trace、false、true
也可以作为应用参数，在启动Erlang系统时指定：</li>
<li>% erl -mnesia debug verbose
9，Mnesia里的并发进程
Mnesia里允许并发的事务提交，程序里不用显式的控制同步的进程
而且可以在用户继续使用表时移动、删除或重新配置表
详细参考四，事务和其他访问上下文
10，原型
如果我们决定使用Mnesia，通常会先将定义和数据写在纯文本里，这样比较简单
这样在构建原型时我们把定义和数据写在纯文本文件里，然后使用下面方法来处理：
mnesia:load_textfile(Filename)
mnesia:dump_to_textfile(Filename)
文本文件的格式为：</li>
<li>{tables, [{Typename, [Options]}, {Typename2 ...}]}.</li>
<li>{Typename, Attribute1, Attribute2 ...}.</li>
<li>{Typename, Attribute1, Attribute2 ...}.
Options是{Key,Value}list，和mnesia:create_table/2的options一致
例如我们有一个healthy foods的数据库，有下面的文件FRUITS：</li>
<li>{tables,</li>
<li>[{fruit, [{attributes, [name, color, taste]}]},</li>
<li>{vegetable, [{attributes, [name, color, taste, price]}]}</li>
<li>]}.</li>
<li>{fruit, orange, orange, sweet}.</li>
<li>{fruit, apple, green, sweet}.</li>
<li>{vegetable, carrot, orange, carrotish, 2.55}.</li>
<li>{vegetable, potato, yellow, none, 0.45}.
我们可以这样来加载fruits数据库：</li>
<li>1&gt; mnesia:load_textfile(&quot;FRUITS&quot;).</li>
<li>New table fruit</li>
<li>New table vegetable</li>
<li>{atomic, ok}</li>
<li>2&gt; mnesia:info().</li>
<li>---&gt; Processes holding locks &lt;---</li>
<li>---&gt; Processes waiting for locks &lt;---</li>
<li>---&gt; Pending (remote) transactions &lt;---</li>
<li>---&gt; Active (local) transactions &lt;---</li>
<li>---&gt; Uncertain transactions &lt;---</li>
<li>---&gt; Active tables &lt;---</li>
<li>vegetable : with 2 records occuping 299 words of mem</li>
<li>fruit : with 2 records occuping 291 words of mem</li>
<li>schema : with 3 records occuping 401 words of mem</li>
<li>===&gt; System info in version &quot;1.1&quot;, debug level = none &lt;===</li>
<li>opt disc. Directory &quot;/var/tmp/Mnesia.nonode@nohost&quot; is used.</li>
<li>use fallback at restart = false</li>
<li>running db nodes = [nonode@nohost]</li>
<li>stopped db nodes = []</li>
<li>remote = []</li>
<li>ram copies = [fruit,vegetable]</li>
<li>disc copies = [schema]</li>
<li>disc only copies = []</li>
<li>[fnonode@nohost,disc copiesg] = [schema]</li>
<li>[fnonode@nohost,ram copiesg] = [fruit,vegetable]</li>
<li>3 transactions committed, 0 aborted, 0 restarted, 2 logged to disc</li>
<li>0 held locks, 0 in queue; 0 local transactions, 0 remote</li>
<li>0 transactions waits for other nodes: []</li>
<li>ok</li>
</ol>
<p>-mnesia dc_dump_limit 400
-mnesia dump_log_time_threshold 90000
-mnesia dump_log_write_threshold 150000
<a href="http://www.tuicool.com/articles/rIBbqa">http://www.tuicool.com/articles/rIBbqa</a></p>
<p>当我们启动Mnesia的时候，一个名为LATEST.LOG的文件被创建并且放在数据库目录内。
这个文件被Mnesia用来对基于磁盘的事务做日志。这包括所有在存储类型为disc_copies或disc_only_copies的表中至少写入一条记录的事务。还包括对模式本身所作的全部操作，如创建新表等。
Mnesia的不同实现的日志格式可能有变化。当前实现的Mnesia是标准库模块disc_log。
日志文件会持续增长，因此需要定期转储。对于Mnesia“ ” 转储日志文件 意味着执行在日志中列出的所有操作并且将记录存放到对应的.DAT、.DCD和.DCL  “ 文件中。例如，如果 写记录{foo, 4,elvis, 6}” 操作被列入日志，Mnesia插入此操作到foo.DCL中，随后在Mnesia认为.DCL文件已经变得太大时，再将数据移入.DCD文件。如果日志很大，转储操作可能非常耗时。因此，理解Mesia系统在日志转储期间要持续运转是很重要的。
在默认状态下，只要日志中写入了100条记录或者过去了3分钟这两种情况之一出现，Mnesia即转储日志。
可用两个应用程序参数-mnesia dump_log_write_threshold WriteOperations和-mnesiadump_log_time_threshold MilliSecs来对此进行控制。
在日志被转储之前，文件LATEST.LOG改名为PREVIOUS.LOG，并且创建一个新的LATEST.LOG文件。日志转储成功后，文件PREVIOUS.LOG被删除。在启动时以及每当一个模式操作被执行时，也要转储日志。</p>
<div style="break-before: page; page-break-before: always;"></div><p>ETS基础
ETS查询时间是常量,例外是如果使用ordered_set查询时间与logN成正比(N为存储的数据量)
ETS Table由进程创建,进程销毁ETS Table也随着销毁,在使用Shell做ETS实验的时候要注意一下,Table的拥有关系可以give_away 转交给其它进程
一个Erlang节点的ETS表的数量是有限制的,默认是1400个表,在启动erlang节点之前修改 ERL_MAX_ETS_TABLES参数可以修改这个限制ejabberd社区站点上总结的性能调优中提到了这一点,点击这里查看:
<a href="http://www.ejabberd.im/tuning">http://www.ejabberd.im/tuning</a>
ETS表不在GC的管理范围内，除非拥有它的进程死掉它才会终止；可以通过delete删除数据
目前版本,insert和lookup操作都会导致对象副本的创建,insert和lookup时间对于set bag duplicate_bag都是常量值与表大小无关.
并发控制：所有针对一个对象的更新都被保证是原子的、隔离的：修改要么全部成功要么失败。也没有其它的中间结果被其它的进程使用。有些方法可以在处理多个对象的时候保证这种原子性和隔离性。
在数据库术语中隔离级别被称作序列化，就好像所有隔离的操作一个接一个严格按照顺序执行。
在遍历过程中,可以使用safe_fixtable来保证遍历过程中不出现错误,所有数据项只被访问一遍.用到逐一遍历的场景就很少，使用safe_fixtable的情景就更少。不过这个机制是非常有用的，还记得在.net中版本中很麻烦的一件事情就是遍历在线玩家用户列表.由于玩家登录退出的变化,这里的异常几乎是不可避免的.select match内部实现的时候都会使用safe_fixtable</p>
<p>set,ordered_set,bag,duplicate_bag 指定创建的table类型
public,private,protected 指定table的访问权限，若是public表示所有process都可以对该table进行读写(只要你知道TableId或者TableName)，private表示只有创建表的process才能对table进行读写，而protected则表示所有的process都可以对表进行读取，但是只有创建表的process能够对表进行写操作（ps: ets table仅可以被同一个erlang node中的processes共享）
named_table 若指定了named_table这个属性，就可以使用表名(也就是new函数的第一个参数Name)对表进行操作，而无需使用TableId
{keypos,Pos} 上面说到，我们默认使用tuple中第一个元素作为Key，那么是否可以修改这个规则呢？自然可以，使用{keypos,Pos}即可，其中Pos就是表示使用tuple中第几个元素作为Key
{heir, Pid, HeirData},{heir,none} 这个heir属性指明当创建table的process终止时，是否有其他process来继承这个table，默认值是{heir,none},表示没有继承者，所以当创建表的process终止时，表也随之被delete；若我们指定了{heir,Pid,HeirData}，那么当创建表的process终止时，process identifer为Pid的process将会收到一个消息：{'ETS-TRANSFER',tid(),FromPid,HeirData},这样表的拥有权就转交了，我们可以看下面这段测试代码</p>
<p>match(Tab, Pattern, Limit) -&gt; {[Match],Continuation} | '$end_of_table'
match(Continuation) -&gt; {[Match],Continuation} | '$end_of_table'
match_object(Tab, Pattern, Limit) -&gt; {[Match],Continuation} | '$end_of_table'
match_object(Continuation) -&gt; {[Match],Continuation} | '$end_of_table'<br />
select(Tab, MatchSpec, Limit) -&gt; {[Match],Continuation} | '$end_of_table'
select(Continuation) -&gt; {[Match],Continuation} | '$end_of_table'
ets:all()
列出所有的ETS Table<br />
ets:i()
给出一个ETS Table的清单 包含表的类型,数据量,使用内存,所有者信息
ets:i(zen_ets)
输出zen_ets表的数据
ets:info(zen_ets)
单独查看一个ETS Table的详细信息
表被锁了可以使用ets:info(zen_ets,fixed)查看,
看表里面是否存在键值为Key的数据项.
ets:fun2ms
ets:fun2ms( fun( {Name, Country, Job} ) when Job /= cook -&gt; [Country, Name] end ).
[{{'$1','$2','$3'}, [{'/=','$3',cook}], [['$2','$1']]}]</p>
<p>ets:fun2ms( fun( #table{ name=N, id= Id } ) when N &gt; 1000 -&gt; ['$$'] end )
include_lib(&quot;stdlib/include/ms_transform.hrl&quot;).
Match specifications的详细说明参见这里: http://www.erlang.org/doc/apps/erts/match_spec.html<br />
MS = ets:fun2ms(fun({ Name,Country , Position }  ) when Position /=cook -&gt; [Country,Name ] end   )<br />
new(Name, Options)
Option =
Type = set | ordered_set | bag | duplicate_bag
| Access = public | protected | private
| named_table
| {keypos, Pos}
| {heir, Pid :: pid(), HeirData::term()}
| {heir, none}
| Tweaks = {write_concurrency, boolean()} | {read_concurrency, boolean()} | compressed
ets:insert(Table, Value)
ets:lookup(Table, Key)
ets:delete(Table, Key)
ets:member(Tab, Key)
select_count()
MS2=ets:fun2ms(fun(T={A,B,C}) when B=:=&quot;hi&quot; -&gt; true end).
Count2 = ets:select_count(task_table,MS2).
['$$']||['$_']</p>
<p>A Study of Erlang ETS Table Implementation and Performance</p>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-erlang">select(Name, MatchSpec, N)
dets:delete_all_objects(Name)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>dump_log_time_threshold %转储间隔次数
dump_log_write_threshold %转储次数
dc_dump_limit %出发dump的默认值，当filesize(<em>.DCL) &gt; filesize(</em>.DCD) / dc_dump_limit，把*.DCL的记录存储到*.DCD文件中</p>
<p>application:set_env( mnesia, dc_dump_limit, 40 ),
application:set_env( mnesia, dump_log_write_threshold, 10000 ),</p>
<p>mnesia在频繁操作数据的过程可能会报错：<strong>WARNING</strong> Mnesia is overloaded: {dump_log, write_threshold}，可以看出，mnesia应该是过载了。这个警告在mnesia dump操作会发生这个问题，表类型为disc_only_copies 、disc_copies都可能会发生。
如何重现这个问题，例子的场景是多个进程同时在不断地mnesia:dirty_write/2
mnesia过载分析
1、抛出警告是在mnesia 增加dump worker的时候</p>
<pre><code> mnesia_controller.erl
</code></pre>
<p>抛出警告是当Worker的#dump_log.opt_reply_to 未定义，仔细看这里的代码，这一步先检查了dumper_queue里的worker
所以，mnesia抛出过载警告有2个条件：
1）当worker的#dump_log.opt_reply_to 未定义
2）dumper_queue有相同操作（InitBy）的worker</p>
<p>2、那什么样的worker的#dump_log.opt_reply_to 未定义？</p>
<p>代码也在mnesia_controller.erl，这里add的worker的dump_log.opt_reply_to 未定义，而{async_dump_log, InitBy} 就是 mnesia:dirty_write/2的过程中调用 mnesia_controller:async_dump_log(write_threshold) 产生的。</p>
<p>就是说，mnesia:dirty_write/2会触发异步dump操作，而只有异步的dump会导致mnesia抛出过载警告</p>
<p>3、看一下，mnesia什么时候会修正worker？</p>
<p>代码也在mnesia_controller.erl，在dump完成时，mnesia会修改worker的dump_log.opt_reply_to，然后移出dumper_queue</p>
<p>从上面可以得到结论，mnesia:dirty_write/2的操作是会触发异步dump操作，每次dump操作mnesia都会加到dumper_queue队列，mnesia通过检查dumper_queue是否存有相同操作的worker来检查是否过载
mnesia dump分析
mnesia数据存储实际上使用的是ets和dets，对于ram_copies类型的表使用ets；disc_copies表也使用ets，通过 dump将数据保存到*.DCD（disc copy data）文件来持久化，中间可能会用*.DCL（disc copy log）转储；而disc_only_copies表使用的是dets，保存的文件为*.DAT。
表类型不同，mnesia记录数据的过程也不同，这里先讨论mnesia 记录disc_copies数据的过程。
1、mnesia 记录disc_copies数据有2个过程：
1）操作先记录到日志文件LATEST.LOG，然后再dump到*.DCD文件，同时清除LATEST.LOG
2）把修改同步到ets表中
2、mnesia disc_copies表数据dump过程
1）将日志文件LATEST.LOG重命名为PREVIOUS.LOG，然后再新建一个空的日志文件LATEST.LOG
2）分析PREVIOUS.LOG文件中的内容，将disc_copies的表实际修改写到*.DCL文件
3）比较*.DCL和*.DCD的大小，当filesize(<em>.DCL) &gt; filesize(</em>.DCD) / dc_dump_limit，把*.DCL的记录存储到*.DCD文件中。dc_dump_limit默认为4，可以通过-mnesia dc_dump_limit Number设置
3、mnesia什么时候会dump
1）定时触发
mnesia启动后，mnesia_controller进程设置定时器，触发dump
mnesia_controller.erl:</p>
<p>默认值为180000，可以通过 -mnesia dump_log_time_threshold 300000 设置。
2）一定次数的操作后触发
每次数据操作，mnesia都会调用mnesia_log:log/1或者mnesia_log:slog/1进行日志记录，记录一次日志就将trans_log_writes_left的值减1，当这个值为0时，触发dump
mnesia_log.erl:</p>
<p>mnesia_dumper.erl</p>
<p>默认值为1000，可以通过 -mnesia dump_log_write_threshold 50000 设置。
3）手动dump
手动调用 mnesia:dump_log/0  可以强制mnesia 完成dump，而这个dump是同步的
mnesia.erl:</p>
<p>mnesia_controller.erl:</p>
<p>解决mnesia过载
结合上面的分析再谈谈mnesia过载问题，dict_copies表写数据的时候，mnesia会写记录到ets表和日志文件 LATEST.LOG，然后定时或定量dump做持久化。通过dump_log_write_threshold /dump_log_time_threshold 可以控制持久化的频率。mnesia在dump数据的时候，如果上一个worker进程dump没完成，就抛出过载警告。对 此，dump_log_write_threshold的值表示mnesia经历过多少数据操作做一次持久 化，dump_log_time_threshold的值表示mnesia多长时间做一次持久化。</p>
<p>这里再谈谈，为何同一时间只能有一个dumper？</p>
<p>dump的过程是先将日志文件重命名为PREVIOUS.LOG，然后分析PREVIOUS.LOG的数据做持久化，如果同时有第二个dump，将 会替换掉第一个dump的PREVIOUS.LOG，影响第一个dump的持久化。那么，聪明的你就会这么想，为何不重命名为XXX.LOG，每次重命名 都不同？事实上，如果同时有两个dumper，mnesia仅保证第二个dump能正常进行，放弃掉第一个dump的数据。所以，mnesia出现过载警告的时候，数据有可能会丢失。</p>
<p>这里，我做过了一项测试，修改mnesia的代码，将所有异步dump去掉，改用定时手动dump。还是原来的例子，发现第一个dump还没完成日志文件的分析和持久化，而新的日志文件已经增长到快2G。</p>
<p>dump的过程在文件io层面上其实是，一边在没有控制的追加数据，一边又在分析文件和有序写入，这个过程是在挑战磁盘io的读写极限啊。所以，就算现在有多个dumper，结果只会让cpu和硬盘更加抓狂。</p>
<p>另外，别太过依赖dump_log_write_threshold/dump_log_time_threshold这两个参数，改大了就有用吗？</p>
<p>这两个参数改大了，就是说，dump的频率就会降低，那么等待dump的数据就会更多，dump花的时间将会越长，到头来还是不能解决到问题。这两 个参数的意义在于平缓写入速度，避免一时间大量数据写入造成数据丢失。但是，如果每时每刻都是高密度写入，硬盘也承受不了，一般到了这个局面，问题应该从 数据缓冲和持久化的设计上去解决，而不是想着换一个数据库去解决。</p>
<p>这里有一点经验可以分享一下：
1、在mnesia没报过载错误的时候，不建议去改动，调节这些参数会影响持久化
2、可以多个进程读mnesia的数据，但写数据的过程只交给少数几个进程去完成
参考：
<a href="http://blog.csdn.net/mycwq/article/details/28660813">http://blog.csdn.net/mycwq/article/details/28660813</a>
<a href="http://my.oschina.net/hncscwc/blog/161763">http://my.oschina.net/hncscwc/blog/161763</a></p>
<p>来自 <a href="http://blog.csdn.net/mycwq/article/details/28660813?utm_source=tuicool">http://blog.csdn.net/mycwq/article/details/28660813?utm_source=tuicool</a></p>
<div style="break-before: page; page-break-before: always;"></div><p>官方网站：redis.io</p>
<p>中文翻译网站：<a href="http://www.redis.cn">http://www.redis.cn</a>
<a href="http://doc.redisfans.com/index.html">http://doc.redisfans.com/index.html</a></p>
<p>make MALLOC=libc</p>
<p>客户端工具
<a href="http://redisdesktop.com/download">http://redisdesktop.com/download</a></p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><pre><code class="language-redis">keys *
Keys invite*
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>配置 值
daemonize no 是否后台启动
yes
requirepass foobared 登录密码
appendfsync no 当设置appendfsync为no的时候，Redis不会主动调用fsync去将AOF日志内容同步到磁盘，所以这一切就完全依赖于操作系统的调试了。对大多数Linux操作系统，是每30秒进行一次fsync，将缓冲区中的数据写到磁盘上
当设置appendfsync为everysec的时候，Redis会默认每隔一秒进行一次fsync调用，将缓冲区中的数据写到磁盘。但是当这一 次的fsync调用时长超过1秒时。Redis会采取延迟fsync的策略，再等一秒钟。也就是在两秒后再进行fsync，这一次的fsync就不管会执行多长时间都会进行。这时候由于在fsync时文件描述符会被阻塞，所以当前的写操作就会阻塞。
当设置appendfsync为always时，每一次写操作都会调用一次fsync，这时数据是最安全的，当然，由于每次都会执行fsync，所以其性能也会受到影响。
appendonly yes</p>
<p>开机启动</p>
<p>redis_init_script 位于位于Redis的 /utils/ 目录下</p>
<pre><code class="language-bash"># 大致浏览下该启动脚本，发现redis习惯性用监听的端口名作为配置文件等命名，我们后面也遵循这个约定。
# redis服务器监听的端口
REDISPORT=6379
# 服务端所处位置，在make install后默认存放与`/usr/local/bin/redis-server`，如果未make install则需要修改该路径，下同。
EXEC=/usr/local/bin/redis-server
# 客户端位置
CLIEXEC=/usr/local/bin/redis-cli
# Redis的PID文件位置
PIDFILE=/var/run/redis_${REDISPORT}.pid
# 配置文件位置，需要修改
CONF=&quot;/etc/redis/${REDISPORT}.conf&quot;

1. 根据启动脚本要求，将修改好的配置文件以端口为名复制一份到指定目录。需使用root用户。
mkdir /etc/redis

cp redis.conf /etc/redis/6379.conf

 2. 将启动脚本复制到/etc/init.d目录下，本例将启动脚本命名为redisd（通常都以d结尾表示是后台自启动服务）。
cp redis_init_script /etc/init.d/redisd
 3. 设置为开机自启动
update-rc.d redis-server defaults %设置开机自动启动，关机自动关闭
update-rc.d redisd defaults

/etc/init.d/redisd start
</code></pre>
<p>主从备份
主机开启</p>
<p>重机conf
slaveof 127.0.0.1 5672
masterauth 123456</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="with"><a class="header" href="#with">WITH</a></h2>
<pre><code class="language-sql">
-- WITH
WITH ali AS (SELECT * FROM rpt_kh_amount_conf)
SELECT ali.val FROM ali


</code></pre>
<h2 id="not-exists"><a class="header" href="#not-exists">NOT EXISTS</a></h2>
<pre><code class="language-sql">SELECT
  *
FROM
  `account` a1
WHERE a1.deleted = 0
  AND a1.status = 1
  AND a1.created_time &gt;= '2021-08-16 14:10:31' AND NOT EXISTS
  (SELECT
    1
  FROM
    account a2
  WHERE a2.uid = a1.uid
    AND a2.deleted = 0
    AND a2.created_time &lt; '2021-08-16 14:10:31')
</code></pre>
<h2 id="json"><a class="header" href="#json">JSON</a></h2>
<pre><code class="language-sql">SELECT
    JSON_EXTRACT(CHARGE_DATA, &quot;$[0].amount&quot;) as '取值',
    json_valid(&quot;$[0].amount&quot;) as 'path 类型',
    JSON_SEARCH(CHARGE_DATA, 'one', 'FRET'), 'chargeTypeCd', 'amount') as 'json search',
    json_valid(select 'json search') as 'json search path 类型',
    
    JSON_CONTAINS_PATH(CHARGE_DATA, 'one',&quot;$[0].amount&quot;) as '是否包含',

    JSON_VALID(json_UNquote(REPLACE(JSON_SEARCH(CHARGE_DATA, 'one', 'FRET'), 'chargeTypeCd', 'amount'))) as a,
    
    JSON_EXTRACT(CHARGE_DATA, json_UNquote(REPLACE(JSON_SEARCH(CHARGE_DATA, 'one', 'FRET'), 'chargeTypeCd', 'amount'))) as '基础运费'

</code></pre>
<h2 id="不常用命令"><a class="header" href="#不常用命令">不常用命令</a></h2>
<pre><code class="language-sql">#表
SHOW TABLES;#获取表
SHOW COLUMNS FROM `file`; #获取列基础信息
DESCRIBE `file`;#获取列
SHOW FULL COLUMNS FROM `file`;#获取列所有信息


#编码
SELECT * FROM information_schema.SCHEMATA; #库的编码
SELECT * FROM information_schema.tables WHERE table_schema = 'party_2';#表的信息
SELECT * FROM information_schema.columns WHERE TABLE_SCHEMA='party_2'; #列的信息


#配置
SHOW STATUS;#获取状态配置信息
SHOW VARIABLES LIKE 'default_%'
SHOW VARIABLES LIKE 'log_%'; 


#日志
SHOW MASTER LOGS; #获取bin日志
SHOW MASTER STATUS;#日志状态
SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [OFFSET,] ROW_COUNT];
SHOW BINLOG EVENTS IN 'mysql-bin.000001' LIMIT 0, 1000;#日志文件内容
FLUSH LOGS;#自此刻开始产生一个新编号的binlog日志文件
PURGE MASTER LOGS TO 'MySQL-bin.010'; #清除MySQL-bin.010日志
PURGE MASTER LOGS BEFORE '2008-06-22 13:00:00'; #清除2008-06-22 13:00:00前binlog日志
PURGE MASTER LOGS BEFORE DATE_SUB( NOW( ), INTERVAL 3 DAY); #清除3天前binlog日志BEFORE，变量的date自变量可以为'YYYY-MM-DD hh:mm:ss'格式。
RESET MASTER;#清空日志文件
mysqlbinlog /usr/LOCAL/mysql/DATA/mysql-bin.000001 #查看日志
mysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名 #还原数据
常用选项：
          --start-POSITION=953                   起始pos点
          --stop-POSITION=1437                   结束pos点
          --start-DATETIME=&quot;2013-11-29 13:18:54&quot; 起始时间点
          --stop-DATETIME=&quot;2013-11-29 13:21:53&quot;  结束时间点
          --database=zyyshop                     指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)
          

#主从

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-sql">-- 1.SELECT
order by 字段 asc或desc（即升级或降序）
SELECT * FROM attr -- 选择整张表的数据
SELECT uid FROM `attr` WHERE uid &gt;= 163 LIMIT 5, 1; -- 从attr表选择uid字段，并且uid&gt;163, LIMIT从第几行还是选择多少行
SELECT uid FROM `attr` WHERE uid &gt;= 163 LIMIT 0, 1, -- 选取从0开始，选取一行数据
SELECT* FROM Table WHERE 字段 LIKE '%702%';
[&quot;SELECT NAME FROM yj_dynamic1.attr where name='&quot;, &lt;&lt;229,188,160,230,181,169,232,141,161&gt;&gt;, &quot;'&quot;]
CALL select_vip(id)
SELECT DISTINCT 列名称 FROM 表名称  去重
FIND_IN_SET( Str, StrList ) -&gt; 返回Str在StrList中的第几位，没有返回0
1.1去重 DISTINCT  SELECT DISTINCT uid FROM task
1.2多条件查找
SELECT COUNT(uid) FROM `rmb_info` WHERE TIME &gt;=1383632065 AND TIME &lt;1383632067 AND 0=(SELECT COUNT(*) FROM `rmb_info` WHERE uid=uid AND TIME &lt;1383632065);
 select 学号,班级,姓名,学科,成绩
 from 学生
 where 学号 in
 (
  select top 10 学号
  from 学生
  where 学科='语文'
  order by 成绩 desc
 )and 学号 not in
 (
  select top 10 学号
  from 学生
  where 学科='数学'
  order by 成绩 asc
 )
1.2.多表查询.
       SELECT a.uid FROM `aa` AS a, `attr` AS b WHERE b.lv &gt;= 5 AND b.uid &gt; 162 AND b.uid = a.`roleId` GROUP BY a.uid;
1.2 多库查询
 SELECT a.uid FROM `server1`.`attr` AS a, `server2`.`attr` AS b
   WHERE b.lv &gt;= 5 AND b.uid &gt; 162 AND b.uid = a.`roleId`
   GROUP BY a.uid
 UNION SELECT a.uid FROM `hyw`.`aa` AS a, `hyw`.`attr` AS b
   WHERE b.lv &gt;= 5 AND b.uid &gt; 162 AND b.uid = a.`roleId`
   GROUP BY a.uid
1.3 SELECT uid,SUM(IF(num&gt;0, num, 0)) AS a, SUM(IF(num&lt;0, num, 0)) AS b FROM rmb_cost GROUP BY uid HAVING a &lt; -b

select `name` from item_prop where `name` in (select `name` from item_prop group by `name` having count(`name`) &gt; 1);

-- 2.INSERT,设置主键自增
INSERT INTO 表名称 VALUES (值1, 值2,....)
INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....)
INSERT INTO yj_dynamic.activity_task(uid,tableId,state,num,completeNum) SELECT 2,tableId,state,num,completeNum FROM yj_dynamic1.activity_task WHERE uid=1

replace into 跟 insert 功能类似，不同点在于：replace into 首先尝试插入数据到表中，

/*
1. 如果发现表中已经有此行数据（根据主键或者唯一索引判断）则先删除此行数据，然后插入新的数据。
2. 否则，直接插入新数据。
要注意的是：插入数据的表必须有主键或者是唯一索引！否则的话，replace into 会直接插入数据，这将导致表中出现重复的数据。
*/
INSERT INTO `day_online_time`(`date`,`uid`,`platformId`,`time`,logincount) VALUES (1399564800,163,1,12369,logincount+1) ON DUPLICATE KEY UPDATE
TIME=13000, logincount=logincount+1 ;
ON DUPLICATE KEY UPDATE  MySQL 当记录不存在时插入，当记录存在时更新

-- 3.UPDATE
UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值
UPDATE fun_open SET funList=CONCAT(funList, '11000')
WHERE uid IN (SELECT DISTINCT uid FROM task WHERE tableId=102100 AND state=3 AND 0=FIND_IN_SET('11000',funList))
UPDATE fun_open SET funList = REPLACE(funList, '10400', '') WHERE uid IN (SELECT uid FROM attr WHERE lv&lt;28)
Update A,B Set B.Name=A.Name, B.age='12' Where A.Id=B.Id;
Update A Inner Join B On A.Id=B.Id Set B.Name=A.Name;

-- 4.DELETE
DELETE FROM 表名称 WHERE 列名称 = 值
根据某个字段去重（推荐使用临时表,不重复的数据导入到一张表）
delete from 表 where 主键ID not in(select max(主键ID) from 表 group by 需要去重的字段 having count(需要去重的字段)&gt;=1）


关键字 例 
 Group by 1.SELECT  
   DATE_FORMAT(FROM_UNIXTIME(`time`), '%Y%m%d') dayTime,
   SUM(win) AS win_count
 FROM
   game_info 
 WHERE `time` &gt;= 1460217600 
   AND `time` &lt; 1462204800 
 GROUP BY dayTime ;
In select count(*) from user where stats_time='2012-11-25' and 
 id in (select id from user where stats_time='2012-11-24' and type=1)
datediff select A.user,A.stats_time from user A, user B where A.userid = B.userid and B.type=1 and datediff(A.stats_time, B.stats_time)=1 
EXPLAIN  
CONCAT UPDATE ai SET icon = CONCAT('http://dz.game2us.com/head/', icon) 
REPLACE UPDATE ai SET icon = REPLACE(icon, '/head/../head', '/head') 
最大連接數 SHOW VARIABLES LIKE 'max_connections'; 
模糊查询 SHOW VARIABLES LIKE '%connections'; 
 SHOW STATUS; 
设置最大连接数 SET GLOBAL max_connections=1024; 
获取所有建立的连接 SHOW FULL PROCESSLIST 
 utf8mb4 移动端的表情占用4字节。需要设置成utf8的扩展字符 
 COALESCE 
  

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="cnf"><a class="header" href="#cnf">cnf</a></h2>
<pre><code class="language-config">
[mysqld]
port            = 63099         #端口
max_connections = 1024          #最大连接数量

default-storage-engine=INNODB
character-set-server=utf8mb4
collation-server = utf8mb4_unicode_ci

slow_query_log = on   #开启慢查询日志
long_query_time=3   #3秒以上
#slow-query-log-file = /home/db/madb/log/slow-query.log


default-authentication-plugin=mysql_native_password


table_open_cache=2000 #表文件句柄缓存（表数据是存储在磁盘上的，缓存磁盘文件的句柄方便打开文件读取数据）
key_buffer_size=8388608 #索引缓存大小（将从磁盘上读取的索引缓存到内存，可以设置大一些，有利于快速检索）
innodb_buffer_pool_size=8388608 #Innodb存储引擎缓存池大小（对于Innodb来说最重要的一个配置，如果所有的表用的都是Innodb，那么甚至建议将该值设置到物理内存的80%，Innodb的很多性能提升如索引都是依靠这个）


# 客户端来源数据的默认字符集
[client]
default-character-set = utf8mb4

# 数据库默认字符集
[mysql]
default-character-set = utf8mb4


#主从
server-id=1
log-bin=mysql-bin

log-slave-updates=ON
auto-increment-increment       = 10
auto-increment-offset          = 1
binlog-do-db=game_d_1,game_log_1,game_s_1,game_user,ontology,ontology_d_1,ontology_log_1,ontology_s_1
replicate-do-db=game_d_1,game_log_1,game_s_1,game_user,ontology,ontology_d_1,ontology_log_1,ontology_s_1


[master sql]
SHOW VARIABLES LIKE '%log_bin%';
SHOW MASTER STATUS;
GRANT FILE ON *.* TO 'repl_user'@'10.105.240.11' IDENTIFIED BY '8183ab0a79ed8461e15352832e91F5_#';
GRANT REPLICATION SLAVE ON *.* TO 'repl_user'@'10.105.240.11' IDENTIFIED BY '8183ab0a79ed8461e15352832e91F5_#';

/*start slave*/
STOP SLAVE;
SHOW SLAVE STATUS
CHANGE MASTER TO MASTER_HOST='10.105.240.11',MASTER_PORT=27199,MASTER_USER='repl_user',MASTER_PASSWORD='8183ab0a79ed8461e15352832e91F5_#',MASTER_LOG_FILE='mysql-bin.000021',MASTER_LOG_POS=11288354;
SLAVE START;


[slave sql]
/*start master*/
SHOW VARIABLES LIKE '%log_bin%';
SHOW MASTER STATUS;
GRANT FILE ON *.* TO 'repl_user'@'10.105.19.157' IDENTIFIED BY '8183ab0a79ed8461e15352832e91F5_#';
GRANT REPLICATION SLAVE ON *.* TO 'repl_user'@'10.105.19.157' IDENTIFIED BY '8183ab0a79ed8461e15352832e91F5_#';

/*start slave*/
STOP SLAVE;
RESET SLAVE;
SHOW SLAVE STATUS;
CHANGE MASTER TO MASTER_HOST='10.105.19.157',MASTER_PORT=27199,MASTER_USER='repl_user',MASTER_PASSWORD='8183ab0a79ed8461e15352832e91F5_#',MASTER_LOG_FILE='mysql-bin.000022',MASTER_LOG_POS=154;
START SLAVE;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="日志"><a class="header" href="#日志">日志</a></h2>
<pre><code class="language-config">[mysqld]
skip-log-bin
</code></pre>
<pre><code class="language-sql">
#日志
SHOW MASTER LOGS; #获取bin日志
SHOW MASTER STATUS;#日志状态

SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [OFFSET,] ROW_COUNT];
SHOW BINLOG EVENTS IN 'mysql-bin.000001' LIMIT 0, 1000;#日志文件内容

FLUSH LOGS;#自此刻开始产生一个新编号的binlog日志文件
PURGE MASTER LOGS TO 'MySQL-bin.010'; #清除MySQL-bin.010日志
PURGE MASTER LOGS BEFORE '2008-06-22 13:00:00'; #清除2008-06-22 13:00:00前binlog日志
PURGE MASTER LOGS BEFORE DATE_SUB( NOW( ), INTERVAL 3 DAY); #清除3天前binlog日志BEFORE，变量的date自变量可以为'YYYY-MM-DD hh:mm:ss'格式。

RESET MASTER;#清空日志文件

mysqlbinlog /usr/LOCAL/mysql/DATA/mysql-bin.000001 #查看日志
mysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名 #还原数据

常用选项：
          --start-POSITION=953                   起始pos点
          --stop-POSITION=1437                   结束pos点
          --start-DATETIME=&quot;2013-11-29 13:18:54&quot; 起始时间点
          --stop-DATETIME=&quot;2013-11-29 13:21:53&quot;  结束时间点
          --database=zyyshop                     指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)
          

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="主从"><a class="header" href="#主从">主从</a></h2>
<p>修改/etc/my.cnf，实现主主配置。
如果不存在/etc/my.cnf，则复制support-files/my-default.cnf生成my.cnf，两台机器的my.cnf分别配置为（不难看到，只有server_id和auto_increment_increment两项不同）：
机器A 机器B
server-id=1 server-id=2
user=mysql user=mysql
log-bin=mysql-bin log-bin=mysql-bin
log-slave-updates log-slave-updates
slave-skip-errors=all slave-skip-errors=all
sync_binlog=1 sync_binlog=1
auto_increment_increment=1 auto_increment_increment=2
auto_increment_offset=1 auto_increment_offset=1</p>
<p>配置项 配置项说明
server-id 不能相同！唯一标识号，值位于1~2^32-1之间
user 这个可以不指定，则使用mysqld_safe指定的用户，或者mysqld_safe默认的用户mysql
log-bin 启用二进制日志文件
log-slave-updates 配置从库上的更新操作是否写二进制文件，需要和log-bin一起使用
slave-skip-errors 值为all表示让从库跳过所有错误（但不能跳过所有DDL所引起的主从错误），也可以只跳过指定的错误，如：--slave-skip-errors=1062,1053；也可以配置只跳过DDL错误，如：--slave-skip-errors=ddl_exist_errors，这等同于：
--slave-skip-errors=1007,1008,1050,1051,1054,1060,1061,1068,1094,1146
sync_binlog 值为1表示主机每次提交事务的时候把二进制日志的内容同步到磁盘上
auto_increment_increment 和auto_increment_offset一起用于主主同步，用来错开自增，防止键值冲突，所以auto_increment_increment和auto_increment_offset两者，至少要有一项值不同。
auto_increment_offset</p>
<p>上述配置会导致同步所有的数据库，借助下列配置项也可以选择性的同步或不同步：
配置项 配置项说明
binlog-do-db=test1 表示只同步数据库test1和test2，如果还想同步test3，只需要新增一行：binlog-do-db=test3即可
binlog-do-db=test2
binlog-ignore-db=db1 表示不同步数据库db1和db2，如果还有db3不想同步，新增一行：binlog-ignore-db=db3即可
binlog-ignore-db=db2</p>
<p>相关配置项（对于主从同步，只需要在从上配置）：replicate-do-db、replicate-ignore-db、replicate_wild_do_table和replicate_wild_ignore_table。</p>
<p>来自 <a href="http://blog.csdn.net/Aquester/article/details/50674140">http://blog.csdn.net/Aquester/article/details/50674140</a></p>
<p>master
vim /etc/my.cnf
server-id=1
log_bin=mysql-bin
log_slave-updates</p>
<p>GRANT FILE ON <em>.</em> TO 'repl_user'@'10.105.240.11' IDENTIFIED BY '8183ab0a79ed8461e15352832e91F5_#';
GRANT REPLICATION SLAVE ON <em>.</em> TO 'repl_user'@'10.105.240.11' IDENTIFIED BY '8183ab0a79ed8461e15352832e91F5_#';</p>
<p>SHOW VARIABLES LIKE '%log_bin%';
SHOW MASTER STATUS;</p>
<p>slave
stop slave;</p>
<p>show slave status</p>
<p>change master to master_host='10.105.19.157',master_port=27199,master_user='repl_user',master_password='8183ab0a79ed8461e15352832e91F5_#',master_log_file='mysql-bin.000021',master_log_pos=11288354;</p>
<p>START SLAVE;</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="存储引擎"><a class="header" href="#存储引擎">存储引擎</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">特点</th><th style="text-align: left">Myisam</th><th style="text-align: left">BDB</th><th style="text-align: left">Memory</th><th style="text-align: left">InnoDB</th><th style="text-align: left">Archive</th></tr></thead><tbody>
<tr><td style="text-align: left">存储限制</td><td style="text-align: left">没有</td><td style="text-align: left">没有</td><td style="text-align: left">有</td><td style="text-align: left">64TB</td><td style="text-align: left">没有</td></tr>
<tr><td style="text-align: left">事务安全</td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">锁机制</td><td style="text-align: left">表锁</td><td style="text-align: left">页锁</td><td style="text-align: left">表锁</td><td style="text-align: left">行锁</td><td style="text-align: left">行锁</td></tr>
<tr><td style="text-align: left">B树索引</td><td style="text-align: left">支持</td><td style="text-align: left">支持</td><td style="text-align: left">支持</td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">哈希索引</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">全文索引</td><td style="text-align: left">支持</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">集群索引</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">数据缓存</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">索引缓存</td><td style="text-align: left">支持</td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">数据可压缩</td><td style="text-align: left">支持</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">支持</td></tr>
<tr><td style="text-align: left">空间使用</td><td style="text-align: left">低</td><td style="text-align: left">低</td><td style="text-align: left">N/A</td><td style="text-align: left">高</td><td style="text-align: left">非常低</td></tr>
<tr><td style="text-align: left">内存使用</td><td style="text-align: left">低</td><td style="text-align: left">低</td><td style="text-align: left">中等</td><td style="text-align: left">高</td><td style="text-align: left">低</td></tr>
<tr><td style="text-align: left">批量插入的速度</td><td style="text-align: left">高</td><td style="text-align: left">高</td><td style="text-align: left">高</td><td style="text-align: left">低</td><td style="text-align: left">非常高</td></tr>
<tr><td style="text-align: left">支持外键</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left">支持</td><td style="text-align: left"></td></tr>
</tbody></table>
</div>
<p>最常使用的2种存储引擎：</p>
<pre><code>• Myisam是Mysql的默认存储引擎。当create创建新表时，未指定新表的存储引擎时，默认使用Myisam。每个MyISAM在磁盘上存储成三个文件。文件名都和表名相同，扩展名分别是.frm（存储表定义）、.MYD (MYData，存储数据)、.MYI (MYIndex，存储索引)。数据文件和索引文件可以放置在不同的目录，平均分布io，获得更快的速度。
• InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比Myisam的存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。
</code></pre>
<p>如何选择合适的存储引擎
选择标准：根据应用特点选择合适的存储引擎，对于复杂的应用系统可以根据实际情况选择多种存储引擎进行组合。</p>
<p>下面是常用存储引擎的适用环境：</p>
<ol>
<li>MyISAM：默认的MySQL插件式存储引擎，它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一</li>
<li>InnoDB：用于事务处理应用程序，具有众多特性，包括ACID事务支持。</li>
<li>Memory：将所有数据保存在RAM中，在需要快速查找引用和其他类似数据的环境下，可提供极快的访问。</li>
<li>Merge：允许MySQL DBA或开发人员将一系列等同的MyISAM表以逻辑方式组合在一起，并作为1个对象引用它们。对于诸如数据仓储等VLDB环境十分适合。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="安装"><a class="header" href="#安装">安装</a></h2>
<pre><code class="language-bash">
#ubuntu
wget https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm
sudo dpkg -i mysql-apt-config_0.8.6-1_all.deb
#centOS
rpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm

# 安装成功后， 提示选择版本， ubuntu18.04 默认安装8.0 &amp;nbsp;所以这里选择 8.0 &amp;nbsp;点击 ok

sudo apt update
sudo yum -y install mysql-community-server
systemctl start mysqld
sudo grep 'temporary password' /var/log/mysqld.log #密码
mysql -uroot -p
&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'a1C,_#';
&gt; CREATE USER 'root'@'%' IDENTIFIED BY '1fC_,#';
&gt; GRANT ALL ON *.* TO 'root'@'%';
&gt; GRANT ALL ON gitea.* TO 'gitea'@'localhost';

&gt; SET PASSWORD FOR 'pig'@'%' = PASSWORD(&quot;123456&quot;);
&gt; REVOKE SELECT ON *.* FROM 'pig'@'%'; #撤销权限
&gt; DROP USER 'username'@'host';

&gt; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';
&gt; flush privileges;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="msyqldump"><a class="header" href="#msyqldump">msyqldump</a></h2>
<pre><code class="language-bash"># 导出数据到文件
mysqldump -uroot -p123456 --host=127.0.0.1 --port=3306 -C --all-databases &gt; /backup/test/${DATE}.sql


# 导出数据到远程数据库
mysqldump --default-character-set=utf8mb4 --host=127.0.0.1 -uusername -ppassword --opt dbname | mysql --host=127.0.0.2 -uusernameb -ppasswordb --default-character-set=utf8mb4 -C dbnamenew
mysqldump --default-character-set=utf8mb4 --host=192.168.1.46 -P 55001 -uroot -p123456 --opt test | mysql --host=192.168.1.85 -P 55001 -uroot -p123456 --default-character-set=utf8mb4 -C test
# --opt命令可选，建议加上。等同于指定 --add-drop-tables--add-locking --create-option --disable-keys--extended-insert --lock-tables --quick --set-charset。它可以给出很快的转储操作并产生一个可以很快装入MySQL服务器的转储文件。
# -default-character-set=utf8mb4 指定该数据库连接的字符类型。如果服务器默认未utf8的话，导出的数据可能会丢失四字节的unicode信息（表情之类的）
# -C 客户端和服务器之间启用压缩传递所有信息。

# 1.备份全部数据库的数据和结构
mysqldump -uroot -p123456 -A &gt;F:\all.sql

# 2.备份全部数据库的结构（加 -d 参数）
mysqldump -uroot -p123456 -A-d&gt;F:\all_struct.sql

# 3.备份全部数据库的数据(加 -t 参数)
mysqldump -uroot -p123456 -A-t&gt;F:\all_data.sql

# 数据和结构(,数据库名mydb)
mysqldump -uroot-p123456 mydb&gt;F:\mydb.sql

# 8.一次备份多个数据库
mysqldump -uroot -p123456 --databases db1 db2&gt;f:\muldbs.sql

# 5.备份单个数据库的结构
mysqldump -uroot -p123456 mydb-d&gt;F:\mydb.sql
# 6.备份单个数据库的数据
mysqldump -uroot -p123456 mydb-t&gt;F:\mydb.sql

# 1.还原全部数据库:
(1) mysql命令行：mysql&gt;source f:\all.sql
(2) 系统命令行： mysql -uroot -p123456 &lt;f:\all.sql

# 2.还原单个数据库(需指定数据库)
(1) mysql&gt;use mydb
mysql&gt;source f:\mydb.sql
(2) mysql -uroot -p123456 mydb &lt;f:\mydb.sql

# 3.还原单个数据库的多个表(需指定数据库)
(1) mysql&gt;use mydb
mysql&gt;source f:\multables.sql
(2) mysql -uroot -p123456 mydb&lt;f:\multables.sql

# 4.还原多个数据库，（一个备份文件里有多个数据库的备份，此时不需要指定数据库）
(1) mysql命令行：mysql&gt;source f:\muldbs.sql
(2) 系统命令行： mysql -uroot -p123456&lt;f:\muldbs.sql

mysqldump --host=192.168.80.137 -uroot -proot -C --databases test |mysql --host=192.168.80.133 -uroot -proot test 


-A, --all-databases
导出全部数据库。
mysqldump  -uroot -p --all-databases

-Y, --all-tablespaces
导出全部表空间。
mysqldump  -uroot -p --all-databases --all-tablespaces

-y, --no-tablespaces
不导出任何表空间信息。
mysqldump  -uroot -p --all-databases --no-tablespaces

--add-drop-database
每个数据库创建之前添加drop数据库语句。
mysqldump  -uroot -p --all-databases --add-drop-database

--add-drop-table
每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用--skip-add-drop-table取消选项)
mysqldump  -uroot -p --all-databases  (默认添加drop语句)
mysqldump  -uroot -p --all-databases --skip-add-drop-table  (取消drop语句)
 
--add-locks
在每个表导出之前增加LOCK TABLES并且之后UNLOCK  TABLE。(默认为打开状态，使用--skip-add-locks取消选项)
mysqldump  -uroot -p --all-databases  (默认添加LOCK语句)
mysqldump  -uroot -p --all-databases --skip-add-locks   (取消LOCK语句)
 
--allow-keywords
允许创建是关键词的列名字。这由表名前缀于每个列名做到。
mysqldump  -uroot -p --all-databases --allow-keywords

--apply-slave-statements
在'CHANGE MASTER'前添加'STOP SLAVE'，并且在导出的最后添加'START SLAVE'。 
mysqldump  -uroot -p --all-databases --apply-slave-statements

--character-sets-dir
字符集文件的目录 
mysqldump  -uroot -p --all-databases  --character-sets-dir=/usr/local/mysql/share/mysql/charsets

--comments
附加注释信息。默认为打开，可以用--skip-comments取消
mysqldump  -uroot -p --all-databases  (默认记录注释)
mysqldump  -uroot -p --all-databases --skip-comments   (取消注释)
 
--compatible
导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等，
要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。
mysqldump  -uroot -p --all-databases --compatible=ansi

--compact
导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：--skip-add-drop-table  --skip-add-locks --skip-comments --skip-disable-keys
mysqldump  -uroot -p --all-databases --compact

-c,  --complete-insert
使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。
mysqldump  -uroot -p --all-databases --complete-insert

-C, --compress
在客户端和服务器之间启用压缩传递所有信息
mysqldump  -uroot -p --all-databases --compress

-a,  --create-options
在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态)
mysqldump  -uroot -p --all-databases

--databases,  -B
导出几个数据库。参数后面所有名字参量都被看作数据库名。
mysqldump  -uroot -p --databases test mysql

--debug
输出debug信息，用于调试。默认值为：d:t,/tmp/mysqldump.trace
mysqldump  -uroot -p --all-databases --debug
mysqldump  -uroot -p --all-databases --debug=” d:t,/tmp/debug.trace”

--debug-check
检查内存和打开文件使用说明并退出。
mysqldump  -uroot -p --all-databases --debug-check

--debug-info
输出调试信息并退出
mysqldump  -uroot -p --all-databases --debug-info

--default-character-set
设置默认字符集，默认值为utf8
mysqldump  -uroot -p --all-databases --default-character-set=utf8

--delayed-insert
采用延时插入方式（INSERT DELAYED）导出数据
mysqldump  -uroot -p --all-databases --delayed-insert

--delete-master-logs
master备份后删除日志. 这个参数将自动激活--master-data。
mysqldump  -uroot -p --all-databases --delete-master-logs

--disable-keys
对于每个表，用/*!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/*!40000 ALTER TABLE tbl_name ENABLE KEYS */;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。
mysqldump  -uroot -p --all-databases

--dump-slave
该选项将主的binlog位置和文件名追加到导出数据的文件中(show slave status)。设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，会在change前加上注释。该选项将会打开--lock-all-tables，除非--single-transaction被指定。该选项会自动关闭--lock-tables选项。默认值为0。
mysqldump  -uroot -p --all-databases --dump-slave=1
mysqldump  -uroot -p --all-databases --dump-slave=2

--master-data
该选项将当前服务器的binlog的位置和文件名追加到输出文件中(show master status)。如果为1，将会输出CHANGE MASTER 命令；如果为2，输出的CHANGE  MASTER命令前添加注释信息。该选项将打开--lock-all-tables 选项，除非--single-transaction也被指定（在这种情况下，全局读锁在开始导出时获得很短的时间；其他内容参考下面的--single-transaction选项）。该选项自动关闭--lock-tables选项。
mysqldump  -uroot -p --host=localhost --all-databases --master-data=1;
mysqldump  -uroot -p --host=localhost --all-databases --master-data=2;

--events, -E
导出事件。
mysqldump  -uroot -p --all-databases --events

--extended-insert,  -e
使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用--skip-extended-insert取消选项。
mysqldump  -uroot -p --all-databases
mysqldump  -uroot -p --all-databases--skip-extended-insert   (取消选项)

--fields-terminated-by
导出文件中忽略给定字段。与--tab选项一起使用，不能用于--databases和--all-databases选项
mysqldump  -uroot -p test test --tab=”/home/mysql” --fields-terminated-by=”#”

--fields-enclosed-by
输出文件中的各个字段用给定字符包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项
mysqldump  -uroot -p test test --tab=”/home/mysql” --fields-enclosed-by=”#”

--fields-optionally-enclosed-by
输出文件中的各个字段用给定字符选择性包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项
mysqldump  -uroot -p test test --tab=”/home/mysql”  --fields-enclosed-by=”#” --fields-optionally-enclosed-by  =”#”

--fields-escaped-by
输出文件中的各个字段忽略给定字符。与--tab选项一起使用，不能用于--databases和--all-databases选项
mysqldump  -uroot -p mysql user --tab=”/home/mysql” --fields-escaped-by=”#”

--flush-logs
开始导出之前刷新日志。
请注意：假如一次导出多个数据库(使用选项--databases或者--all-databases)，将会逐个数据库刷新日志。除使用--lock-all-tables或者--master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用--lock-all-tables 或者--master-data 和--flush-logs。
mysqldump  -uroot -p --all-databases --flush-logs

--flush-privileges
在导出mysql数据库之后，发出一条FLUSH  PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。
mysqldump  -uroot -p --all-databases --flush-privileges

--force
在导出过程中忽略出现的SQL错误。
mysqldump  -uroot -p --all-databases --force

--help
显示帮助信息并退出。
mysqldump  --help

--hex-blob
使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。
mysqldump  -uroot -p --all-databases --hex-blob

--host, -h
需要导出的主机信息
mysqldump  -uroot -p --host=localhost --all-databases

--ignore-table
不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：--ignore-table=database.table1 --ignore-table=database.table2 ……
mysqldump  -uroot -p --host=localhost --all-databases --ignore-table=mysql.user

--include-master-host-port
在--dump-slave产生的'CHANGE  MASTER TO..'语句中增加'MASTER_HOST=&lt;host&gt;，MASTER_PORT=&lt;port&gt;'  
mysqldump  -uroot -p --host=localhost --all-databases --include-master-host-port

--insert-ignore
在插入行时使用INSERT IGNORE语句.
mysqldump  -uroot -p --host=localhost --all-databases --insert-ignore

--lines-terminated-by
输出文件的每行用给定字符串划分。与--tab选项一起使用，不能用于--databases和--all-databases选项。
 
mysqldump  -uroot -p --host=localhost test test --tab=”/tmp/mysql”  --lines-terminated-by=”##”
--lock-all-tables,  -x
提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭--single-transaction 和--lock-tables 选项。
 
mysqldump  -uroot -p --host=localhost --all-databases --lock-all-tables
--lock-tables,  -l
开始导出前，锁定所有表。用READ  LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，--single-transaction是一个更好的选择，因为它根本不需要锁定表。
请注意当导出多个数据库时，--lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。
 
mysqldump  -uroot -p --host=localhost --all-databases --lock-tables
--log-error
附加警告和错误信息到给定文件
mysqldump  -uroot -p --host=localhost --all-databases  --log-error=/tmp/mysqldump_error_log.err
--max_allowed_packet
服务器发送和接受的最大包长度。
 
mysqldump  -uroot -p --host=localhost --all-databases --max_allowed_packet=10240
--net_buffer_length
TCP/IP和socket连接的缓存大小。
 
mysqldump  -uroot -p --host=localhost --all-databases --net_buffer_length=1024
--no-autocommit
使用autocommit/commit 语句包裹表。
 
mysqldump  -uroot -p --host=localhost --all-databases --no-autocommit
--no-create-db,  -n
只导出数据，而不添加CREATE DATABASE 语句。
 
mysqldump  -uroot -p --host=localhost --all-databases --no-create-db
--no-create-info,  -t
只导出数据，而不添加CREATE TABLE 语句。
 
mysqldump  -uroot -p --host=localhost --all-databases --no-create-info
--no-data, -d
不导出任何数据，只导出数据库表结构。
 
mysqldump  -uroot -p --host=localhost --all-databases --no-data
--no-set-names,  -N
等同于--skip-set-charset
mysqldump  -uroot -p --host=localhost --all-databases --no-set-names
--opt
等同于--add-drop-table,  --add-locks, --create-options, --quick, --extended-insert, --lock-tables,  --set-charset, --disable-keys 该选项默认开启,  可以用--skip-opt禁用.
 
mysqldump  -uroot -p --host=localhost --all-databases --opt
--order-by-primary
如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出MyISAM表到InnoDB表时有效，但会使得导出工作花费很长时间。 
 
mysqldump  -uroot -p --host=localhost --all-databases --order-by-primary
--password, -p
连接数据库密码
--pipe(windows系统可用)
使用命名管道连接mysql
 
mysqldump  -uroot -p --host=localhost --all-databases --pipe
--port, -P
连接数据库端口号
--protocol
使用的连接协议，包括：tcp, socket, pipe, memory.
 
mysqldump  -uroot -p --host=localhost --all-databases --protocol=tcp
--quick, -q
不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项。
 
mysqldump  -uroot -p --host=localhost --all-databases 
mysqldump  -uroot -p --host=localhost --all-databases --skip-quick
--quote-names,-Q
使用（\`）引起表和列名。默认为打开状态，使用--skip-quote-names取消该选项。
 
mysqldump  -uroot -p --host=localhost --all-databases
mysqldump  -uroot -p --host=localhost --all-databases --skip-quote-names
--replace
使用REPLACE INTO 取代INSERT INTO.
 
mysqldump  -uroot -p --host=localhost --all-databases --replace
--result-file,  -r
直接输出到指定文件中。该选项应该用在使用回车换行对（\\r\\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。
 
mysqldump  -uroot -p --host=localhost --all-databases --result-file=/tmp/mysqldump_result_file.txt
--routines, -R
导出存储过程以及自定义函数。
 
mysqldump  -uroot -p --host=localhost --all-databases --routines
--set-charset
添加'SET NAMES  default_character_set'到输出文件。默认为打开状态，使用--skip-set-charset关闭选项。
 
mysqldump  -uroot -p --host=localhost --all-databases 
mysqldump  -uroot -p --host=localhost --all-databases --skip-set-charset
--single-transaction
该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎，仅InnoDB。本选项和--lock-tables 选项是互斥的，因为LOCK  TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用--quick 选项。
 
mysqldump  -uroot -p --host=localhost --all-databases --single-transaction
--dump-date
将导出时间添加到输出文件中。默认为打开状态，使用--skip-dump-date关闭选项。
 
mysqldump  -uroot -p --host=localhost --all-databases
mysqldump  -uroot -p --host=localhost --all-databases --skip-dump-date
--skip-opt
禁用–opt选项.
 
mysqldump  -uroot -p --host=localhost --all-databases --skip-opt

--socket,-S
指定连接mysql的socket文件位置，默认路径/tmp/mysql.sock
mysqldump  -uroot -p --host=localhost --all-databases --socket=/tmp/mysqld.sock

--tab,-T
为每个表在给定路径创建tab分割的文本文件。注意：仅仅用于mysqldump和mysqld服务器运行在相同机器上。
mysqldump  -uroot -p --host=localhost test test --tab=&quot;/home/mysql&quot;

--tables
覆盖--databases (-B)参数，指定需要导出的表名。
mysqldump  -uroot -p --host=localhost --databases test --tables test

--triggers
导出触发器。该选项默认启用，用--skip-triggers禁用它。
mysqldump  -uroot -p --host=localhost --all-databases --triggers

--tz-utc
在导出顶部设置时区TIME_ZONE='+00:00' ，以保证在不同时区导出的TIMESTAMP 数据或者数据被移动其他时区时的正确性。
mysqldump  -uroot -p --host=localhost --all-databases --tz-utc

--user, -u
指定连接的用户名。

--verbose, --v
输出多种平台信息。
 
--version, -V
输出mysqldump版本信息并退出

--where, -w
只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。
mysqldump  -uroot -p --host=localhost --all-databases --where=” user=’root’”

--xml, -X
导出XML格式.
 mysqldump  -uroot -p --host=localhost --all-databases --xml

--plugin_dir
客户端插件的目录，用于兼容不同的插件版本。
mysqldump  -uroot -p --host=localhost --all-databases --plugin_dir=”/usr/local/lib/plugin”

--default_auth
客户端插件默认使用权限。
mysqldump  -uroot -p --host=localhost --all-databases --default-auth=”/usr/local/lib/plugin/&lt;plugin&gt;”&lt;/plugin&gt;&lt;/port&gt;&lt;/host&gt;


</code></pre>
<h2 id="参数选项"><a class="header" href="#参数选项">参数选项</a></h2>
<pre><code>-c, --complete-insert #使用完整的insert语句(用列名字)。
-C, --compress #如果客户和服务器均支持压缩，压缩两者间所有的信息。
--delayed #用INSERT DELAYED命令插入行。
-e, --extended-insert #使用全新多行INSERT语法。（给出更紧缩并且更快的插入语句）
-#, --debug[=option_string] #跟踪程序的使用(为了调试)。
--help #显示一条帮助消息并且退出。
    --fields-terminated-by=...
    --fields-enclosed-by=...
    --fields-optionally-enclosed-by=...
    --fields-escaped-by=...　
    --fields-terminated-by=...
这些选择与-T选择一起使用，并且有相应的LOAD DATA INFILE子句相同的含义。
LOAD DATA INFILE语法。
-F, --flush-logs
在开始导出前，洗掉在MySQL服务器中的日志文件。
-f, --force,
即使我们在一个表导出期间得到一个SQL错误，继续。
-h, --host=..
从命名的主机上的MySQL服务器导出数据。缺省主机是localhost。
-l, --lock-tables.
为开始导出锁定所有表。
-t, --no-create-info
不写入表创建信息(CREATE TABLE语句）
-d, --no-data
不写入表的任何行信息。如果你只想得到一个表的结构的导出，这是很有用的！
--opt
同--quick --add-drop-table --add-locks --extended-insert --lock-tables。
应该给你为读入一个MySQL服务器的尽可能最快的导出。
-pyour_pass, --password[=your_pass]
与服务器连接时使用的口令。如果你不指定“=your_pass”部分，mysqldump需要来自终端的口令。
-P port_num, --port=port_num
与一台主机连接时使用的TCP/IP端口号。（这用于连接到localhost以外的主机，因为它使用 Unix套接字。）
-q, --quick
不缓冲查询，直接导出至stdout；使用mysql_use_result()做它。
-S /path/to/socket, --socket=/path/to/socket
与localhost连接时（它是缺省主机)使用的套接字文件。
-T, --tab=path-to-some-directory
对于每个给定的表，创建一个table_name.sql文件，它包含SQL CREATE 命令，和一个table_name.txt文件，它包含数据。注意：这只有在mysqldump运行在mysqld守护进程运行的同一台机器上的时候才工作。.txt文件的格式根据--fields-xxx和 --lines--xxx选项来定。
-u user_name, --user=user_name
与服务器连接时，MySQL使用的用户名。缺省值是你的Unix登录名。
-O var=option, --set-variable var=option设置一个变量的值。可能的变量被列在下面。
-v, --verbose
冗长模式。打印出程序所做的更多的信息。
-V, --version
打印版本信息并且退出。
-w, --where='where-condition'
只导出被选择了的记录；注意引号是强制的！
&quot;--where=user='jimf'&quot; &quot;-wuserid&gt;1&quot; &quot;-wuserid&lt;1&quot;
--routines选项：表示备份时，存储过程和存储函数也会被备份。
--triggers选项：表示备份时，触发器会被备份。
--events选项：表示备份时，事件表会被备份。
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>id SELECT识别符。这是SELECT查询序列号。这个不重要
select_type 1、 SIMPLE
表示简单查询，其中不包含连接查询和子查询。
2、 PRIMARY
表示主查询，或者是最外面的查询语句。
3、 UNION
表示连接查询的第2个或后面的查询语句。
4、 DEPENDENT UNION
UNION中的第二个或后面的SELECT语句，取决于外面的查询。
5、 UNION RESULT
连接查询的结果。
6、 SUBQUERY
子查询中的第1个SELECT语句。
7、 DEPENDENT SUBQUERY
子查询中的第1个SELECT语句，取决于外面的查询。
8、 DERIVED
SELECT(FROM 子句的子查询)。
table 表示查询的表
type 表示表的连接类型。
以下的连接类型的顺序是从最佳类型到最差类型：
1、 system
表仅有一行，这是const类型的特列，平时不会出现，这个也可以忽略不计。
2、 const
数据表最多只有一个匹配行，因为只匹配一行数据，所以很快，常用于PRIMARY KEY或者UNIQUE索引的查询，可理解为const是最优化的。
3、 eq_refmysql手册是这样说的:&quot;对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY&quot;。eq_ref可以用于使用=比较带索引的列。
4、 ref查询条件索引既不是UNIQUE也不是PRIMARY KEY的情况。ref可用于=或&lt;或&gt;操作符的带索引的列。
5、 ref_or_null该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。
上面这五种情况都是很理想的索引使用情况。
6、 index_merge
该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。
7、 unique_subquery
该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr)
unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。
8、 index_subquery
该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr)
9、 range
只检索给定范围的行,使用一个索引来选择行。
10、 index
该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。
11、 ALL
对于每个来自于先前的表的行组合,进行完整的表扫描。（性能最差）
possible_keys 指出MySQL能使用哪个索引在该表中找到行。
如果该列为NULL，说明没有使用索引，可以对该列创建索引来提高性能。
key 显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。
可以强制使用索引或者忽略索引：
key_len key_len显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL。
注意：key_len是确定了MySQL将实际使用的索引长度。
ref 显示使用哪个列或常数与key一起从表中选择行。
rows 显示MySQL认为它执行查询时必须检查的行数。
Extra 该列包含MySQL解决查询的详细信息
• Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。
• Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。
• range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。
• Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。
• Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。
• Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。
• Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。
• Using sort_union(...), Using union(...), Using intersect(...):这些函数说明如何为index_merge联接类型合并索引扫描。
• Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。</p>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-bash">Linux中进入mysql
mysql -u root mysql -u root::用户名 -p  回车
password::输入密码

Linux中退出mysql
quit; 回车

查看进程中带有mysql的进程
ps -ef|grep mysql

杀mysql进程
kill -9 mysqld
mysql服务启动
service mysqld start
查询运行文件所在路径
which mysql
查看mysql 安装路径
whereis mysql

linux下卸载mysql方法  
查找已安装的myslq 版本
rpm -qa | grep mysql （注意大小写，如果mysql 不行就换MySQL）
包名卸载
rpm -e –nodeps mysql-5.0.77-4.el5_4.2 （nodeps表示强制删除）

修改mysql数据库的路径
vi /etc/my.cnf  datadir=修改路径

设置密码
SET PASSWORD FOR 'root'@'host_name' = PASSWORD('newpwd');
.sql文件导入到dbname数据库 mysql -u user -p dbname &lt; /path/.../file.sql  

show engines
select @@innodb_version;

查看mysql最大連接數
show variables like 'max_connections';

查看当前使用的数据库
status;
 show tables;
 show databases;//可以查看有哪些数据库,返回数据库名(databaseName)
 use databaseName; //更换当前使用的数据库
 show tables; //返回当前数据库下的所有表的名称
 show tables from databaseName;//databaseName可以用show databases得来
mysql查看表结构命令 desc 表名;
 show columns from 表名;
 describe 表名;
 show create table 表名;
 use information_schema;
 select * from columns where table_name='表名';
 show columns from table_name [ from database_name ] ;
 show columns from database_name.table_name;

查看警告
show warnings; 显示最后一个执行的语句所产生的错误、警告和通知

查看存储过程状态
show procedure status;  

显示一个用户的权限
show grants for user_name;

显示表的索引
show index from table_name;

显示一些系统特定资源的信息
show status [from db_name];

显示系统变量的名称和值
show [ global] variables;

显示系统中正在运行的所有进程

show processlist 也就是当前正在执行的查询大多数用户可以查看他们自己的进程，
  但是如果他们拥有process权限，就可以查看所有人的进程，包括密码

显示每个表的信息
show table status 显示当前使用或者指定的database中的每个表的信息信息包括表类型和表的最新更新时间

显示服务器所支持的不同权限
show privileges

显示create database 语句是否能够创建指定的数据库
show create database database_name

显示create database 语句是否能够创建指定的数据库
show create table table_name

显示安装以后可用的存储引擎和默认引擎
show engies

显示innoDB存储引擎的状态
show innodb status

显示BDB存储引擎的日志
show logs -----这个已经被遗弃了
  只显示最后一个执行语句所产生的错误

show errors;

show [storage] engines; 显示安装后的可用存储引擎和默认引擎
  例如：mysqlshow -uroot -pXXXX mysql #显示mysql数据库的信息
  例如：mysqlshow -uroot -pXXXX mysql user #显示mysql数据库中user表的信息

mysqlshow，该指令只参显示数据库、表、列的信息  例如：mysqlshow -uroot -pXXXX mysql user user #显示

mysql数据库中user表中的user列的信息
1.另外在mysql的monitor后，各种命令以分号结束。
2.ps -ef|grep mysql 得出结果

/etc/init.d/mysql stop  
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p><a href="http://www.sqlite.org/">http://www.sqlite.org/</a>
windows安装：
1.下载
<a href="http://www.sqlite.org/download.html">http://www.sqlite.org/download.html</a>
Precompiled Binaries for Windows
<a href="http://www.sqlite.org/2015/sqlite-shell-win32-x86-3080900.zip">http://www.sqlite.org/2015/sqlite-shell-win32-x86-3080900.zip</a>
2.解压得到sqlite3.exe
3.复制该文件到C:\Windows\System32（可以在运行命令中直接运行sqlite3.exe dbname,会在C:\Users\yujian下创建数据库文件dbname）</p>
<p>4.操作数据库。
a.在该面板中操作。
sqlite&gt; create table tbl1(one varchar(10), two smallint);
sqlite&gt; insert into tbl1 values('hello!',10);
sqlite&gt; insert into tbl1 values('goodbye', 20);
sqlite&gt; select * from tbl1;
hello!|10
goodbye|20
sqlite&gt;</p>
<p>b.使用.bat文件
sqlite3.bat(双击执行该文件，需要保证sqlite3.bat,insertdb.bat,test.db在同一个目录下)
@ECHO OFF
For /L %%i in (1,1,2) do (sqlite3.exe test&lt;insertdb.bat)
pause
insertdb.bat
insert into test_select values (&quot;040e6b974755aa78838cfe6de482b60b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;,&quot;f&quot;)
5.工具：<a href="http://www.sqlitedeveloper.com/">http://www.sqlitedeveloper.com/</a>（使用该可视化工具）</p>
<p>linux下安装
1.下载源文件。<a href="http://www.sqlite.org/snapshot/sqlite-amalgamation-201505051108.zip">http://www.sqlite.org/snapshot/sqlite-amalgamation-201505051108.zip</a>
2.编译。<a href="http://www.sqlite.org/howtocompile.html">http://www.sqlite.org/howtocompile.html</a>
gcc -DSQLITE_THREADSAFE=0 -DSQLITE_OMIT_LOAD_EXTENSION shell.c sqlite3.c
3.编写c++代码</p>
<pre><code class="language-c++">sqlite_query.c
# include &lt;stdio.h&gt;
# include &lt;sqlite3.h&gt;
  static int callback(void *NotUsed, int argc, char **argv , char **azColName){
    int i;
    for(i=0; i&lt;argc; i++){
      printf(&quot;%s = %s\n&quot;, azColName[i], argv[i] ? argv[i] : &quot;NULL&quot; );
    }
    printf(&quot;\n&quot;);
    return 0;
  }

  int main( int argc, char **argv){
    sqlite3 *db;
    char *zErrMsg = 0;
    int rc;

    if( argc!=3 ){
      fprintf(stderr , &quot;Usage: %s DATABASE SQL-STATEMENT\n&quot;, argv[0]);
      return(1);
    }
    rc = sqlite3_open(argv[1], &amp;db);
    if( rc ){
      fprintf(stderr , &quot;Can't open database: %s\n&quot;, sqlite3_errmsg( db));
      sqlite3_close(db);
      return(1);
    }
    rc = sqlite3_exec(db, argv[2], callback, 0, &amp;zErrMsg);
    if( rc!=SQLITE_OK ){
      fprintf(stderr , &quot;SQL error: %s\n&quot;, zErrMsg);
      sqlite3_free(zErrMsg);
    }
    sqlite3_close(db);
    return 0;
}
</code></pre>
<p>4.编译运行</p>
<pre><code class="language-bash"> $ gcc sqlite_query.c -o db.out -lsqlite3 -L/usr/local/sqlite3/lib -I/usr/local/sqlite3/include
 $ ./db.out &quot;dbname&quot; &quot;sql&quot;
   ./db.out &quot;test&quot; &quot;select count(*) from test_select where key like '%1111%';&quot;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="管理"><a class="header" href="#管理">管理</a></h2>
<h2 id="查询活动用户"><a class="header" href="#查询活动用户">查询活动用户</a></h2>
<pre><code class="language-sql">-- 查看postgresql的连接数
select * from pg_stat_activity;

-- 查看最大连接数限制
show max_connections;

-- 查看为超级用户保留的连接数
show superuser_reserved_connections; 
</code></pre>
<h2 id="正在执行中的sql"><a class="header" href="#正在执行中的sql">正在执行中的SQL</a></h2>
<pre><code class="language-sql">SELECT 
    procpid, 
    start, 
    now() - start AS lap, 
    current_query 
FROM 
    (SELECT 
        backendid, 
        pg_stat_get_backend_pid(S.backendid) AS procpid, 
        pg_stat_get_backend_activity_start(S.backendid) AS start, 
       pg_stat_get_backend_activity(S.backendid) AS current_query 
    FROM 
        (SELECT pg_stat_get_backend_idset() AS backendid) AS S 
    ) AS S 
WHERE 
   current_query &lt;&gt; '&lt;IDLE&gt;' 
ORDER BY 
   lap DESC;

/*
procpid：进程id
start：进程开始时间
lap：经过时间
current_query：执行中的sql
*/

-- 怎样停止正在执行的sql
SELECT pg_cancel_backend(进程id);

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="create"><a class="header" href="#create">create</a></h2>
<pre><code class="language-sql">-- 创建表

-- 创建自增字段
CREATE SEQUENCE tablename_colname_seq;
CREATE TABLE tablename(
    colname integer DEFAULT nextval('tablename_colname_seq') NOT NULL
);

CREATE TABLE tablename (
    colname SERIAL
);

-- 创建序列
CREATE SEQUENCE name increment by 1 maxvalue 10 minvalue 1 start 1 cycle

-- 下一个值：nextval(regclass)
-- 当前值：currval(regclass)
-- 设置值：setval(regclass)

SELECT * FROM sd.ext_codes_id_seq;
SELECT nextval('sd.ext_codes_id_seq');
SELECT setval('shipments_ship_id_seq', 1010); -- SELECT nextval('shipments_ship_id_seq'); 1011
SELECT setval('shipments_ship_id_seq', 1010, false); -- SELECT nextval('shipments_ship_id_seq'); 1010

DROP SEQUENCE sd.ext_codes_id_seq;
SELECT p.relname, a.adsrc FROM pg_class p
JOIN pg_attrdef a on (p.relfilenode = a.adrelid) 
WHERE a.adsrc ~ 'shipments_ship_id_seq'; -- 查看被引用

-- 创建自动更新日期字段
-- 创建触发器
create or replace function update_modified_timestamp_column() returns trigger as
$$
begin
    new.modified = current_timestamp;
    return new;
end
$$
language plpgsql;


CREATE TABLE product (
id INT NOT NULL,
modified_timestamp TIMESTAMP DEFAULT 'now'::timestamp
);

CREATE TRIGGER product_update_modified_timestamp
BEFORE UPDATE ON product 
FOR EACH ROW EXECUTE PROCEDURE update_modified_timestamp_column();

-- 插入数据时返回数据
INSERT INTO user_tbl(name, signup_date) VALUES('张三', '2013-12-22') RETURNING *;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="常用配置"><a class="header" href="#常用配置">常用配置</a></h2>
<pre><code class="language-text"># https://www.postgresql.org/docs/14/runtime-config.html

listen_addresses = '*'
port = 27198                # (change requires restart)
max_connections = 1024           # (change requires restart)

data_directory = 'ConfigDir'


#/usr/pgsql-10/bin/postgresql-10-setup initdb -E UTF-8 --locale=en_US.UTF-8 -U postgres -W
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>选项</th><th>默认值</th><th>说明</th><th>是否优化</th><th>原因</th></tr></thead><tbody>
<tr><td>max_connections</td><td>100</td><td>允许客户端连接的最大数目</td><td>否</td><td>因为在测试的过程中，100个连接已经足够</td></tr>
<tr><td>fsync</td><td>on</td><td>强制把数据同步更新到磁盘</td><td>是</td><td>因为系统的IO压力很大，为了更好的测试其他配置的影响，把改参数改为off</td></tr>
<tr><td>shared_buffers</td><td>24MB</td><td>决定有多少内存可以被PostgreSQL用于缓存数据（推荐内存的1/4)</td><td>是</td><td>在IO压力很大的情况下，提高该值可以减少IO</td></tr>
<tr><td>work_mem</td><td>1MB</td><td>使内部排序和一些复杂的查询都在这个buffer中完成</td><td>是</td><td>有助提高排序等操作的速度，并且减低IO</td></tr>
<tr><td>effective_cache_size</td><td>128MB</td><td>优化器假设一个查询可以用的最大内存，和shared_buffers无关（推荐内存的1/2)</td><td>是</td><td>设置稍大，优化器更倾向使用索引扫描而不是顺序扫描</td></tr>
<tr><td>maintenance_work_mem</td><td>16MB</td><td>这里定义的内存只是被VACUUM等耗费资源较多的命令调用时使用</td><td>是</td><td>把该值调大，能加快命令的执行</td></tr>
<tr><td>wal_buffer</td><td>768kB</td><td>日志缓存区的大小</td><td>是</td><td>可以降低IO，如果遇上比较多的并发短事务，应该和commit_delay一起用</td></tr>
<tr><td>checkpoint_segments</td><td>3</td><td>设置wal log的最大数量数（一个log的大小为16M）</td><td>是</td><td>默认的48M的缓存是一个严重的瓶颈，基本上都要设置为10以上</td></tr>
<tr><td>checkpoint_completion_target</td><td>0.5</td><td>表示checkpoint的完成时间要在两个checkpoint间隔时间的N%内完成</td><td>是</td><td>能降低平均写入的开销</td></tr>
<tr><td>commit_delay</td><td>0</td><td>事务提交后，日志写到wal log上到wal_buffer写入到磁盘的时间间隔。需要配合commit_sibling</td><td>是</td><td>能够一次写入多个事务，减少IO，提高性能</td></tr>
<tr><td>commit_siblings</td><td>5</td><td>设置触发commit_delay的并发事务数，根据并发事务多少来配置</td><td>是</td><td>减少IO，提高性能</td></tr>
</tbody></table>
</div>
<p>asa
测试数据</p>
<pre><code>• 测试的数据是运行3次，取平均值。
• 关闭fsync是为了更好的体现出其他参数对PostgreSQL的影响。
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>参数</th><th>修改值</th><th>事务总数</th><th>tps(包括建立连接)</th><th>tps(不包括建立连接)</th></tr></thead><tbody>
<tr><td>默认设置</td><td></td><td>8464</td><td>140.999792</td><td>141.016182</td></tr>
<tr><td>fsync</td><td>off</td><td>92571</td><td>1479.969755</td><td>1480.163355</td></tr>
<tr><td>shared_buffers</td><td>1GB</td><td>100055</td><td>1635.759275</td><td>1635.977823</td></tr>
<tr><td>work_mem</td><td>10MB</td><td>101209</td><td>1665.804812</td><td>1666.04082</td></tr>
<tr><td>effective_cache_size</td><td>2GB</td><td>98209</td><td>1636.733152</td><td>1636.970271</td></tr>
<tr><td>maintenance_work_mem</td><td>512MB</td><td>92930</td><td>1548.029233</td><td>1548.223108</td></tr>
<tr><td>checkpoint_segments</td><td>32</td><td>195982</td><td>3265.995</td><td>3266.471064</td></tr>
<tr><td>checkpoint_completion_target</td><td>0.9</td><td>194390</td><td>3239.406493</td><td>3239.842596</td></tr>
<tr><td>wal_buffer</td><td>8MB</td><td>198639</td><td>3310.241458</td><td>3310.724067</td></tr>
<tr><td>恢复fsync</td><td>off</td><td>11157</td><td>185.883542</td><td>185.909849</td></tr>
<tr><td>commit_delay &amp;&amp; commit_siblings</td><td>10 &amp;&amp; 4</td><td>11229</td><td>187.103538</td><td>187.131747</td></tr>
</tbody></table>
</div>
<p>来自 <a href="http://www.cnblogs.com/shanyou/p/3495935.html">http://www.cnblogs.com/shanyou/p/3495935.html</a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="配置数据库路径"><a class="header" href="#配置数据库路径">配置数据库路径</a></h2>
<pre><code class="language-bash">mkdir /home/pg14/data
chown -R postgres:postgres /home/pg14

su - postgres
/usr/pgsql-14/bin/initdb -D /home/pg14/data
exit

sudo vim /usr/lib/systemd/system/postgresql-14.service

# 修改Enviroment=PGDATA=/var/lib/pgsql/14/data/为/home/pg14/data/后保存退出编辑器

systemctl daemon-reload
systemctl restart postgresql-14
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="配置"><a class="header" href="#配置">配置</a></h2>
<pre><code class="language-bash">psql -U postgres -h 127.0.0.1

create database nyc_data;
\c nyc_data
CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;

CREATE TABLE conditions (
  time        TIMESTAMPTZ       NOT NULL,
  location    TEXT              NOT NULL,
  temperature DOUBLE PRECISION  NULL,
  humidity    DOUBLE PRECISION  NULL
);

SELECT create_hypertable('conditions', 'time');


INSERT INTO conditions(time, location, temperature, humidity)
  VALUES (NOW(), 'office', 70.0, 50.0);

SELECT * FROM conditions ORDER BY time DESC LIMIT 100;

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="外部表-postgres_fdw"><a class="header" href="#外部表-postgres_fdw">外部表 postgres_fdw</a></h2>
<h2 id="添加extension"><a class="header" href="#添加extension">添加extension</a></h2>
<pre><code class="language-sql">create extension postgres_fdw;
select * from pg_foreign_data_wrapper;
</code></pre>
<h2 id="创建远端数据库"><a class="header" href="#创建远端数据库">创建远端数据库</a></h2>
<p>create database dblink TEMPLATE template0;</p>
<h2 id="本地创建server"><a class="header" href="#本地创建server">本地创建server</a></h2>
<p>select * from pg_foreign_server;
create server ex_db foreign data wrapper postgres_fdw options(host '127.0.0.1',port '5866',dbname 'highgo');
create server mysql_config foreign data wrapper postgres_fdw options(host '192.168.69.161',port '3306',dbname 'config');
ALTER SERVER ex_db OPTIONS (host '127.0.0.1', dbname 'highgo_2');</p>
<h2 id="创建用户匹配信息"><a class="header" href="#创建用户匹配信息">创建用户匹配信息</a></h2>
<p>select * from pg_user_mappings;
create user mapping for postgres[账户名] server ex_db options(user 'highgo',password 'highgo');
create user mapping for postgres server mysql_config options(user 'root',password '185b838a0a4f_#A');</p>
<h2 id="创建外部表"><a class="header" href="#创建外部表">创建外部表</a></h2>
<p>CREATE FOREIGN TABLE config_lv(lv int4, &quot;exp&quot; int4) server ex_db options (dbname 'config',table_name 'config_lv');</p>
<p>CREATE FOREIGN TABLE dblink.usr_truck_mapping(
&quot;PROFILE_ID&quot; int4,
&quot;TKID&quot; int4,
&quot;DEFAULT_TK&quot; int4,
&quot;DELETED&quot; int4,
&quot;CREATED_BY&quot; int4,
&quot;CREATED_BY_NAME&quot; varchar,
&quot;CREATED_TIME&quot; TIMESTAMP,
&quot;UPDATED_BY&quot; int4,
&quot;UPDATED_BY_NAME&quot; varchar,
&quot;UPDATED_TIME&quot; TIMESTAMP,
&quot;VERSION&quot; int4
)
server ex_db options (dbname 'member_pilot', table_name 'usr_truck_mapping');</p>
<h2 id="删除外部表"><a class="header" href="#删除外部表">删除外部表</a></h2>
<p>DROP FOREIGN TABLE bb;</p>
<h2 id="导入整个schema下的所有表"><a class="header" href="#导入整个schema下的所有表">导入整个schema下的所有表</a></h2>
<p>grant all on foreign server mysql_config to postgres;
IMPORT FOREIGN SCHEMA dblink FROM SERVER ex_db into dblink;</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="pg_hbaconf"><a class="header" href="#pg_hbaconf">pg_hba.conf</a></h2>
<pre><code class="language-text">#md5 -- 客户端需要提供密码来进行md5算法处理  
#ident -- 根据操作系统获取连接的客户端的用户名，并且使用指定匹配查询用户名  
#trust -- 任何连接到PostgreSQL的人都可以作为任何用户并且不需要提供密码  
#peer -- 从操作系统中获取用户名，并确认用户名是否匹配数据库用户名  

# https://www.postgresql.org/docs/14/auth-pg-hba-conf.html

host    all             all             0.0.0.0/0               md5 //#所有IP和用户，密码对都可以连接


# TYPE  DATABASE        USER            ADDRESS                 METHOD

# &quot;local&quot; is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            md5
host    all             all             0.0.0.0/0               md5
# IPv6 local connections:
host    all             all             ::1/128                 md5
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            md5
host    replication     all             ::1/128                 md5
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="exists-in"><a class="header" href="#exists-in">EXISTS IN</a></h2>
<h2 id="not-in-使用-left-join--is-null或not-exists而不是not-in"><a class="header" href="#not-in-使用-left-join--is-null或not-exists而不是not-in">NOT IN 使用 LEFT JOIN / IS NULL或NOT EXISTS而不是NOT IN</a></h2>
<pre><code class="language-text">
NOT IN正如我们之前讨论的那样，由于它处理NULL列表中的值的方式，这是一个特例。

不幸的是，PostgreSQL的优化器不能使用t_right.value定义为的事实，NOT NULL因此列表不能返回任何NULL值。

这就是为什么NOT IN查询PostgreSQL使用一种特殊的访问方法hashed Subplan：

首先，它执行列表查询（使用Seq Scanon t_right）并散列其结果。从哈希中消除重复值
然后它从t_left（再次，使用Seq Scan）获取每一行并对每个值应用过滤条件
过滤条件的工作原理如下：

如果t_left.value是NULL，它立即返回NULL。
如果t_left.value不是NULL，则在步骤1中生成的哈希表中搜索：

如果在列表中找到该值，TRUE则返回。
如果未找到该值，则再次搜索哈希表以查找NULL值。取决于是否NULL找到NULL或FALSE返回
这本身就是一种非常有效的方法，但是需要两次查找值会降低查询性能。

查询需要1.34秒。

另一个令人讨厌的副作用是使用a subplan是PostgreSQL的优化器可用于NOT IN构造的唯一方法。

由于PostgreSQL无法将散列子计划刷新到磁盘上，因此它将估计子查询大小，如果它确定它不适合work_mem，它将使用仅为subplan每行执行t_left或实现的仅仅是将在循环中搜索行。

这可能非常糟糕，因为优化器只会改变计划，因为t_right会超出一定的限制，有一天查询会变得很慢而没有任何明显的原因。


PostgreSQL treats LEFT JOIN and NOT EXISTS equally, using same execution plan for both of them (namely a Hash Anti Join for the example above).
PostgreSQL对待它们LEFT JOIN并NOT EXISTS同样地使用相同的执行计划（即Hash Anti Join上面的示例）。

As for NOT IN, which is semantically different since its logic is trivalent and it can return NULL, PostgreSQL tries to take this into account and limits itself to using a filter against a subplan (a hashed subplan for a hashable resultset like in example above).
至于NOT IN它在语义上是不同的，因为它的逻辑是三价的并且它可以返回NULL，PostgreSQL试图将此考虑在内并限制自己使用针对a的a subplan（hashed subplan对于像上面的例子中的可哈希结果集）。

Since it need to search the hash table for each missing value twice (first time to find the value, second time to find a NULL), this method is a little less efficient.
由于需要两次搜索哈希表中的每个缺失值（第一次查找值，第二次查找a NULL），此方法效率稍差。

A plain subplan, which the optimizer can resort to any time it decides the list will not fit into the memory, is very inefficient and the queries that have possibility of using it should be avoided like a plague.
一个普通的subplan，它优化器可以求助于它决定名单将不适合到内存中的任何时间，是非常低效的，应该避免像瘟疫一样有使用它的可能性的查询。

That's why in PostgreSQL 8.4 one should always use LEFT JOIN / IS NULL or NOT EXISTS rather than NOT IN to find the missing values.
这就是为什么在PostgreSQL 8.4中应该总是使用LEFT JOIN / IS NULL或NOT EXISTS不是NOT IN找到缺失的值。

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="install"><a class="header" href="#install">Install</a></h2>
<pre><code class="language-bash">
# https://www.postgresql.org/download/linux/redhat/

# Install the repository RPM:
sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm

# Install PostgreSQL:
sudo yum install -y postgresql14-server

# Optionally initialize the database and enable automatic start:
sudo /usr/pgsql-14/bin/postgresql-14-setup initdb
sudo systemctl enable postgresql-14
sudo systemctl start postgresql-14


##=timescaledb================================================
cd /etc/yum.repos.d/
vim timescale_timescaledb.repo
[timescale_timescaledb]
name=timescale_timescaledb
baseurl=https://packagecloud.io/timescale/timescaledb/el/7/\$basearch
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/timescale/timescaledb/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300

sudo yum update -y

sudo yum install -y timescaledb-postgresql-14

timescaledb-tune

systemctl restart postgresql-14


#=插件=========================================================
centOS
yum install geos geos-devel proj-devel
</code></pre>
<h2 id="外网访问postgres"><a class="header" href="#外网访问postgres">外网访问postgres</a></h2>
<pre><code class="language-bash">
# 设置pgsql中用户名【postgres】的密码

# 1.切换linux用户到【postgres】
# 2.登陆pgsql服务端【psql】
# 3.修改密码，输入命令【\password 账户名】回车，输入密码，再次输入密码
su - postgres
psql
postgres=#\password 密码
postgres=#\q

#新用户
#sudo adduser dbuser
su - postgres
pgsql
postgres=#CREATE USER [dbuser] WITH PASSWORD 'password';
postgres=#CREATE DATABASE [db_t1] OWNER [dbuser];
postgres=#GRANT ALL PRIVILEGES ON DATABASE [db_t1] to [dbuser];
postgres=#\q

#远程登陆
cd /var/lib/pgsql/14/data

vim pg_hba.conf 
    host    all             all             0.0.0.0/0               md5 # 所有IP和用户，密码对都可以连接

vim postgresql.conf
    listen_addresses = '*'

systemctl restart postgresql-14

</code></pre>
<h2 id="客户端"><a class="header" href="#客户端">客户端</a></h2>
<pre><code class="language-bash"># https://www.pgadmin.org/download/


</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="elk"><a class="header" href="#elk">elk</a></h2>
<pre><code class="language-bash">
</code></pre>
<h2 id="config"><a class="header" href="#config">config</a></h2>
<pre><code class="language-config">
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="安装-1"><a class="header" href="#安装-1">安装</a></h1>
<h2 id="docker安装"><a class="header" href="#docker安装">docker安装</a></h2>
<pre><code class="language-bash">docker run -d --restart=always --privileged=true -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; --name elasticsearch1 -v /data1/project/elk/elasticsearch/config:/usr/share/elasticsearch/config/ docker.elastic.co/elasticsearch/elasticsearch:7.10.2

docker run -d --restart=always --privileged=true --link elasticsearch-1:elasticsearch -p 5601:5601 --name kibana1 docker.elastic.co/kibana/kibana:7.10.2
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="clickhouse"><a class="header" href="#clickhouse">clickhouse</a></h2>
<pre><code class="language-bash">
</code></pre>
<h2 id="config-1"><a class="header" href="#config-1">config</a></h2>
<pre><code class="language-config">
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="curl"><a class="header" href="#curl">curl</a></h1>
<h2 id="ping"><a class="header" href="#ping">ping</a></h2>
<pre><code class="language-bash">
curl 'http://localhost:8123/ping'

</code></pre>
<h2 id="select"><a class="header" href="#select">select</a></h2>
<pre><code class="language-bash">
echo 'SELECT 1' | curl 'http://192.168.1.185:8123/?user=default&amp;password=1Aa_abbccd' -d @-
echo 'SELECT number FROM numbers LIMIT 10' | curl 'http://192.168.1.185:8123/?user=default&amp;password=1Aa_abbccd&amp;database=system' --data-binary @-

</code></pre>
<h2 id="insert"><a class="header" href="#insert">insert</a></h2>
<pre><code class="language-base">
echo 'INSERT INTO t VALUES (1),(2),(3)' | POST 'http://localhost:8123/?database=test_db'

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick start</a></h1>
<h2 id="安装-2"><a class="header" href="#安装-2">安装</a></h2>
<pre><code class="language-text">    https://clickhouse.tech/#quick-start
</code></pre>
<h2 id="配置-1"><a class="header" href="#配置-1">配置</a></h2>
<pre><code class="language-text">&lt;http_port&gt;8123&lt;/http_port&gt;
&lt;tcp_port&gt;8124&lt;/tcp_port&gt;
&lt;mysql_port&gt;8125&lt;/mysql_port&gt;
&lt;listen_host&gt;::&lt;/listen_host&gt;
</code></pre>
<h2 id="用户"><a class="header" href="#用户">用户</a></h2>
<h3 id="如何生成密码"><a class="header" href="#如何生成密码">如何生成密码</a></h3>
<pre><code class="language-bash">PASSWORD=$(base64 &lt; /dev/urandom | head -c8);
echo &quot;$PASSWORD&quot;; echo -n &quot;$PASSWORD&quot; | sha256sum | tr -d '-'

 &lt;users&gt;
    &lt;default&gt;
        &lt;password&gt;705c37761366c70774b786a9d800af2369759c1fc73ff61f2396648dd5daa5aa&lt;/password&gt;
        &lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&gt;
            &lt;ip&gt;::/0&lt;/ip&gt;
        &lt;/networks&gt;
        &lt;profile&gt;default&lt;/profile&gt;
        &lt;quota&gt;default&lt;/quota&gt;
    &lt;/default&gt;
    &lt;ck&gt;
        &lt;password_sha256_hex&gt;967f3bf355dddfabfca1c9f5cab39352b2ec1cd0b05f9e1e6b8f629705fe7d6e&lt;/password_sha256_hex&gt;
        &lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&gt;
            &lt;ip&gt;::/0&lt;/ip&gt;
        &lt;/networks&gt;
        &lt;profile&gt;readonly&lt;/profile&gt;
        &lt;quota&gt;default&lt;/quota&gt;
    &lt;/ck&gt;
&lt;/users&gt;

clickhouse-client -h 127.0.0.1  -u log --port 8124 --password ldsLjNhB
clickhouse-client -h 127.0.0.1  -u default --port 8124 --password 705c37761366c70774b786a9d800af2369759c1fc73ff61f2396648dd5daa5aa

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="hugo-使用"><a class="header" href="#hugo-使用">hugo 使用</a></h2>
<h2 id="安装-3"><a class="header" href="#安装-3">安装</a></h2>
<pre><code class="language-bash"># 源代码安装
go get -u -v github.com/spf13/hugo

# 包安装
https://github.com/gohugoio/hugo/releases

hugo version
</code></pre>
<h2 id="生成站点"><a class="header" href="#生成站点">生成站点</a></h2>
<pre><code class="language-bash">hugo new site /path/to/site
hugo new site blog.01cs.cc
</code></pre>
<h2 id="创建-themes-目录"><a class="header" href="#创建-themes-目录">创建 themes 目录</a></h2>
<pre><code class="language-bash">cd /path/to/site
git init

# doc 模板
git clone https://github.com/matcornic/hugo-theme-learn.git 

git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke
echo 'theme = &quot;ananke&quot;' &gt;&gt; config.toml

git submodule add  https://github.com/spf13/hyde.git themes/hyde
echo 'theme = &quot;hyde&quot;' &gt;&gt; config.toml
</code></pre>
<h2 id="创建文章"><a class="header" href="#创建文章">创建文章</a></h2>
<pre><code class="language-bash">hugo new about.md
hugo new post/first.md
</code></pre>
<h2 id="运行-httplocalhost1313"><a class="header" href="#运行-httplocalhost1313">运行 <a href="http://localhost:1313">http://localhost:1313</a></a></h2>
<pre><code class="language-bash">hugo server -D

hugo server --theme=hyde --buildDrafts

hugo server --baseURL=http://yoursite.org/ \
              --port=80 \
              --appendPort=false \
              --bind=87.245.198.50 \
              --theme=hyde


使用方法:
  hugo
  hugo [flags]
  hugo [command]
  hugo [command] [flags]

节选的 command:
  new         为你的站点创建新的内容
  server      一个高性能的web服务器

节选的 flags:
  -D, --buildDrafts                包括被标记为draft的文章
  -E, --buildExpired               包括已过期的文章
  -F, --buildFuture                包括将在未来发布的文章

举几个栗子:
  hugo -D                          生成静态文件并包括draft为true的文章
  hugo new post/new-content.md     新建一篇文章
  hugo new site mysite             新建一个称为mysite的站点
  hugo server --buildExpired       启动服务器并包括已过期的文章

</code></pre>
<h2 id="部署"><a class="header" href="#部署">部署</a></h2>
<pre><code class="language-bash">hugo --theme=hyde --baseUrl=&quot;http://coderzh.github.io/&quot;



</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>{{% button href=&quot;https://getgrav.org/&quot; %}}Get Grav{{% /button %}}
{{% button href=&quot;https://getgrav.org/&quot; icon=&quot;fas fa-download&quot; %}}Get Grav with icon{{% /button %}}
{{% button href=&quot;https://getgrav.org/&quot; icon=&quot;fas fa-download&quot; icon-position=&quot;right&quot; %}}Get Grav with icon right{{% /button %}}</p>
<p>{{% children  %}}</p>
<p>{{%expand &quot;test expand&quot;%}}
Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
{{% /expand%}}</p>
<p>{{<mermaid align="left">}}
graph LR;
A[Hard edge] --&gt;|Link text| B(Round edge)
B --&gt; C{Decision}
C --&gt;|One| D[Result one]
C --&gt;|Two| E[Result two]
{{&lt; /mermaid &gt;}}</p>
<pre><code class="language-mermaid">graph LR;
  A[Hard edge] --&gt;|Link text| B(Round edge)
    B --&gt; C{Decision}
    C --&gt;|One| D[Result one]
    C --&gt;|Two| E[Result two]
</code></pre>
<p>{{<mermaid>}}
sequenceDiagram
participant Alice
participant Bob
Alice-&gt;&gt;John: Hello John, how are you?
loop Healthcheck
John-&gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts <br/>prevail...
John--&gt;Alice: Great!
John-&gt;Bob: How about you?
Bob--&gt;John: Jolly good!
{{&lt; /mermaid &gt;}}</p>
<pre><code class="language-mermaid">sequenceDiagram
    participant Alice
    participant Bob
    Alice-&gt;&gt;John: Hello John, how are you?
    loop Healthcheck
        John-&gt;John: Fight against hypochondria
    end
    Note right of John: Rational thoughts 
prevail...
    John--&gt;Alice: Great!
    John-&gt;Bob: How about you?
    Bob--&gt;John: Jolly good!
</code></pre>
<p>{{% notice note %}}
A notice disclaimer
{{% /notice %}}</p>
<p>{{% notice info %}}
An information disclaimer
{{% /notice %}}</p>
<p>{{% notice tip %}}
A tip disclaimer
{{% /notice %}}</p>
<p>{{% notice warning %}}
An warning disclaimer
{{% /notice %}}</p>
<p><code>editURL</code> Value : {{% siteparam &quot;editURL&quot; %}}</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="1安装"><a class="header" href="#1安装">1.安装</a></h2>
<pre><code class="language-bash">
# 在各台服务器上，新建用户minio
useradd minio
su minio

cd ~/
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
</code></pre>
<h2 id="2分布式部署"><a class="header" href="#2分布式部署">2.分布式部署</a></h2>
<p>采用单节点，多drivers模式</p>
<h3 id="21防火墙配置"><a class="header" href="#21防火墙配置">2.1防火墙配置</a></h3>
<pre><code class="language-bash">firewall-cmd --permanent --zone=public --add-port=9000-9001/tcp
firewall-cmd --reload

#如果使用云服务器，需要在云厂商管理后台中配置防火墙规则
</code></pre>
<h3 id="22dns配置"><a class="header" href="#22dns配置">2.2DNS配置</a></h3>
<pre><code class="language-bash">
# 1.设置主机名称
vim /etc/hostname
  dev-oss4.htjicon.com


# 2.设置DNS
vim /etc/hosts
  192.168.1.121 dev-oss1.htjicon.com
  192.168.1.122 dev-oss2.htjicon.com
  192.168.1.123 dev-oss3.htjicon.com
  192.168.1.124 dev-oss4.htjicon.com
</code></pre>
<h3 id="23挂载本地硬盘"><a class="header" href="#23挂载本地硬盘">2.3挂载本地硬盘</a></h3>
<pre><code class="language-bash">
# 确保部署中的所有节点使用具有相同容量（例如TB）的相同类型（NVMe、SSD 或 HDD）驱动器。MinIO 不区分驱动器类型，也不受益于混合存储类型。此外。MinIO 将每个磁盘使用的大小限制为部署中的最小驱动器。例如，如果部署有 15 个 10TB 磁盘和 1 个 1TB 磁盘，MinIO 将每个磁盘的容量限制为 1TB。

# MinIO需要在创建新部署时使用扩展符号{x...y}来表示一系列连续的磁盘，其中部署中的所有节点都有一组相同的已安装驱动器。MinIO 还要求物理磁盘的顺序在重新启动时保持不变，以便给定的挂载点始终指向相同的格式化磁盘。因此，MinIO强烈建议使用/etc/fstab或类似的基于文件的挂载配置，以确保重启后驱动器顺序不会改变。

mkfs.xfs /dev/sdb -L DISK1
mkfs.xfs /dev/sdc -L DISK2
mkfs.xfs /dev/sdd -L DISK3
mkfs.xfs /dev/sde -L DISK4

nano /etc/fstab

  # &lt;file system&gt;  &lt;mount point&gt;  &lt;type&gt;  &lt;options&gt;         &lt;dump&gt;  &lt;pass&gt;
  LABEL=DISK1      /mnt/disk1     xfs     defaults,noatime  0       2
  LABEL=DISK2      /mnt/disk2     xfs     defaults,noatime  0       2
  LABEL=DISK3      /mnt/disk3     xfs     defaults,noatime  0       2
  LABEL=DISK4      /mnt/disk4     xfs     defaults,noatime  0       2

</code></pre>
<h3 id="24创建systemd服务文件"><a class="header" href="#24创建systemd服务文件">2.4创建systemd服务文件</a></h3>
<pre><code class="language-bash">vim /usr/lib/systemd/system/minio.service
    [Unit]
    Description=MinIO
    Documentation=https://docs.min.io
    Wants=network-online.target
    After=network-online.target
    AssertFileIsExecutable=/home/minio/minio

    [Service]
    WorkingDirectory=/home/minio

    User=minio
    Group=minio
    ProtectProc=invisible

    EnvironmentFile=/home/minio/.bashrc
    ExecStartPre=/bin/bash -c &quot;if [ -z \&quot;${MINIO_VOLUMES}\&quot; ]; then echo \&quot;Variable MINIO_VOLUMES not set in /etc/default/minio\&quot;; exit 1; fi&quot;
    ExecStart=/home/minio/minio server $MINIO_OPTS $MINIO_VOLUMES

    # Let systemd restart this service always
    Restart=always

    # Specifies the maximum file descriptor number that can be opened by this process
    LimitNOFILE=1048576

    # Specifies the maximum number of threads this process can create
    TasksMax=infinity

    # Disable timeout logic and wait until process is stopped
    TimeoutStopSec=infinity
    SendSIGKILL=no

    [Install]
    WantedBy=multi-user.target

    # Built for ${project.name}-${project.version} (${project.name})

</code></pre>
<h3 id="25设置环境变量"><a class="header" href="#25设置环境变量">2.5设置环境变量</a></h3>
<pre><code class="language-bash">vim /home/minio/.bashrc
    # .bashrc

    # Source global definitions
    if [ -f /etc/bashrc ]; then
        . /etc/bashrc
    fi

    # Uncomment the following line if you don't like systemctl's auto-paging feature:
    # export SYSTEMD_PAGER=

    # User specific aliases and functions

    # Set the hosts and volumes MinIO uses at startup
    # The command uses MinIO expansion notation {x...y} to denote a
    # sequential series.
    #
    # The following example covers four MinIO hosts
    # with 4 drives each at the specified hostname and drive locations.
    # The command includes the port that each MinIO server listens on
    # (default 9000)

    # http://dev-oss{01...04}.example.com:9000/mnt/disk{1...4}/minio
    MINIO_VOLUMES=&quot;/home/minio/data{1...4}&quot;

    # Set all MinIO server options
    #
    # The following explicitly sets the MinIO Console listen address to
    # port 9001 on all network interfaces. The default behavior is dynamic
    # port selection.

    MINIO_OPTS=&quot;--console-address :9001&quot;

    # Set the root username. This user has unrestricted permissions to
    # perform S3 and administrative API operations on any resource in the
    # deployment.
    #
    # Defer to your organizations requirements for superadmin user name.

    MINIO_ROOT_USER=admin

    # Set the root password
    #
    # Use a long, random, unique string that meets your organizations
    # requirements for passwords.

    MINIO_ROOT_PASSWORD=adminadmin

    # Set to the URL of the load balancer for the MinIO deployment
    # This value *must* match across all MinIO servers. If you do
    # not have a load balancer, set this value to to any *one* of the
    # MinIO hosts in the deployment as a temporary measure.
    MINIO_SERVER_URL=&quot;http://127.0.0.1:9000&quot;

</code></pre>
<h3 id="26启动minio服务"><a class="header" href="#26启动minio服务">2.6启动minio服务</a></h3>
<pre><code class="language-bash">
ln -s /usr/lib/systemd/system/minio.service /etc/systemd/system/multi-user.target.wants/minio.service
systemctl start minio.service

systemctl status minio.service
journalctl -f -n 1000 -u minio.service

systemctl stop minio.service

# Enable startup on boot
systemctl enable minio.service
# Disable MinIO service
systemctl disable minio.service
</code></pre>
<h2 id="3操作minio"><a class="header" href="#3操作minio">3.操作minio</a></h2>
<h3 id="31扩容"><a class="header" href="#31扩容">3.1扩容</a></h3>
<pre><code class="language-bash">vim /home/minio/.bashrc
    MINIO_VOLUMES=&quot;/home/minio/data{1...4}&quot;
    # 修改为
    MINIO_VOLUMES=&quot;/home/minio/data{1...4} /home/minio/data{5...8}&quot;

systemctl restart minio.service
</code></pre>
<h3 id="32减容"><a class="header" href="#32减容">3.2减容</a></h3>
<pre><code class="language-bash">./mc admin decommission status dev-minio
┌─────┬─────────────────────────┬─────────────────────────────────┬────────┐
│ ID  │ Pools                   │ Capacity                        │ Status │
│ 1st │ /home/minio/data{1...4} │ 67 GiB (used) / 3.0 TiB (total) │ Active │
│ 2nd │ /home/minio/data{5...8} │ 67 GiB (used) / 3.0 TiB (total) │ Active │
└─────┴─────────────────────────┴─────────────────────────────────┴────────┘


./mc admin decommission start dev-minio/ /home/minio/data{1...4}
    Decommission started successfully for `/home/minio/data{1...4}`.


./mc admin decommission status dev-minio
┌─────┬─────────────────────────┬─────────────────────────────────┬──────────┐
│ ID  │ Pools                   │ Capacity                        │ Status   │
│ 1st │ /home/minio/data{1...4} │ 67 GiB (used) / 3.0 TiB (total) │ Draining │
│ 2nd │ /home/minio/data{5...8} │ 68 GiB (used) / 3.0 TiB (total) │ Active   │
└─────┴─────────────────────────┴─────────────────────────────────┴──────────┘

./mc admin decommission status dev-minio /home/minio/data{1...4}
    Decommissioning rate at 155 B/sec [67 GiB/3.0 TiB]
    Started: 1 minute ago


# 如果状态读取为失败，您可以重新运行该 命令以恢复该过程。对于持续性故障，使用或查看日志（例如）以识别更具体的错误。
./mc admin console dev-minio
journalctl -f -n 1000 -u minio


# 执行完成后，修改启动命令参数
vim /home/minio/.bashrc
    MINIO_VOLUMES=&quot;/home/minio/data{1...4} /home/minio/data{5...8}&quot;
    # 修改为
    MINIO_VOLUMES=&quot;/home/minio/data{5...8}&quot;

# 重启minio
systemctl restart minio

# 删除老文件目录
rm -rf /home/minio/data1 /home/minio/data2 /home/minio/data3 /home/minio/data4
</code></pre>
<h3 id="33升级minio"><a class="header" href="#33升级minio">3.3升级minio</a></h3>
<pre><code class="language-bash">cd /home/minio
wget https://dl.min.io/server/minio/release/linux-amd64/minio minio2
chmod +x minio2
chown minio:minio minio2
mv minio2 minio

./mc admin service restart dev-minio
# 或者
systemctl restart minio
</code></pre>
<h2 id="4配置"><a class="header" href="#4配置">4.配置</a></h2>
<pre><code class="language-bash"># 版本控制

# 对象锁定功能

</code></pre>
<h2 id="5异常情况"><a class="header" href="#5异常情况">5.异常情况</a></h2>
<pre><code class="language-bash"># 软件异常 文件损坏 
/data5/public/Downloads/mock-partner-service-java.zip
echo &quot;aaa&quot; &gt; xl.meta
# 文件改动后，会自动修复


# 硬件异常 硬盘损坏 异常断电

# 一节点 4driver的情况下，删除一个或者两个driver目录，minio会自动修复目录，删除两个以上的driver后，数据无法修复
ls
data1
data2
data3
data4

rm -rf data1
data2
data3
data4

./mc admin heal dev-minio/public
 ◓  public
    0/0 objects; 0 B in 1s
    ┌────────┬───┬─────────────────────┐
    │ Green  │ 0 │   0.0%              │
    │ Yellow │ 3 │  75.0% █████████    │
    │ Red    │ 1 │  25.0% ███          │
    │ Grey   │ 0 │   0.0%              │
    └────────┴───┴─────────────────────┘

# 如果不出现硬件故障，driver可用的情况下，minio会自动修复数据

./mc admin heal dev-minio/public
 ◓  public
    0/0 objects; 0 B in 1s
    ┌────────┬───┬─────────────────────┐
    │ Green  │ 4 │ 100.0% ████████████ │
    │ Yellow │ 0 │   0.0%              │
    │ Red    │ 0 │   0.0%              │
    │ Grey   │ 0 │   0.0%              │
    └────────┴───┴─────────────────────┘


</code></pre>
<h2 id="6纠删码"><a class="header" href="#6纠删码">6.纠删码</a></h2>
<pre><code class="language-bash"># EC:N默认设置
# 当drivers个数小于等于5时，EC:2
# 当drivers个数6-7时，EC:3
# 当drivers个数大于等于8时，EC:4

# If N is equal to exactly 1/2 the drives in the erasure set, MinIO write quorum requires N+1 drives to avoid data inconsistency (“split-brain”).

# Minio使用纠删码erasure code和校验和checksum来保护数据免受硬件故障和无声数据损坏。 即便您丢失一半数量（N/2）的硬盘，您仍然可以恢复数据。

# 纠删码的工作原理和RAID或者复制不同，像RAID6可以在损失两块盘的情况下不丢数据，而Minio纠删码可以在丢失一半的盘的情况下，仍可以保证数据安全。 而且Minio纠删码是作用在对象级别，可以一次恢复一个对象，而RAID是作用在卷级别，数据恢复时间很长。 Minio对每个对象单独编码，存储服务一经部署，通常情况下是不需要更换硬盘或者修复。Minio纠删码的设计目标是为了性能和尽可能的使用硬件加速。

# 如果8个driver，最大可以4个driver出现故障，此时可以读取数据；当小于4个driver出现故障时，可以写入数据
# 如果4个driver，最大可以2个driver出现故障，此时可以读取数据；当小于2个driver出现故障时，可以写入数据
# 注意扩容时的数据，由4driver扩容到8driver时，当前版本[RELEASE.2022-05-23T18-45-11Z],如果老的4个driver出现故障后整个集群会异常，数据丢失。


# 什么是位衰减bit rot保护?
# 位衰减又被称为数据腐化Data Rot、无声数据损坏Silent Data Corruption,是目前硬盘数据的一种严重数据丢失问题。硬盘上的数据可能会神不知鬼不觉就损坏了，也没有什么错误日志。正所谓明枪易躲，暗箭难防，这种背地里犯的错比硬盘直接咔咔宕了还危险。 不过不用怕，Minio纠删码采用了高速 HighwayHash 基于哈希的校验和来防范位衰减。

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>LeoFS is a highly available, distributed, eventually consistent object/blob store. If you are searching a storage system that is able to store huge amount and various kind of files such as photo, movie, log data and so on, LeoFS is suitable for that.
Leofs是一个高可靠性、分布式、最终一致性的对应存储。如果你需要一个存储系统用来存储巨量的各种类型的文件比如图片、视频、大文件等等。leofs适用于这种情况</p>
<p>功能设计</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.2%20Leofs//images/screenshot_1527428802419.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>1.download 源码 git clone <a href="https://github.com/leo-project/leofs.git">https://github.com/leo-project/leofs.git</a></p>
<p>2.需要的依赖项：Erlang</p>
<p>3.打开项目的readme，按照其中安装方法安装</p>
<ol start="4">
<li></li>
</ol>
<p>cd leofs/
make
make release
cp -r package {LEOFS_DEPLOYED_DIR}
cd {LEOFS_DEPLOYED_DIR}/</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.2%20Leofs//images/screenshot_1527428834643.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p><a href="http://leo-project.net/leofs/docs/installation/install_4.html">http://leo-project.net/leofs/docs/installation/install_4.html</a></p>
<p>Firewall Rules
In order for LeoFS to work correctly, it is necessary to set and check the firewall rules in your environment as follows:
Subsystem Direction Ports Notes
LeoFS Manager-Master Incoming 10010/<em>Manager console
LeoFS Manager-Master Incoming 4369/</em> Erlang Port Mapper
LeoFS Manager-Master Incoming 4020/<em>SNMP Listen Port
LeoFS Manager-Master Outgoing</em>/4369 Erlang Port Mapper
LeoFS Manager-Slave Incoming 10011/<em>Manager console
LeoFS Manager-Slave Incoming 4369/</em> Erlang Port Mapper
LeoFS Manager-Slave Incoming 4021/<em>SNMP Listen Port
LeoFS Manager-Slave Outgoing</em>/4369 Erlang Port Mapper
LeoFS Storage Incoming 4369/<em>Erlang Port Mapper
LeoFS Storage Incoming 4010/</em> SNMP Listen Port
LeoFS Storage Outgoing <em>/4369 Erlang Port Mapper
LeoFS Gateway Incoming 8080/</em> HTTP listen port
LeoFS Gateway Incoming 8443/<em>HTTPS listen port
LeoFS Gateway Incoming 4369/</em> Erlang Port Mapper
LeoFS Gateway Incoming 4000/<em>SNMP Listen Port
LeoFS Gateway Outgoing</em>/4369 Erlang Port Mapper
ALL Both [1] Erlang RPC to others
[1] Port range can be specified by setting the kernel variables ‘inet_dist_listen_min’ AND ‘inet_dist_listen_max’
Example
%%% This forces Erlang to use only ports 9100--9105 for distributed Erlang traffic. application:set_env(kernel, inet_dist_listen_min, 9100). application:set_env(kernel, inet_dist_listen_max, 9105).</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.2%20Leofs//images/screenshot_1527428848958.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>Shell Description
一般命令
leofs-adm status [<node>] • Retrieve status of every node (default)检索所有节点的状态
• Retrieve status of the specified node 检索特定节点的状态
leofs-adm whereis <file-path> • Retrieve an assigned object by the file-path 检索指定的object的路径
LeoFS Storage MQ Operation [1.2.0-]
leofs-adm mq-stats <storage-node> • See the statuses of message queues used in LeoFS Storage
leofs-adm mq-suspend <storage-node> <mq-id> • Suspend a process consuming a message queue
• Active message queues only can be suspended
• While suspending, no messages are consumed
leofs-adm mq-resume <storage-node> <mq-id> • Resume a process consuming a message queue
Recover Commands
leofs-adm recover-file <file-path> • Recover an inconsistent object specified by the file-path
leofs-adm recover-node <storage-node> • Recover all inconsistent objects in the specified node
leofs-adm recover-ring <storage-node> • Recover rings of the specified node
leofs-adm recover-cluster <cluster-id> • v1.0.0- Recover all inconsistent objects in the specified cluster
Data Compaction Commands
Disk Usage
leofs-adm du <storage-node> • See the current disk usages
leofs-adm du detail <storage-node> • See the current disk usages in the details
LeoFS Gateway Operation
leofs-adm purge-cache <file-path> • Remove the cache from each LeoFS gateway
leofs-adm remove-gateway <gateway-node> • Remove the LeoFS Gateway node, which is already stopped
LeoFS Manager Maintenance
leofs-adm backup-mnesia <backup-filepath> • Copy LeoFS’s Manager data to the filepath
leofs-adm restore-mnesia <backup-filepath> • Restore LeoFS’s Manager data from the backup file
leofs-adm update-managers <manager-master> <manager-slave> • Update LeoFS Manager nodes
• Destribute the new LeoFS Manager nodes to LeoFS Storage and Gateway
leofs-adm dump-ring (<manager-node>|<storage-node>|<gateway-node>) • Dump the ring data to the local disk
S3-API Commands - User
leofs-adm create-user <user-id> <password> • Register the new user
• Generate an S3 key pair (AccessKeyID and SecretAccessKey)
leofs-adm delete-user <user-id> • Remove the user
leofs-adm get-users • Retrieve the list of users
leofs-adm update-user-role • Update the user’s role
• Currently, we are supporting two kinds of roles
• 1: General user, 9: Administrator
S3-API Commands - Endpoint
leofs-adm add-endpoint <endpoint> • Register a new S3 Endpoint
• LeoFS’ domains are ruled by this rule
leofs-adm delete-endpoint <endpoint> • Remove the endpoint
leofs-adm get-endpoints • Retrieve the list of endpoints
S3-API Commands - Bucket
leofs-adm add-bucket <bucket> <access-key-id> • Create the new bucket
leofs-adm delete-bucket <bucket> <access-key-id> • Remove the bucket and all files stored in the bucket
leofs-adm get-buckets • Retrieve the list of the buckets registered
leofs-adm get-bucket <access-key-id> • Retrieve the list of the buckets owned by the specified user
leofs-adm chown-bucket <bucket> <access-key-id> • v0.16.5- Change the owner of the bucket
leofs-adm update-acl <bucket> <access-key-id> (private | public-read | public-read-write) • v0.16.0- Update the ACL (Access Control List) for the bucket
• Available ACL list:
○ private (default) : No one except the owner has access rights
○ public-read : All users have READ access
○ public-read-write : All users have READ and WRITE access
Multi Data Center Operation
leofs-adm join-cluster <manager-master> <manager-slave> 1.0.0- Begin to communicate between the local cluster and the remote cluster
leofs-adm remove-cluster <manager-master> <manager-slave> 1.0.0- Terminate to communicate between the local cluster and the remote cluster
leofs-adm cluster-status 1.0.0- See the current state of cluster(s)</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.2%20Leofs//images/screenshot_1527428859897.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>Shell Description 描述
leofs-adm detach <storage-node> • Remove the storage node from the LeoFS storage cluster 移除
• Current status: running | stop 可以使用
leofs-adm rollback storage_0@127.0.0.1 恢复（当node状态是detach时）</p>
<p>leofs-adm suspend <storage-node> • Suspend a storage node for maintenance 挂起
• This command is NOT similar to the detach command, just only to suspend the node.
• While suspending, it rejects any requests
• Current status: running
leofs-adm resume <storage-node> • Resume a storage node until a finished maintenance 恢复
• Current status: suspended | restarted
leofs-adm start • Start LeoFS after distributing the RING from LeoFS Manager to LeoFS Storage and Gateway 第一次启动时，初始化数据库以及数据
leofs-adm rebalance • Commit detached and attached nodes to update the cluster and Ring(routing-table) 在node加入集群或者离开集群时，需要调用该命令来重新刷新ring
• Rebalance objects in the cluster which is based on the updated cluster topology
• Current status: attached</p>
<p>leofs-adm compact-start <storage-node> (all|<num-of-targets>) [<num-of-compaction-proc>] • Remove unnecessary objects from the node delete操作无法删除持久化的数据，
• num-of-targets: It controls the number of containers in parallel 使用该命令移除多余的数据
• num-of-compaction-procs: It controls the number of procs to execute the compaction in parallel
leofs-adm compact-suspend <storage-node> • Suspend the compaction 压缩挂起
leofs-adm compact-resume <storage-node> • Resume the compaction 压缩重新启动
leofs-adm compact-status <storage-node> • See the current compaction status 目前的状态，包括压缩状态，目前正在压缩的containers in parallel，等待压缩哦containers in parallel
• Compaction’s status: idle, running, suspend
leofs-adm diagnose-start <storage-node> • v1.1.5- Diagnose data of a target storage node 诊断</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.2%20Leofs//images/screenshot_1527428873410.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>Here is the list of available events in ejabberd. The types of the corresponding hooks parameters is described below.</p>
<p>adhoc_local_items(Acc, From, To, Lang) -&gt; Adhoc
adhoc_sm_items(Acc, From, To, Lang) -&gt; Adhoc
anonymous_purge_hook(User, Server) -&gt; ok
c2s_auth_result(bool(), User, Server, IP) -&gt; ok
c2s_broadcast_recipients(Acc, Server, StateData, Type, From, Packet) -&gt; []
c2s_filter_packet(Acc, Server, C2SState, Feature, To, Packet) -&gt; bool()
c2s_filter_packet_in(Acc, JID, From, To) -&gt; FixedPacket
c2s_loop_debug({route, From, To, Packet}) -&gt; ok
c2s_loop_debug(Text) -&gt; ok
c2s_loop_debug({xmlstreamelement, Packet}) -&gt; ok
c2s_post_auth_features(Acc, Server) -&gt; []
c2s_presence_in(Acc, {From, To, Packet}) -&gt; C2SState
c2s_stream_features(Acc, Server) -&gt; []
c2s_unauthenticated_iq(Acc, Server, IQ, IP) -&gt; empty | Packet
c2s_update_presence(Acc, User, Server) -&gt; Packet
caps_update(From, To, get_features(Server, Caps)) -&gt; ok
csi_filter_stanza(Acc, Stanza) -&gt; send
disco_info(Acc, Host, Module, Node, Lang) -&gt; []
disco_local_features(Acc, From, To, Node, Lang) -&gt; Disco
disco_local_identity(Acc, From, To, Node, Lang) -&gt; []
disco_local_items(Acc, From, To, Node, Lang) -&gt; Disco
disco_sm_features(Acc, From, To, Node, Lang) -&gt; Disco
disco_sm_identity(Acc, From, To, Node, Lang) -&gt; []
disco_sm_items(Acc, From, To, Node, Lang) -&gt; Disco
filter_packet(Acc) -&gt; OrigPacket
forbidden_session_hook(JID) -&gt; ok
http_request_debug({LocalPath, Request}) -&gt; ok
local_send_to_resource_hook(From, To, Packet) -&gt; ok
muc_filter_message(Stanza, MUCState, RoomJID, FromJID, FromNick) -&gt; Stanza drop
muc_filter_presence(Stanza, MUCState, RoomJID, FromJID, FromNick) -&gt; Stanza drop
offline_message_hook(From, To, Packet) -&gt; ok
presence_probe_hook(From, To, Pid) -&gt; ok
privacy_check_packet(Acc, User, Server, PrivacyList, {From, To, Packet}, Dir) -&gt; Auth
privacy_get_user_list(Acc, User, Server) -&gt; #userlist{}
privacy_iq_get(Acc, From, To, IQ, PrivacyList) -&gt; {result, Packet} | {error, Error}
privacy_iq_set(Acc, From, To, IQ) -&gt; {result, Packet} | {error, Error}
privacy_updated_list(Acc, PrivacyList, PrivList) -&gt; bool()
pubsub_create_node(ServerHost, Host, Node, NodeId, NodeOptions) -&gt; ok
pubsub_delete_node(ServerHost, Host, Node, NodeId) -&gt; ok
pubsub_publish_item(ServerHost, Node, Publisher, service_jid(Host), ItemId, Payload) -&gt; ok
register_user(User, Server) -&gt; ok
remove_user(User, Server) -&gt; ok
reopen_log_hook() -&gt; ok
resend_offline_messages_hook(Acc, User, Server) -&gt; []
resend_subscription_requests_hook(Acc, User, Server) -&gt; []
roster_get(Acc, {User, Server}) -&gt; []
roster_get_jid_info(Acc, User, Server, From) -&gt; []}
roster_get_subscription_lists(Acc, User, Server) -&gt; []}
roster_get_versioning_feature(Acc, Server) -&gt; []
roster_groups(Acc, ServerHost) -&gt; []
roster_in_subscription(Acc, User, Server, From, SubscriptionInType, Reason) -&gt; bool()
roster_out_subscription(User, Server, To, SubscriptionOutType) -&gt; ok
roster_process_item(Acc, Server) -&gt; RosterItem
s2s_allow_host(Acc, Host, Host) -&gt; Auth
s2s_connect_hook(Host, Server) -&gt; ok
s2s_loop_debug({xmlstreamelement, Packet}) -&gt; ok
s2s_receive_packet(From, To, Packet) -&gt; ok
s2s_send_packet(From, To, Packet) -&gt; ok
s2s_stream_features(Acc, Server) -&gt; []
set_presence_hook(User, Server, Resource, Presence) -&gt; ok
sm_register_connection_hook(SID, JID, Info) -&gt; ok
sm_remove_connection_hook(SID, JID, Info) -&gt; ok
unset_presence_hook(User, Server, Resource, Status) -&gt; ok
user_available_hook(JID) -&gt; ok
user_ping_timeout(JID) -&gt; ok
user_receive_packet(Packet, C2SState, JID, From, To) -&gt; Packet
user_send_packet(Packet, C2SState, From, To) -&gt; Packet
vcard_set(User, Server, VCARD) -&gt; ok
webadmin_menu_host(Acc, Host, Lang) -&gt; []
webadmin_menu_hostnode(Acc, Host, Node, Lang) -&gt; []
webadmin_user(Acc, User, Server, Lang) -&gt; []
webadmin_user_parse_query(Acc, Action, User, Server, Query) -&gt; []</p>
<p>Hooks parameters data types
To = From = JID = ServerJID = #jid (see jlib.h)
Packet = Payload = {xmlelement, Name, Attrs, SubEl}
IQ = #iq (see jlib.h)
Error = ?STANZA_ERROR/3 (see jlib.h)
Lang = binary()
Dir = in | out
Auth = allow | deny
PrivacyList = OldPrivacyList = NewPrivacyList = none | #userlist
CtlStatus = false | ?STATUS_SUCCESS | ?STATUS_ERROR | ?STATUS_USAGE | ?STATUS_BADRPC (see ejabberd_ctl.hrl)
Adhoc = {result, I} | {error, Error} | empty
Disco = {result, Items} | {error, Error}
Items = Packet
Arg = [string()]
Node = [string()]
ItemID = string()
Route = {route, From, To, Packet}
RosterItem = #roster (see mod_roster.hrl)
Subscription = none | from | to | both | remove
SubscriptionInType = subscribe | unsubscribe
SubscriptionOutType = subscribed | unsubscribed
Reason = binary()
Groups = [string()]
SimpleJID = FromSubscription = ToSubscription = {User, Server, Resource}
User = binary()
Server = binary()
Resource = binary()
Status = binary()
SID = {Time, pid()}
Time = {MegaSecs, Secs, MicroSecs} (see erlang:now/0)
MegaSecs = Secs = MicroSecs = int()
Acc = same type as the return type of the function</p>
<div style="break-before: page; page-break-before: always;"></div><p>filter_packet (run_hook)
ejabberd_hooks:run_fold(filter_packet, {OrigFrom, OrigTo, OrigPacket}, []).</p>
<div style="break-before: page; page-break-before: always;"></div><p>Ejabberd扩展案例
源码：<a href="https://github.com/processone/ejabberd/blob/master/src/mod_echo.erl">https://github.com/processone/ejabberd/blob/master/src/mod_echo.erl</a></p>
<p>Ejabberd通用扩展包说明
源码：<a href="https://github.com/processone/ejabberd-contrib">https://github.com/processone/ejabberd-contrib</a></p>
<p>基于现在的扩展模式，做出的通用性的拓展功能</p>
<div style="break-before: page; page-break-before: always;"></div><p>Web服务器，basho出品
git地址:<a href="https://github.com/ninenines/cowboy">https://github.com/ninenines/cowboy</a></p>
<p>Dispatch组合</p>
<p>静态文件
erlydtl模块动态文件</p>
<div style="break-before: page; page-break-before: always;"></div><div class="table-wrapper"><table><thead><tr><th></th><th><a href="http://www.kbengine.org/">http://www.kbengine.org/</a></th><th>C++ python</th></tr></thead><tbody>
<tr><td></td><td></td><td></td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><p><a href="https://github.com/basho/rebar/">https://github.com/basho/rebar/</a></p>
<p>配置文件说明：<a href="https://github.com/basho/rebar/blob/master/rebar.config.sample">https://github.com/basho/rebar/blob/master/rebar.config.sample</a></p>
<p>使用案例：
<a href="http://dhq.me/build-compile-eunit-release-erlang-application-with-rebar">http://dhq.me/build-compile-eunit-release-erlang-application-with-rebar</a></p>
<p>1.git clone git://github.com/basho/rebar.git</p>
<p>2.cd rebar
./bootstrap</p>
<p>Recompile: src/rebar
==&gt; rebar (compile)
==&gt; rebar (escriptize)
Congratulations! You now have a self-contained script called &quot;rebar&quot; in
your current working directory. Place this script anywhere in your path
and you can use rebar to build OTP-compliant apps.</p>
<p>3.rebar commond
./rebar -h
./rebar compile eunit</p>
<p>注意：rebar编译一定需要是application的文件结构，即必须包含：_app.erl_app.src_sup.erl</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="开源的图像处理软件"><a class="header" href="#开源的图像处理软件">开源的图像处理软件</a></h2>
<p>GraphicsMagick官网
GraphicsMagick编程接口<br />
GraphicsMagick 命令行参数，说明文档</p>
<p>GraphicsMagick的命令概览</p>
<hr />
<p>[ convert | identify | mogrify | composite | montage | compare | display | animate | import | conjure ]</p>
<p>convert：转换图像格式和大小，模糊，裁剪，驱除污点，抖动，临近，图片上画图片，加入新图片，生成缩略图等。
identify：描述一个或较多图像文件的格式和特性。
mogrify：按规定尺寸<em><strong>一个图像，模糊，裁剪，抖动等。Mogrify改写最初的图像文件然后写到一个不同的图像文件。
composite：根据一个图片或多个图片组合生成图片。
montage：创建一些分开的要素图像。在含有要素图像任意的装饰图片，如边框、结构、图片名称等。
compare：在算术上和视觉上评估不同的图片</strong></em>其它的改造图片。
display：如果你拥有一个X server的系统，它可以按次序的显示图片
animate：利用X server显示动画图片
import：在X server或任何可见的窗口上输出图片文件。 你可以捕获单一窗口，整个的荧屏或任何荧屏的矩形部分。
conjure：解释执行 MSL (Magick Scripting Language) 写的脚本。</p>
<p>需要安装的依赖库函数
png <a href="http://www.libpng.org/pub/png/pngcode.html">http://www.libpng.org/pub/png/pngcode.html</a> apt-get install libpng
www.zlib.net yum install libpng-devel
jpg <a href="http://www.remotesensing.org/libtiff/">http://www.remotesensing.org/libtiff/</a> apt-get install libtiff
yum install libtiff-devel</p>
<div style="break-before: page; page-break-before: always;"></div><div class="table-wrapper"><table><thead><tr><th>显示图像文件详细信息</th><th>gm identify a.jpg</th></tr></thead><tbody>
<tr><td>更改当前目录下*.jpg的尺寸大小，并保存于目录.thumb里面</td><td>gm mogrify -output-directory .thumbs -resize 320x200 *.jpg</td></tr>
<tr><td>将三幅图像和并为一副图像</td><td>gm montage -mode concatenate -tile 3x1 image1.ppm image2.ppm image3.ppm concatenated.miff</td></tr>
<tr><td>显示图像</td><td>gm display 'vid:*.jpg'</td></tr>
<tr><td>格式转换</td><td>gm convert a.bmp a.jpg || gm convert a.bmp a.pdf（转换为pdf)</td></tr>
<tr><td>调整图像dpi和大小</td><td>gm convert -density 288 -geometry 25% image.gif image.gif（缩小为原先的1／4，并且dpi为288）gm convert -resize 640x480 image.gif image.gif（转换为640x480的图像)</td></tr>
<tr><td>在图像上添加文字</td><td>gm convert -font Arial -fill blue -pointsize 18 -draw &quot;text 10,10 'your text here'&quot; test.tif test.png</td></tr>
<tr><td>从gif文件中抽取第一帧</td><td>gm convert &quot;Image.gif[0]&quot; first.gif</td></tr>
<tr><td>建立gif图像</td><td>gm convert -delay 20 frame*.gif animation.gif gm convert -loop 50 frame*.gif animation.gif（让动画循环50次）gm convert -delay 20 frame1.gif -delay 10 frame2.gif -delay 5 frame3.gif animation.gif（对每一帧手动指定延时）</td></tr>
<tr><td>截屏</td><td>gm import a.jpg 用鼠标点击所要截取的窗口，或者选择截屏区域，保存为a.jpg gm import -frame a.jpg 保留窗口的边框</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h2 id="graphicsmagick缩放比例的精准控制"><a class="header" href="#graphicsmagick缩放比例的精准控制">GraphicsMagick缩放比例的精准控制</a></h2>
<p>原始图片是input.jpg，尺寸：160x120只缩小不放大
gm convert input.jpg -resize &quot;500x500&gt;&quot; output_1.jpg
加了&gt;,表示只有当图片的宽与高，大于给定的宽与高时，才进行“缩小”操作。
生成的图片大小是：160x120，未进行操作
如果不加&gt;,会导致图片被比等放大。</p>
<p>等比缩图  （缺点：产生白边）
gm convert input.jpg -thumbnail &quot;100x100&quot; output_1.jpg</p>
<p>生成的图片大小是：100x75
非等比缩图，按给定的参数缩图
gm convert input.jpg -thumbnail &quot;100x100!&quot; output_2.jpg</p>
<p>生成的图片大小是：100x100
（缺点：长宽比会变化）
裁剪后保证等比缩图</p>
<p>gm convert input.jpg -thumbnail &quot;100x100^&quot; -gravity center -extent 100x100 output_3.jpg
生成的图片大小是：100x100，还保证了比例。不过图片经过了裁剪，剪了图片左右两边才达到1:1
（缺点：裁剪了图片的一部分）
填充后保证等比缩图</p>
<p>gm convert input.jpg -thumbnail &quot;100x100&quot; -background gray -gravity center -extent 100x100 output_4.jpg
生成的图片大小是：100x100，还保证了比例，同时没有对图片进行任何裁剪，缺失的部分按指定颜色进行填充。
（缺点：要填充颜色，和第一种方法基本一样）
裁剪、填充相结合</p>
<p>gm convert input.jpg -thumbnail &quot;10000@ -background gray -gravity center -extent 100x100 output_5.jpg
生成的图片大小是：</p>
<p>100x100，这次保证了大小和比例，其中的10000就是100x100的乘积，同时在填充和裁剪之间做了一个平衡。
（缺点：最差的方法）
位深度32 转为24 IE6,7,8不支持显示“位深度32”的图片，但IE9、火狐、谷歌浏览器就可以显示。
使用GM,把“位深度32”的图片转换为“位深度24”的图片
输入图片zzz.jpg就是“位深度32”的图片，输出图片 zzz_out.jpg就是“位深度24”的图片
gm convert -resize 100x100 -colorspace RGB zzz.jpg zzz_out.jpg
转完后，图片的颜色会有轻微变化。</p>
<p>原始图片（input.jpg：160x120）</p>
<p>缩略图1
gm convert input.jpg -thumbnail '100x100' output_1.jpg
实际生成的图片大小是：100x75，也就是说说按此命令，会保持图片比例不变生成缩略图。这样很不错，但是有一个潜在的问题：我们不能简单明 了的知道图片的最终大小，结果是前端显示的时候，无法设置img标签的width和height属性，如果我没记错的话，一般是推荐设定width和 height属性的，否则浏览器渲染起来可能会稍稍慢一点
缩略图2
gm convert input.jpg -thumbnail '100x100!' output_2.jpg 这次实际生成的图片大小按定义来，但图片变形了，有时候这是不能接受的。
缩略图3
gm convert input.jpg -thumbnail '100x100^' \ -gravity center -extent 100x100 output_3.jpg 这次不仅保证了大小，还保证了比例。不过图片经过了裁剪。
缩略图4
gm convert input.jpg -thumbnail '100x100' \ -background gray -gravity center -extent 100x100 output_4.jpg 这次不仅保证了大小，还保证了比例，同时没有对图片进行任何裁剪，多余的部分按指定颜色进行填充。
缩略图5
gm convert input.jpg -thumbnail '10000@' \ -background gray -gravity center -extent 100x100 output_5.jpg 这次保证了大小和比例，其中的10000就是100x100的乘积，同时在填充和裁剪之间做了一个平衡。</p>
<p>补充：如果想让用户手动裁剪头片的话，imgAreaSelect是个好选择。</p>
<p><img src="7.%20%E9%A1%B9%E7%9B%AE/7.7%20GraphicsMagick/7.7.1%20%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5//images/screenshot_1527428311215.png" alt="pic" /></p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>1.编译成动态库。
./configure --enable-shared
make
sudo make install</p>
<p>编写一个例子
gcc -o demo demo.c -O <code>GraphicsMagick-config --cppflags --ldflags --libs</code>
执行时出现：libGraphicsMagick++.so.12: cannot open shared object file: No such file or directory</p>
<p>原因应该是“原因可以归结为一句话：程序没有找到动态链接库，虽然这个动态链接库存在，但是默认情况下，编译器只会使用/lib和/usr/lib这两个目录下的库文件</p>
<p>所以需要添加lib库的路径
vim /etc/ld.so.conf</p>
<p>加入路径：
/usr/local/lib</p>
<p>ldconfig</p>
<p>然后就可以正常使用了</p>
<p>动态库：在程序执行时加载，所以可以编译成功，在执行时提示没有找到该动态库链接</p>
<p>2.多核心 OpenMP
export OMP_NUM_THREADS=4 %用来设置使用几个核心</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>terminate called after throwing an instance of 'Magick::WarningCoder'
what():  Magick: profile matches sRGB but writing iCCP instead (q1_80x80_100%.png) reported by coders/png.c:1076 (PNGWarningHandler)</p>
<p><a href="http://my.oschina.net/1pei/blog/479162#OSC_h1_1">http://my.oschina.net/1pei/blog/479162#OSC_h1_1</a></p>
<p>libpng 1.6+更严格的检查会对original HP/MS sRGB profile报警。老的profile使用D50 whitepoint, 而D65才是标准。这种profile由Adobe Photoshop使用, 虽然缺省在png图片中并不嵌入该profile。最简单的方法是从图片中删除内嵌的profile，但这会导致颜色有稍许偏差（当有颜色校正系统时）。但如果不希望颜色有偏差（例如用于打印输出）， 可以嵌入另一种不同的颜色profile。</p>
<p>解决方案1: 删除png图片内嵌的iCCP profile sRGB
gm convert -strip <input filename> <output filename></p>
<div style="break-before: page; page-break-before: always;"></div><p><a href="https://docs.mongodb.org">https://docs.mongodb.org</a></p>
<p>a) mongod - Mongodb服务通过执行该文件启动。启动时可指定数据存放目录及日志存放目录等。
b) mongos - Mongodb Sharding控制器，主要用在Mongodb分布式存储上，为数据的插入和查询提供路由服务。
c) mongo - Mongodb的CLI（Comannd Line Interface）为管理员或者开发人员提供操作mongodb的接口，纯命令行形式
d) mongodump - MongoDB dump工具，用于备份文件以及获取快照，可指定备份策略，同时配合mongorestore作为恢复数据库一起使用
e) mongorestore - MongoDB备份的恢复工具，配合mongodump一起使用
f) mongoexport - 对某个mongodb实例以Json或者CSV格式进行数据导出，若要导出所有数据，建议使用monogodump，同时配合mongoimport作为数据导入一起使用
g) mongoimport - 对某个mongodb实例导入Json或者CSV格式的数据，配合mongoexport一起使用
h) mongofiles - 用于往GridFS写入文件或者从GridFS中读取文件（GridFS是Monogodb提供的文件系统，用于管理数据文件）
i) mongostat - 用来查看当前运行的mongodb服务及mongos路由服务的状态
j) mongotop - 用来查看某个Mongodb实例的数据读写时间，并提供了某个数据库级别的数据读写时间，每秒返回统计值
k) mongosniff - 类似tcpdump的工具，主要用来实时查看mongodb的运行情况，更多时候是给开发人员使用
l) mongoperf - 用来检查mongodb运行时磁盘的IO情况</p>
<p>客户端：<a href="https://robomongo.org/">https://robomongo.org/</a></p>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-mongo"># rs.initiate(config),需要连接入某个节点

# rs.config()  rs.status() rs.isMaster()

# rs.add(&quot;server_4:27017&quot;)

# rs.addArb(&quot;localhost:30001&quot;) %添加仲裁者

# rs.remove(&quot;server_1:20000&quot;)

# var config = rs.config()

# config.memebers[0].host = &quot;server_1:20000&quot;

# rs.reconfig(config)

# rs.addArb(&quot;server_5:27017&quot;) 等效与 rs.add({&quot;_id&quot;:4, &quot;host&quot;:&quot;server_5:27017&quot;, &quot;arbiterOnly&quot;:true})

# rs.stepDown(600) %主节点降级为备份节点10分钟内没有选举出新的主节点，该节点可以重新加入选举

# rs.freeze(10000) %保持备份节点，不能参与选举成主节点

# rs.freeze(0) %释放, 参与选举成主节点

# c1 = (new Mongo(&quot;localhost:30001&quot;)).getDB(&quot;test&quot;)

# db1 = c2.getDB(&quot;test&quot;)

# db1.test.find()

# db1.test.count()

# db1.stats()

# db1.test.stats()

# sh,status()
# sh.enableSharding(&quot;test&quot;) #需要分片的数据库
# db.users.ensureIndex({&quot;username&quot;:1}) #片键 &quot;hashed&quot;
# sh.shardCollection(&quot;test.users&quot;, {&quot;username&quot;:1}) #&quot;hashed&quot;
# db.users.find({&quot;username&quot;:&quot;user12345&quot;}).explain()
# sh.addShard(&quot;ADCMS_HUIYU/192.168.1.101:20001&quot;)

# 查看配置服务器信息，链接上mongos， use config

# db.shards.find()

# db.databases.find()

# db.collection.find()

# db.chunks.find()
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>分片，根据分片数据库做该分片的集群
mongo分布式：Replica Set / Sharding</p>
<p>参考档案：
<a href="http://blog.csdn.net/luonanqin/article/details/8497860">http://blog.csdn.net/luonanqin/article/details/8497860</a></p>
<p>《MongoDB权威指南》第九章</p>
<p>集群方式：</p>
<p>主节点（primary）</p>
<p>备份节点（secondary，无法读取和写入）</p>
<p>仲裁者节点（参与选举）</p>
<p>注意：</p>
<p>1.一个mongo节点在初始化时需要指定replSet，才能加入集群，本地节点无法加入集群</p>
<p>2.备份节点正常情况无法读写，强制读取可以设置conn.setSlaveOk()</p>
<p>3.*.conf文件的项目路径 ./priv/etc/</p>
<p>4.分片。针对每一个分片节点做集群</p>
<p>5.指定数据库路径需要自己新建该目录。</p>
<p>6.集群就是各自启动一个节点，然后配置谁是主节点，谁是备份节点</p>
<p>配置集群：</p>
<p>sudo mongod -config master.conf(启动主节点)</p>
<p>sudo mongod -config slaver.conf(启动备份节点)</p>
<p>sudo mongod -config arbiter.conf(启动仲裁者节点)</p>
<p>登陆到主节点：</p>
<p>sudo mongo 192.168.1.101:27017   #ip和port是某个节点的地址</p>
<blockquote>
<p>cfg={
&quot;_id&quot;:&quot;ADCMS_HUIYU&quot;,
&quot;members&quot;:[
{&quot;_id&quot;:0,&quot;host&quot;:'10.10.148.130:27017',priority:2},
{&quot;_id&quot;:1,&quot;host&quot;:'10.10.148.131:27017',priority:1},
{&quot;_id&quot;:2,&quot;host&quot;:'10.10.148.132:27017',arbiterOnly:true}]};</p>
</blockquote>
<blockquote>
<p>rs.initiate(cfg)#使配置生效</p>
</blockquote>
<p>cfg的详细信息参考config.conf</p>
<blockquote>
<p>rs.status()查看节点详细信息</p>
</blockquote>
<p>客户端写入:
&gt;db.runCommand({“getLastError”:1, “w”:”majority”, “wtimeout”:1000})
该命令返回写入操作成功的节点名称</p>
<p>w:强制 getLastError等待，直到写入操作执行完才返回</p>
<p>wtimeout:超时时间</p>
<p>节点状态</p>
<p>STARTUP 刚出于启动状态
STARTUP2 整个初始化同步过程
RECONVERING 成员运转正常，但是暂时不能处理读取请求
ARBITER 仲裁者处于该状态
DOWN 正常运行的成员不可达
UNKOWN 成员无法到达其他任何成员
REMOVE 移出集群
ROLLBACK 进行数据回滚
FATAL 不可挽回的错误</p>
<p>分片</p>
<p>注意：</p>
<p>1.一个config配置节点集群，维护有多少个分片节点或者集群</p>
<p>2.一个mongos，对外的接口节点</p>
<p>3.多个mongod节点或者集群，一个mongod对应一个分片</p>
<p>4.分片需要指定基于什么规则到某个分片上查询数据</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="redis"><a class="header" href="#redis">redis</a></h2>
<pre><code class="language-bash">https://redis.io/

wget https://download.redis.io/releases/redis-6.2.6.tar.gz

tar -zxf redis-6.2.6.tar.gz

make

</code></pre>
<h2 id="config-2"><a class="header" href="#config-2">config</a></h2>
<pre><code class="language-config">
#bind 127.0.0.1

port 63098  #绑定端口

daemonize yes #是否后台启动

pidfile /var/run/redis_63098.pid
logfile &quot;log_63098.log&quot; #日志

databases 2  #启动多少个数据库

#   save &quot;&quot;

rdbcompression yes
rdbchecksum yes
dbfilename dump_63098.rdb  #dump_63098.rdb redis重启后不会通过该文件还原数据

appendonly yes    #appendonly.aof
appendfsync no     #依赖操作系统，对大多数Linux操作系统，是每30秒进行一次fsync，将缓冲区中的数据写到磁盘上
   everysec  #Redis会默认每隔一秒进行一次fsync调用，将缓冲区中的数据写到磁盘。但是当这一 次的fsync调用时长超过1秒时。Redis会采取延迟fsync的策略，再等一秒钟。也就是在两秒后再进行fsync，这一次的fsync就不管会执行多长时间都会进行。这时候由于在fsync时文件描述符会被阻塞，所以当前的写操作就会阻塞
   always   #每一次写操作都会调用一次fsync，这时数据是最安全的，当然，由于每次都会执行fsync，所以其性能也会受到影响


requirepass 1234567890

loglevel notice
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_line_numbers = true;
        </script>
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="ace.js" type="text/javascript" charset="utf-8"></script>
        <script src="editor.js" type="text/javascript" charset="utf-8"></script>
        <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
