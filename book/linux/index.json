[
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/1.%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/1.4.1-zip/",
	"title": "1.4.1 zip",
	"tags": [],
	"description": "",
	"content": "zip用法 zip -r myfile.zip ./* 将当前目录下的所有文件和文件夹全部压缩成myfile.zip文件,－r表示递归压缩子目录下所有文件. zip -r bbb.zip aaa bc.zip bbb 把当前文件夹下的 \u0026#34;aaa文件夹及其子文件、bc.zip、bbb文件夹及其子文件\u0026#34; 全都压缩成一个bbb.zip -a 将文件转成ASCII模式 -F 尝试修复损坏的压缩文件 -h 显示帮助界面 -m 将文件压缩之后，删除源文件 -n 特定字符串 不压缩具有特定字尾字符串的文件 -o 将压缩文件内的所有文件的最新变动时间设为压缩时候的时间 -q 安静模式，在压缩的时候不显示指令的执行过程 -r 将指定的目录下的所有子目录以及文件一起处理 -S 包含系统文件和隐含文件（S是大写） -t 日期 把压缩文件的最后修改日期设为指定的日期，日期格式为mmddyyyy zip [-AcdDfFghjJKlLmoqrSTuvVwXyz$][-b \u0026lt;工作目录\u0026gt;][-ll][-n \u0026lt;字尾字符串\u0026gt;][-t \u0026lt;日期时间\u0026gt;][-\u0026lt;压缩效率\u0026gt;][压缩文件][文件...][-i \u0026lt;范本样式\u0026gt;][-x \u0026lt;范本样式\u0026gt;]   -A 调整可执行的自动解压缩文件。 -b\u0026lt;工作目录\u0026gt; 指定暂时存放文件的目录。 -c 替每个被压缩的文件加上注释。 -d 从压缩文件内删除指定的文件。 -D 压缩文件内不建立目录名称。 -f 此参数的效果和指定\u0026rdquo;-u\u0026quot;参数类似，但不仅更新既有文件，如果某些文件原本不存在于压缩文件内，使用本参数会一并将其加入压缩文件中。 -F 尝试修复已损坏的压缩文件。 -g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。 -h 在线帮助。 -i\u0026lt;范本样式\u0026gt; 只压缩符合条件的文件。 -j 只保存文件名称及其内容，而不存放任何目录名称。 -J 删除压缩文件前面不必要的数据。 -k 使用MS-DOS兼容格式的文件名称。 -l 压缩文件时，把LF字符置换成LF+CR字符。 -ll 压缩文件时，把LF+CR字符置换成LF字符。 -L 显示版权信息。 -m 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。 -n\u0026lt;字尾字符串\u0026gt; 不压缩具有特定字尾字符串的文件。 -o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。 -q 不显示指令执行过程。 -r 递归处理，将指定目录下的所有文件和子目录一并处理。 -S 包含系统和隐藏文件。 -t\u0026lt;日期时间\u0026gt; 把压缩文件的日期设成指定的日期。 -T 检查备份文件内的每个文件是否正确无误。 -u 更换较新的文件到压缩文件内。 -v 显示指令执行过程或显示版本信息。 -V 保存VMS操作系统的文件属性。 -w 在文件名称里假如版本编号，本参数仅在VMS操作系统下有效。 -x\u0026lt;范本样式\u0026gt; 压缩时排除符合条件的文件。 -X 不保存额外的文件属性。 -y 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。 -z 替压缩文件加上注释。 -$ 保存第一个被压缩文件所在磁盘的卷册名称。 -\u0026lt;压缩效率\u0026gt; 压缩效率是一个介于1-9的数值。   实例 zip -q -r html.zip /home/html # 将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip zip -q -r html.zip * # 如果在我们在 /home/html 目录下，可以执行以下命令 zip -dv cp.zip a.c # 从压缩文件 cp.zip 中删除文件 a.c zip file1.zip file1 创建一个zip格式的压缩包 zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/",
	"title": "1.Linux基础",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.1-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/",
	"title": "1.1 目录结构",
	"tags": [],
	"description": "",
	"content": "目录结构    目录 说明     / 根目录，只能包含目录，不能包含具体文件。   /bin 存放可执行文件。很多命令就对应/bin目录下的某个程序，例如 ls、cp、mkdir。/bin目录对所有用户有效。   /dev 硬件驱动程序。例如声卡、磁盘驱动等，还有如 /dev/null、/dev/console、/dev/zero、/dev/full 等文件。   /etc 主要包含系统配置文件和用户、用户组配置文件。   /lib 主要包含共享库文件，类似于Windows下的DLL；有时也会包含内核相关文件。   /boot 系统启动文件，例如Linux内核、引导程序等。   /home 用户工作目录（主目录），每个用户都会分配一个目录。   /mnt 临时挂载文件系统。这个目录一般是用于存放挂载储存设备的挂载目录的，例如挂载CD-ROM的cdrom目录。   /proc 操作系统运行时，进程（正在运行中的程序）信息及内核信息（比如cpu、硬盘分区、内存信息等）存放在这里。/proc目录伪装的文   /tmp 临时文件目录，系统重启后不会被保存。   /usr /user目下的文件比较混杂，包含了管理命令、共享文件、库文件等，可以被很多用户使用。   /var 主要包含一些可变长度的文件，会经常对数据进行读写，例如日志文件和打印队列里的文件。   /sbin 和 /bin 类似，主要包含可执行文件，不过一般是系统管理所需要的，不是所有用户都需要。    "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.2-%E7%B3%BB%E7%BB%9F%E8%B0%83%E4%BC%98/",
	"title": "1.2 系统调优",
	"tags": [],
	"description": "",
	"content": "系统调优 ulimit -a ulimit -n 102400 1.在/etc/rc.local 中增加一行 ulimit -SHn 65535 2.在/etc/profile 中增加一行 ulimit -SHn 65535 3.在/etc/security/limits.conf最后增加如下两行记录 * soft nofile 65535 * hard nofile 65535 查看 /etc/security/limits.conf 没有就新建，加入 core 和 nofile 的相关配置，比如： * soft nofile 65536 * hard nofile 65536 * soft core unlimited * hard core unlimited # End of file 之类的，不用到 ~/.bashrc 里面调用 ulimit。 sudo vim /etc/sysctl.conf fs.inotify.max_user_watches=16384 ulimit -n 8192    type cmd 说明     core file size (blocks, -c) 0    data seg size (kbytes, -d) unlimited 数据段长度   scheduling priority (-e) 0    file size (blocks, -f) unlimited 文件大小   pending signals (-i) 15240    max locked memory (kbytes, -l) 64    max memory size (kbytes, -m) unlimited 最大内存大小   open files (-n) 1024 可打开的文件数   pipe size (512 bytes, -p) 8    POSIX message queues (bytes, -q) 819200    real-time priority (-r) 0    stack size (kbytes, -s) 8192 堆栈大小   cpu time (seconds, -t) unlimited CPU 时间   max user processes (-u) 15240 最大进程数   virtual memory (kbytes, -v) unlimited 虚拟内存   file locks (-x) unlimited     网卡多队列 打开内核网卡多队列支持，避免网卡中断都集中在 cpu0 上处理，多队列打开后，可以让网卡中断均摊到各个 cpu上，对提高并发十分有用： wget http://skywind3000.github.io/install/set_irq_affinity.sh 放到 /etc/config 目录下面（没有就新建），然后在 /etc/rc.local 里面加一行，每次重启就跑 set_irq_affinity.sh 且必须用 bash跑，参数传入需要开启多队列的网卡，以下是 /etc/rc.local 的内容： /bin/bash /etc/set_irq_affinity.sh eth0 eth1 eth2 exit 0 下面是 setirqaffinity.sh 的代码： # setting up irq affinity according to /proc/interrupts # 2008-11-25 Robert Olsson # 2009-02-19 updated by Jesse Brandeburg # # \u0026gt; Dave Miller: # (To get consistent naming in /proc/interrups) # I would suggest that people use something like: # char buf[IFNAMSIZ+6]; # # sprintf(buf, \u0026#34;%s-%s-%d\u0026#34;, # netdev-\u0026gt;name, # (RX_INTERRUPT ? \u0026#34;rx\u0026#34; : \u0026#34;tx\u0026#34;), # queue-\u0026gt;index); # # Assuming a device with two RX and TX queues. # This script will assign: # # eth0-rx-0 CPU0 # eth0-rx-1 CPU1 # eth0-tx-0 CPU0 # eth0-tx-1 CPU1 # set_affinity() { MASK=$((1\u0026lt;\u0026lt;$VEC)) printf \u0026#34;%s mask=%X for /proc/irq/%d/smp_affinity\\n\u0026#34; $DEV $MASK $IRQ printf \u0026#34;%X\u0026#34; $MASK \u0026gt; /proc/irq/$IRQ/smp_affinity #echo $DEV mask=$MASK for /proc/irq/$IRQ/smp_affinity #echo $MASK \u0026gt; /proc/irq/$IRQ/smp_affinity } if [ \u0026#34;$1\u0026#34; = \u0026#34;\u0026#34; ] ; then echo \u0026#34;Description:\u0026#34; echo \u0026#34; This script attempts to bind each queue of a multi-queue NIC\u0026#34; echo \u0026#34; to the same numbered core, ie tx0|rx0 --\u0026gt; cpu0, tx1|rx1 --\u0026gt; cpu1\u0026#34; echo \u0026#34;usage:\u0026#34; echo \u0026#34; $0eth0 [eth1 eth2 eth3]\u0026#34; fi # check for irqbalance running IRQBALANCE_ON=`ps ax | grep -v grep | grep -q irqbalance; echo $?` if [ \u0026#34;$IRQBALANCE_ON\u0026#34; == \u0026#34;0\u0026#34; ] ; then echo \u0026#34; WARNING: irqbalance is running and will\u0026#34; echo \u0026#34; likely override this script\u0026#39;s affinitization.\u0026#34; echo \u0026#34; Please stop the irqbalance service and/or execute\u0026#34; echo \u0026#34; \u0026#39;killall irqbalance\u0026#39;\u0026#34; fi # # Set up the desired devices. # for DEV in $* do for DIR in rx tx TxRx do MAX=`grep $DEV-$DIR /proc/interrupts | wc -l` if [ \u0026#34;$MAX\u0026#34; == \u0026#34;0\u0026#34; ] ; then MAX=`egrep -i \u0026#34;$DEV:.*$DIR\u0026#34; /proc/interrupts | wc -l` fi if [ \u0026#34;$MAX\u0026#34; == \u0026#34;0\u0026#34; ] ; then echo no $DIR vectors found on $DEV continue #exit 1 fi for VEC in `seq 0 1 $MAX` do IRQ=`cat /proc/interrupts | grep -i $DEV-$DIR-$VEC\u0026#34;$\u0026#34; | cut -d: -f1 | sed \u0026#34;s/ //g\u0026#34;` if [ -n \u0026#34;$IRQ\u0026#34; ]; then set_affinity else IRQ=`cat /proc/interrupts | egrep -i $DEV:v$VEC-$DIR\u0026#34;$\u0026#34; | cut -d: -f1 | sed \u0026#34;s/ //g\u0026#34;` if [ -n \u0026#34;$IRQ\u0026#34; ]; then set_affinity fi fi done done done # done 重启以后，cat 一下 /proc/interrupts里面，最右边网卡相关的中断是不是分摊到不同的cpu上面了。 网络参数优化 参考下面 /etc/sysctl.conf里面的优化选项和你 /etc/sysctl.conf 的具体内容，视情况更改： # # /etc/sysctl.conf - Configuration file for setting system variables fs.file-max = 100000 # 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0 # 是为了防止一定程度上的DOD的 net.ipv4.tcp_syncookies = 1 # 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； 不是很建议设置，可能接受错误的数据 # net.ipv4.tcp_tw_reuse = 1 # 表示尽量不启用交换分区 vm.swappiness=0 # 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 net.ipv4.tcp_tw_recycle = 1 # 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000 net.ipv4.tcp_max_tw_buckets = 10000 # 允许更多的PIDs (减少滚动翻转问题); may break some programs 32768 kernel.pid_max = 65535 # 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000 net.ipv4.ip_local_port_range = 1024 65000 # 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024 net.ipv4.tcp_max_syn_backlog = 16384 # 时间戳可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉 net.ipv4.tcp_timestamps = 0 # 为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK包的数量 net.ipv4.tcp_synack_retries = 2 # 在内核放弃建立连接之前发送SYN包的数量 net.ipv4.tcp_syn_retries = 2 # 如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60秒 # 但要记住的是，即使你的机器是一个轻载的WEB服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2的危险性比FIN-WAIT-1要小，因为它最多只能吃掉1.5K内存，但是它们的生存期长些 # 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间 net.ipv4.tcp_fin_timeout = 5 # 当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时 net.ipv4.tcp_keepalive_time = 1200 # ip_conntrack如果超过限制会出现丢包错误，默认为65535 # net.ipv4.ip_conntrack_max = 655360 # ip_conntrack回收速度 # net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180 # 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.core.netdev_max_backlog = 262144 # web应用中listen函数的backlog默认会给我们内核参数的net.core.somaxconn限制到128，而Nginx内核参数定义的NGX_LISTEN_BACKLOG默认为511，所以有必要调整这个值 net.core.somaxconn = 262144 net.core.wmem_default = 8388608 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.ipv4.tcp_mem = 94500000 915000000 927000000 # 系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS攻击 net.ipv4.tcp_max_orphans = 3276800 # 避免放大攻击 # net.ipv4.icmp_echo_ignore_broadcasts = 1 # 开启恶意icmp错误消息保护 # net.ipv4.icmp_ignore_bogus_error_responses = 1 # 开启并记录欺骗，源路由和重定向包 # net.ipv4.conf.all.log_martians = 1 # net.ipv4.conf.default.log_martians = 1 # 处理无源路由的包 # net.ipv4.conf.all.accept_source_route = 0 # net.ipv4.conf.default.accept_source_route = 0 # 开启反向路径过滤 # net.ipv4.conf.all.rp_filter = 1 # net.ipv4.conf.default.rp_filter = 1 # 确保无人能修改路由表 # net.ipv4.conf.all.accept_redirects = 0 # net.ipv4.conf.default.accept_redirects = 0 # net.ipv4.conf.all.secure_redirects = 0 # net.ipv4.conf.default.secure_redirects = 0 # 不充当路由器 # net.ipv4.ip_forward = 0 # net.ipv4.conf.all.send_redirects = 0 # net.ipv4.conf.default.send_redirects = 0 # Turn off the tcp_window_scaling # #net.ipv4.tcp_window_scaling = 0 # # Turn off the tcp_sack # #net.ipv4.tcp_sack = 0 # 参考上面的经验配置，按需要取消注释。 修改时钟源 查看当前时钟源和修改时钟源： # cat /sys/devices/system/clocksource/clocksource0/available_clocksource # cat /sys/devices/system/clocksource/clocksource0/current_clocksource # echo hpet \u0026gt; /sys/devices/system/clocksource/clocksource0/current_clocksource 之前发现有一台服务器同样进程耗费的 cpu比其他服务器高很多，经过查证开发同学在那个进程里频繁取系统时间，同时那台机器 gettimeofday之类的系统调用耗时比其他服务器要久。因为改代码已经来不及了，还好发现原来几台服务器的时钟源不同，经过修改后，取时间的系统调用时间大大下降。 强制扫描磁盘 机房突然停电，UPS没弄好，机器发生重启，一般会自动扫描硬盘，但是如果不放心要扫描主硬盘的话，可以手动来： touch /forcefsck 在根目录下面创建一个名为 forcefsdk 的文件即可，然后重新启动就会进入强制 fsck程序。 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.2.1-%E4%BF%AE%E6%94%B9%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0/",
	"title": "1.2.1 修改系统参数",
	"tags": [],
	"description": "",
	"content": "修改系统参数 vi /etc/sysctl.conf\n修改下列配置(参数根据自己情况修改) kernel.shmmax = 500000000 kernel.shmmni = 4096 kernel.shmall = 4000000000 kernel.sem = 500 1024000 200 4096 kernel.sysrq = 1 kernel.core_uses_pid = 1 kernel.msgmnb = 65536 kernel.msgmax = 65536 kernel.msgmni = 2048 net.ipv4.tcp_syncookies = 1 net.ipv4.ip_forward = 0 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.conf.all.arp_filter = 1 net.ipv4.ip_local_port_range = 1025 65535 net.core.netdev_max_backlog = 10000 net.core.rmem_max = 2097152 net.core.wmem_max = 2097152 vm.overcommit_memory = 2 修改完毕后重新载入 sysctl -p\n复制代码 limits参数\n修改文件打开数等限制 vi /etc/security/limits.conf ## 添加如下几行（注意*也需要添加） * soft nofile 65536 * hard nofile 65536 * soft nproc 131072 * hard nproc 131072 ## 添加如下几行（注意*也需要添加） vi /etc/security/limits.d/90-nproc.conf * soft nofile 65536 * hard nofile 65536 * soft nproc 131072 * hard nproc 131072 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.3-%E8%87%AA%E5%8A%A8%E5%8C%96/",
	"title": "1.3 自动化",
	"tags": [],
	"description": "",
	"content": "自动启动 # ubuntu vim /etc/rc.local #添加命令 #你想系统启动时自动运行 SSH 隧道，你可以将上面的 autossh 命令添加到 systemd chkconfig --list chkconfig -–list httpd chkconfig –-add httpd chkconfig httpd on chkconfig httpd off chkconfig mysqld on vi /etc/rc.d/rc.local #添加以下命令 /usr/sbin/apachectl start /etc/rc.d/init.d/mysqld start /etc/rc.d/init.d/smb start /usr/local/subversion/bin/svnserve -d 启动命令 systemctl restart iptables.service systemctl enable iptables.service linux的“自动化” linux系统的web网站在运营状态时，我们常需要对网站进行维护，例如查看资源剩余并做出响应、日志分割、数据整理，在特定状态执行特定任务等等，这些都会需要linux能实现自动执行某些任任务。本篇博文介绍如何进行常见的linux自动化任务。\n实现“自动化”有如下好处：\n节省人力，一个脚本就够了。 在夜晚自动执行可以避开网站流量高峰期，不影响网站白天的效率。 准确，设置完善的情况下，不会出差错。 当然最重要的还是省心了，不用频繁的敲某些命令了。 开机启动 开机启动应该是我们很经常的需求了，我们常需要在开机时就自动执行某些命令来开启服务，进程等，有了它我们不必再在每次开机时输入同一堆命令。\nchkconfig命令\n使用chkconfig命令可以在设置在不同启动级别下启动特定的服务或是程序。\n先说一下linux的运行级别：\n等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 chkconfig的命令如下：\nchkconfig \u0026ndash;list //命令查看已设置的开启自启动列表。 xxxd 0:off 1:off 2:on \u0026hellip; 6:off //list的结果，表示在xxxd服务在启动级别为2 3 4 5 的情况下会自动启动。 chkconfig \u0026ndash;add xxxd//向任务列表中添加一个xxxd服务 chkconfig [\u0026ndash;level 1/2/../6] xxxd on/off//设置xxxd用服务在n状态为开/关，[]内省略则在2345级别开启 chkconfig \u0026ndash;del xxxd //将任务列表中的xxxd服务删除 rc.d文件的编辑\n也可以直接编辑/etc/rc.d/目录下的文件来实现开机自启动。此目录下有很多文件，rcn.d是在启动状态为n的情况下的启动文件夹，rc、rc.sysinit、init.d都是系统的模块或系统设置的自启文件[夹]。\n我们用vim rc.local 编辑 rc.local文件，来定制自己的自启计划。命令十分简单，就像平常在操作一样。如/usr/local/apache/bin/apachectl start表示开机自启动apache服务器。\nat实现定时任务 at是一个简单的功能简单的定时任务程序，它只能进行一次性的定时任务，其用法如下：\n at time　//at加时间启动at命令 at\u0026gt;operation　//输入要执行的操作 at\u0026gt;Ctrl+D　//按Ctrl+D退出命令编辑 其time的常见形式如下\n at H:m tomorrow //第二天的H点m分 at now + n minutes/hours/days/weeks //在n分/时/天/周后 at midnight //在午夜=-= at H:m pm/am //在当天上午/下午的H点m分 我们也可以在/var/spool/at文件中查看at的当前命令。还需要注意的是，linux默认atd进程关闭状态，需要手动打开。\ncrontab实现定时任务 linux内置的cron进程能帮我们实现这些需求，cron搭配shell脚本，非常复杂的指令也没有问题。\ncron介绍\ncron守护进程是一个由实用程序和配置文件组成的小型子系统，在几乎所有类 UNIX 系统上都可以找到某种风格的cron，我们可以用ps aux|grep cron找到crond这个守护进程。\n我们经常使用的是crontab命令是cron table的简写，它是cron的配置文件，也可以叫它作业列表，我们可以在以下文件夹内找到相关配置文件。\n/var/spool/cron/ 目录下存放的是每个用户包括root的crontab任务，每个任务以创建者的名字命名 /etc/crontab 这个文件负责调度各种管理和维护任务。 /etc/cron.d/ 这个目录用来存放任何要执行的crontab文件或脚本。 我们还可以把脚本放在/etc/con.hourly、/etc/con.daily、/etc/con.weekly、/etc/con.monthly目录中，让它每小时/天/星期、月执行一次。 crontab的使用\n我们常用的命令如下：\ncrontab [-u username]　//省略用户表表示操作当前用户的crontab -e (编辑工作表) -l (列出工作表里的命令) -r (删除工作作) 我们用crontab -e进入当前用户的工作表编辑，是常见的vim界面。每行是一条命令。\ncrontab的命令构成为 时间+动作，其时间有分、时、日、月、周五种，操作符有\n  取值范围内的所有数字 / 每过多少个数字\n  从X到Z ，散列数字 以下是几个例子。\n  时间 注释 0 0 25 12 *//在12月25日的0时0分 */5 **** //每过5分钟\n 4-6 ***//每天的4 5 6点 *** * 2，5 //每周二和周五 配合简单的shell脚本  如果我们的命令有逻辑判断等非常复杂的操作时，再直接编辑crontab就有点困难了，这时，我们可以使用shell脚本。其来历，分类定义与题不符，不再多说，我们直接说它的用法。\n我们用vim /usr/sh/test.sh来使用vim编辑一个shell脚本\n!/bin/sh //声明开始shell脚本 a = \u0026#34;hello world\u0026#34; //定义一个shell变量 echo $a //熟悉的echo，输出a变量 #然后crontab -e编辑crontab，添加 */5* ** * /usr/sh/test.sh每隔五分钟运行一次test.sh脚本，也可以用 /phppath/php /filepath/test.php 来用php进程来执行php程序。 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.4-%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE/",
	"title": "1.4 系统设置",
	"tags": [],
	"description": "",
	"content": "系统设置 环境变量 # 所有用户 vim /etc/profile PATH=$PATH:/home/erlang/bin/ source /etc/profile # 当前用户 vim ~/.bashrc export JAVA_HOME=/home/[username]/apps/jdk export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH source ~/.bashrc 修改机器名称 ubuntu sudo vi /etc/hostname centOS sudo hostname Server_192.168.69.171 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.5-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/",
	"title": "1.5 常用命令",
	"tags": [],
	"description": "",
	"content": "常用命令 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.5.1-man/",
	"title": "1.5.1 man",
	"tags": [],
	"description": "",
	"content": "man 通常情况下，man 手册里面的内容都是英文的，这就要求你有一定的英文基础。man 手册的内容很多，涉及了 Linux 使用过程中的方方面面。为了便于查找，man 手册被进行了分册（分区段）处理，在 Research UNIX、BSD、OS X 和 Linux 中，手册通常被分为8个区段，安排如下： | 区段 | 说明 | | :\u0026mdash; | :\u0026mdash;\u0026mdash; | | 1 | 一般命令 | | 2 | 系统调用 | | 3 | 库函数，涵盖了C标准函数库 | | 4 | 特殊文件（通常是/dev中的设备）和驱动程序 | | 5 | 文件格式和约定 | | 6 | 游戏和屏保 | | 7 | 杂项 | | 8 | 系统管理命令和守护进程 |\n要查看相应区段的内容，就在 man 后面加上相应区段的数字即可，如：\n$ man 1 ls\n会显示第一区段中的ls命令 man 页面。\n"
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.5.2-%E7%94%A8%E6%88%B7%E5%8F%8A%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/",
	"title": "1.5.2 用户及文件权限管理",
	"tags": [],
	"description": "",
	"content": "用户和群组 groupadd group_name 创建一个新用户组 groupdel group_name 删除一个用户组 groupmod -n new_group_name old_group_name 重命名一个用户组 useradd -c \u0026#34;Name Surname \u0026#34; -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 \u0026#34;admin\u0026#34; 用户组的用户 useradd user1 创建一个新用户 userdel -r user1 删除一个用户 ( \u0026#39;-r\u0026#39; 排除主目录) usermod -c \u0026#34;User FTP\u0026#34; -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性 passwd 修改口令 passwd user1 修改一个用户的口令 (只允许root执行) chage -E 2005-12-31 user1 设置用户口令的失效期限 pwck 检查 \u0026#39;/etc/passwd\u0026#39; 的文件格式和语法修正以及存在的用户 grpck 检查 \u0026#39;/etc/passwd\u0026#39; 的文件格式和语法修正以及存在的群组 newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组 "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.5.3-%E5%8C%85%E7%AE%A1%E7%90%86/",
	"title": "1.5.3 包管理",
	"tags": [],
	"description": "",
	"content": "包管理 # RPM 包 - （Fedora, Redhat及类似系统） rpm -ivh package.rpm 安装一个rpm包 rpm -ivh --nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告 rpm -U package.rpm 更新一个rpm包但不改变其配置文件 rpm -F package.rpm 更新一个确定已经安装的rpm包 rpm -e package_name.rpm 删除一个rpm包 rpm -qa 显示系统中所有已经安装的rpm包 rpm -qa | grep httpd 显示所有名称中包含 \u0026#34;httpd\u0026#34; 字样的rpm包 rpm -qi package_name 获取一个已安装包的特殊信息 rpm -qg \u0026#34;System Environment/Daemons\u0026#34; 显示一个组件的rpm包 rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表 rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表 rpm -q package_name --whatrequires 显示与一个rpm包存在依赖关系的列表 rpm -q package_name --whatprovides 显示一个rpm包所占的体积 rpm -q package_name --scripts 显示在安装/删除期间所执行的脚本l rpm -q package_name --changelog 显示一个rpm包的修改历史 rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供 rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表 rpm --import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书 rpm --checksig package.rpm 确认一个rpm包的完整性 rpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性 rpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间 rpm -Va 检查系统中所有已安装的rpm包- 小心使用 rpm -Vp package.rpm 确认一个rpm包还未安装 rpm2cpio package.rpm | cpio --extract --make-directories *bin* 从一个rpm包运行可执行文件 rpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm 从一个rpm源码安装一个构建好的包 rpmbuild --rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包 # YUM 软件包升级器 - （Fedora, RedHat及类似系统） yum install package_name 下载并安装一个rpm包 yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm 更新当前系统中所有安装的rpm包 yum update package_name 更新一个rpm包 yum remove package_name 删除一个rpm包 yum list 列出当前系统中安装的所有包 yum search package_name 在rpm仓库中搜寻软件包 yum clean packages 清理rpm缓存删除下载的包 yum clean headers 删除所有头文件 yum clean all 删除所有缓存的包和头文件 # DEB 包 (Debian, Ubuntu 以及类似系统) dpkg -i package.deb 安装/更新一个 deb 包 dpkg -r package_name 从系统删除一个 deb 包 dpkg -l 显示系统中所有已经安装的 deb 包 dpkg -l | grep httpd 显示所有名称中包含 \u0026#34;httpd\u0026#34; 字样的deb包 dpkg -s package_name 获得已经安装在系统中一个特殊包的信息 dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表 dpkg --contents package.deb 显示尚未安装的一个包所提供的文件列表 dpkg -S /bin/ping 确认所给的文件由哪个deb包提供 # APT 软件工具 (Debian, Ubuntu 以及类似系统) apt-get install package_name 安装/更新一个 deb 包 apt-cdrom install package_name 从光盘安装/更新一个 deb 包 apt-get update 升级列表中的软件包 apt-get upgrade 升级所有已安装的软件 apt-get remove package_name 从系统删除一个deb包 apt-get check 确认依赖的软件仓库正确 apt-get clean 从下载的软件包中清理缓存 apt-cache search searched-package 返回包含所要搜索字符串的软件包名称 # 字符设置和文件格式转换 dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIX unix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOS recode ..HTML \u0026lt; page.txt \u0026gt; page.html 将一个文本文件转换成html recode -l | more 显示所有允许的转换格式 # 文件系统分析 badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块 fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性 fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性 fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性 fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性 fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 # 初始化一个文件系统 mkfs /dev/hda1 在hda1分区创建一个文件系统 mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统 mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统 mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统 fdformat -n /dev/fd0 格式化一个软盘 mkswap /dev/hda3 创建一个swap文件系统 # SWAP文件系统 mkswap /dev/hda3 创建一个swap文件系统 swapon /dev/hda3 启用一个新的swap文件系统 swapon /dev/hda2 /dev/hdb3 启用两个swap分区 # 备份 dump -0aj -f /tmp/home0.bak /home 制作一个 \u0026#39;/home\u0026#39; 目录的完整备份 dump -1aj -f /tmp/home0.bak /home 制作一个 \u0026#39;/home\u0026#39; 目录的交互式备份 restore -if /tmp/home0.bak 还原一个交互式备份 rsync -rogpav --delete /home /tmp 同步两边的目录 rsync -rogpav -e ssh --delete /home ip_address:/tmp 通过SSH通道rsync rsync -az -e ssh --delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录 rsync -az -e ssh --delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录 dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr \u0026#39;dd of=hda.gz\u0026#39; 通过ssh在远程主机上执行一次备份本地磁盘的操作 dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件 tar -Puf backup.tar /home/user 执行一次对 \u0026#39;/home/user\u0026#39; 目录的交互式备份操作 ( cd /tmp/local/ \u0026amp;\u0026amp; tar c . ) | ssh -C user@ip_addr \u0026#39;cd /home/share/ \u0026amp;\u0026amp; tar x -p\u0026#39; 通过ssh在远程目录中复制一个目录内容 ( tar c /home ) | ssh -C user@ip_addr \u0026#39;cd /home/backup-home \u0026amp;\u0026amp; tar x -p\u0026#39; 通过ssh在远程目录中复制一个本地目录 tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接 find /home/user1 -name \u0026#39;*.txt\u0026#39; | xargs cp -av --target-directory=/home/backup/ --parents 从一个目录查找并复制所有以 \u0026#39;.txt\u0026#39; 结尾的文件到另一个目录 find /var/log -name \u0026#39;*.log\u0026#39; | tar cv --files-from=- | bzip2 \u0026gt; log.tar.bz2 查找所有以 \u0026#39;.log\u0026#39; 结尾的文件并做成一个bzip包 dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作 dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容 # 光盘 cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force 清空一个可复写的光盘内容 mkisofs /dev/cdrom \u0026gt; cd.iso 在磁盘上创建一个光盘的iso镜像文件 mkisofs /dev/cdrom | gzip \u0026gt; cd_iso.gz 在磁盘上创建一个压缩了的光盘iso镜像文件 mkisofs -J -allow-leading-dots -R -V \u0026#34;Label CD\u0026#34; -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件 cdrecord -v dev=/dev/cdrom cd.iso 刻录一个ISO镜像文件 gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件 mount -o loop cd.iso /mnt/iso 挂载一个ISO镜像文件 cd-paranoia -B 从一个CD光盘转录音轨到 wav 文件中 cd-paranoia -- \u0026#34;-3\u0026#34; 从一个CD光盘转录音轨到 wav 文件中（参数-3） cdrecord --scanbus 扫描总线以识别scsi通道 dd if=/dev/hdc | md5sum 校验一个设备的md5sum编码，例如一张 CD "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.5.4-%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/",
	"title": "1.5.4 性能监控工具",
	"tags": [],
	"description": "",
	"content": "1.Top-Linux进程监控 Linux下的Top命令是一个性能监控程序，许多系统管理员常常用它来监控Linux性能，在许多Linux或者类Unix操作系统里都有这个命令。Top命令用于按一定的顺序显示所有正在运行而且处于活动状态的实时进程，而且会定期更新显示结果。这条命令显示了CPU的使用率、内存使用率、交换内存使用大小、高速缓存使用大小、缓冲区使用大小，进程PID、所使用命令以及其他。它还可以显示正在运行进程的内存和CPU占用多的情况。对系统管理员来说，top命令式是一个非常有用的，它可用于监控系统并在需要的时候采取正确的处理动作。让我们看看实际中的top命令。\n top\n 2. VmStat – 虚拟内存统计 Linux 的 VmStat 命令用于显示虚拟内存、内核线程、磁盘、系统进程、I/O 块、中断、CPU 活动 等的统计信息。缺省情况下， vmstat 命令在 Linux 系统下不可用，你需要安装一个包含了 vmstat 程序的 sysstat 软件包。命令格式的常见用法是：\n vmstat procs \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;memory\u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;swap\u0026ndash; \u0026mdash;\u0026ndash;io\u0026mdash;- \u0026ndash;system\u0026ndash; \u0026mdash;\u0026ndash;cpu\u0026mdash;\u0026ndash; r b swpd free inact active si so bi bo in cs us sy id wa st 1 0 0 810420 97380 70628 0 0 115 4 89 79 1 6 90 3 0\n 3.Lsof-列出打开的文件 在许多Linux或者类Unix系统里都有lsof命令，它常用于以列表的形式显示所有打开的文件和进程。打开的文件包括磁盘文件、网络套接字、管道、设备和进程。使用这条命令的主要情形之一就是在无法挂载磁盘和显示正在使用或者打开某个文件的错误信息的时候。使用这条命令，你可以很容易地看到正在使用哪个文件。这条命令最常用的格式如下：\n lsof COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME init 1 root cwd DIR 104,2 4096 2 / init 1 root rtd DIR 104,2 4096 2 / init 1 root txt REG 104,2 38652 17710339 /sbin/init init 1 root mem REG 104,2 129900 196453 /lib/ld-2.5.so init 1 root mem REG 104,2 1693812 196454 /lib/libc-2.5.so init 1 root mem REG 104,2 20668 196479 /lib/libdl-2.5.so init 1 root mem REG 104,2 245376 196419 /lib/libsepol.so.1 init 1 root mem REG 104,2 93508 196431 /lib/libselinux.so.1 init 1 root 10u FIFO 0,17 953 /dev/initctl\n 4.Tcpdump-网络包分析器\nTcpdump是最广泛使用的网络包分析器或者包监控程序之一，它用于捕捉或者过滤网络上指定接口上接收或者传输的TCP/IP包。它还有一个选项用于把捕捉到的包保存到文件里，以便以后进行分析。在几乎所有主要的Linux发布里，tcpdump都可以使用。\n tcpdump -i eth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes 22:08:59.617628 IP tecmint.com.ssh \u0026gt; 115.113.134.3.static-mumbai.vsnl.net.in.28472: P 2532133365:2532133481(116) ack 3561562349 win 9648 22:09:07.653466 IP tecmint.com.ssh \u0026gt; 115.113.134.3.static-mumbai.vsnl.net.in.28472: P 116:232(116) ack 1 win 9648 22:08:59.617916 IP 115.113.134.3.static-mumbai.vsnl.net.in.28472 \u0026gt; tecmint.com.ssh: . ack 116 win 64347\n 5.Netstat-网络状态统计 Netstat是一个用于监控进出网络的包和网络接口统计的命令行工具。它是一个非常有用的工具，系统管理员可以用来监控网络性能，定位并解决网络相关问题。\n netstat -a | moreActive Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 :mysql:LISTEN tcp 0 0:sunrpc : LISTEN tcp 0 0 :realm-rusd:LISTEN tcp 0 0:ftp : LISTEN tcp 0 0 localhost.localdomain:ipp : LISTEN tcp 0 0 localhost.localdomain:smtp : LISTEN tcp 0 0 localhost.localdomain:smtp localhost.localdomain:42709 TIME_WAIT tcp 0 0 localhost.localdomain:smtp localhost.localdomain:42710 TIME_WAIT tcp 0 0 :http:LISTEN tcp 0 0:ssh : LISTEN tcp 0 0 :https:* LISTEN\n 6. Htop – Linux进程监控 Htop 是一个非常高级的交互式的实时linux进程监控工具。 它和top命令十分相似，但是它具有更丰富的特性，例如用户可以友好地管理进程，快捷键，垂直和水平方式显示进程等等。 Htop是一个第三方工具，它不包含在linux系统中，你需要使用YUM包管理工具去安装它。 关于安装的更多信息，请阅读下文.\n htop Htop Command Example\n 7.Iotop-监控Linux磁盘I/O Iotop命令同样也非常类似于top命令和Htop程序，不过它具有监控并显示实时磁盘I/O和进程的统计功能。在查找具体进程和大量使用磁盘读写进程的时候，这个工具就非常有用。\n iotop\n Iotop Command Example Iotop命令举例的截图 有关如何安装和使用iotop的信息，请阅读： 在Linux下安装Iotop。\n8.Iostat-输入/输出统计 Iostat是一个用于收集显示系统存储设备输入和输出状态统计的简单工具。这个工具常常用来追踪存储设备的性能问题，其中存储设备包括设备、本地磁盘，以及诸如使用NFS等的远端磁盘。\n iostat Linux 2.6.18-238.9.1.el5 (tecmint.com) 09/13/2012\n avg-cpu: %user %nice %system %iowait %steal %idle 2.60 3.65 1.04 4.29 0.00 88.42\nDevice: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtn cciss/c0d0 17.79 545.80 256.52 855159769 401914750 cciss/c0d0p1 0.00 0.00 0.00 5459 3518 cciss/c0d0p2 16.45 533.97 245.18 836631746 384153384 cciss/c0d0p3 0.63 5.58 3.97 8737650 6215544 cciss/c0d0p4 0.00 0.00 0.00 8 0 cciss/c0d0p5 0.63 3.79 5.03 5936778 7882528 cciss/c0d0p6 0.08 2.46 2.34 3847771 3659776\n9.IPTraf-实时局域网IP监控 IPTraf是一个在Linux控制台运行的、开放源代码的实时网络（局域网）监控应用。它采集了大量信息，比如通过网络的IP流量监控，包括TCP标记、ICMP详细信息、TCP/UDP流量分离、TCP连接包和字节数。同时还采集有关接口状态的常见信息和详细信息：TCP、UDP、IP、ICMP、非IP，IP校验和错误，接口活动等。\nIP Traffic Monitor\n10. psacct 或者 acct - 监视用户活动 psacct或者acct工具用于监视系统里每个用户的活动状况。这两个服务进程运行在后台，它们对系统上运行的每个用户的所有活动进行近距离监视，同时还监视这些活动所使用的资源情况。\n系统管理员可以使用这两个工具跟踪每个用户的活动，比如用户正在做什么，他们提交了那些命令，他们使用了多少资源，他们在系统上持续了多长时间等等。\n11.Monit - Linux进程和服务监控工具 Monit是一个免费的开源软件，也是一个基于网络的进程监控工具。它能自动监控和管理系统进程，程序，文件，文件夹，权限，总和验证码和文件系统。\n这个软件能监控像Apache, MySQL, Mail, FTP, ProFTP, Nginx, SSH这样的服务。你可以通过命令行或者这个软件提供的网络借口来查看系统状态。\nThe Interface of Moint\nMonit Linux系统监控\n12.NetHogs-监视每个进程使用的网络带宽 NetHogs是一个开放源源代码的很小程序（与Linux下的top命令很相似），它密切监视着系统上每个进程的网络活动。同时还追踪着每个程序或者应用所使用的实时网络带宽。\nNetHogs Linux Bandwidth Monitoring\n13.iftop-监视网络带宽 iftop是另一个在控制台运行的开放源代码系统监控应用，它显示了系统上通过网络接口的应用网络带宽使用（源主机或者目的主机）的列表，这个列表定期更新。iftop用于监视网络的使用情况，而\u0026rsquo;top'用于监视CPU的使用情况。iftop是\u0026rsquo;top'工具系列中的一员，它用于监视所选接口，并显示两个主机间当前网络带宽的使用情况。\niftop - Network Bandwidth Monitoring\niftop-监视网络带宽。\n14 Monitorix-系统和网络监控 Monitorix 是一个免费的轻量级应用工具，它的设计初衷是运行和监控Linux/Unix服务器系统和资源等。它有一个HTTP 网络服务器，这个服务器有规律的收集系统和网络的信息并以图形化的形式展示出来。它监控系统的平均负载和使用，内存分配、磁盘健康状况、系统服务、网络端口、邮件统计（Sendmail，Postfix,Dovecot等），MySQL统计，等等。它就是用来监控系统的总体性能，帮助发现失误、瓶颈和异常活动的。\n15. Arpwatch – 以太网活动监视器 Arpwatch被设计用来监控Linux上的以太网地址解析 (MAC和IP地址的变化)。他在一段时间内持续监控以太网活动并输出IP和MAC地址配对变动的日志。它还可以向管理员发送邮件通知，对地址配对的增改发出警告。这对于检测网络上的ARP攻击很有用。\n更多信息请参阅 : Arpwatch to Monitor Ethernet Activity\n16. Suricata – 网络安全监控 Suricata 是一个开源的高性能网络安全、入侵检测和反监测工具，可以运行Linux、FreeBSD和Windows上。非营利组织OISF (Open Information Security Foundation)开发并拥有其版权。\n17. VnStat PHP – 网络流量监控 VnStat PHP 是流行网络工具\u0026quot;vnstat\u0026quot;的基于web的前端呈现。VnStat PHP 将网络使用情况呈现在漂亮的图形界面中。他可以显示以小时、日、月计的上传和下载流量并输出总结报告。\n18. Nagios – 网络/服务器监控 Nagios是领先而强大的开源监控系统，他可以让网络/系统管理员在问题影响到正常的业务之前发现并解决它们。有了Nagios系统，管理员可以在单个窗口内远程检测Linux、Windows、开关、路由器和打印机。它可以危险警告并指出系统/服务器是否有异常，这可以间接帮助你在问题发生之前采取抢救措施。\n更多信息请参阅 : Install Nagios Monitoring System to Monitor Remote Linux/Windows Hosts\n我们想知道：你在用什么监控程序来监控Linux服务器的性能呢？如果我们在上面错过了你认为重要的工具，请在评论中告诉我们，不要忘了分享它！\n"
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.6-debian/",
	"title": "1.6 debian",
	"tags": [],
	"description": "",
	"content": "debian "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.6-debian/1.6.1-sudo%E6%8F%90%E6%9D%83/",
	"title": "1.6.1 sudo提权",
	"tags": [],
	"description": "",
	"content": "如何安装sudo及配置其sudoers文件 #首先登陆超级管理员账户，在 Terminal 命令行内输入 su #“Enter”键后，输入超级管理员密码，即进入root账户 apt install sudo #\u0026#34;Enter\u0026#34;键后，系统即开始安装sudo（因为我这边已经安装好了sudo，所以只提示已安装的信息） adduser yl sudo #“Enter”键 意思是：将我的用户名 yl 添加到sudo组内，大家根据实际将自己的用户名添加进sudo组内 #接下来是配置sudoers文件，这里通过vi编辑器来写 vi /etc/sudoers #-在vi命令模式中，输入 /%sudo 搜索定位到 %sudo ALL = (ALL:ALL) ALL，或者手动定位 #-在vi插入模式中（按一下 i 键），在 %sudo ALL = (ALL:ALL) ALL 下面键入 yl ALL = (ALL:ALL) ALL （同样，这里 yl 代表我的普通用户名，大家根据实际修改） #-在vi命令模式中，输入 :x ,即可退出vi并保存文件 #验证sudo是否安装成功 #重启下Terminal ，输入命令 sudo ls ，再输入用户密码，如果显示如下字样，则可能sudo安装或配置出现了问题，需要重复上述步骤； #yl is not in the sudoers file. This incident will be reported. #如果显示如下字样，则说明sudo安装与配置成功 #Desktop Documents Downloads Music Pictures Public Templates Videos "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.7-ubuntu/",
	"title": "1.7 ubuntu",
	"tags": [],
	"description": "",
	"content": "ubuntu "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/",
	"title": "2.Shell 教程",
	"tags": [],
	"description": "",
	"content": "安裝 install linux库时，有时带有 lib，dev，gdb\n运行装lib\n编译dev\n调试装gdb\nlinux下configure，make，make install的意义 tar.gz、tar.bz2的是源代码包，需要编译之后才能安装，在编译过程中你可以指定各种参数以适应你的系统需求，比如安装位置，优化参数，要哪些功能不要哪些功能等等。 这类源代码包需要解压后（tar.gz的用 tar zxvf 解压，tar.bz2的用 tar jxvf 解压），进入解压目录，一般都有一个 INSTALL 的文本文件，里面一般都是安装的详细说明，可以用vi、nano、pico或X下面的文本编辑器（如gedit,gvim,kedit等）打开查看，安装一般就是三个步骤： configure 这一步一般用来生成 Makefile，为下一步的编译做准备，你可以通过在 configure 后加上参数来对安装进行控制，比如代码: ./configure --prefix=/usr 上面的意思是将该软件安装在 /usr 下面，执行文件就会安装在 /usr/bin （而不是默认的 /usr/local/bin),资源文件就会安装在 /usr/share（而不是默认的/usr/local/share）。同时一些软件的配置文件你可以通过指定 --sys-config= 参数进行设定。有一些软件还可以加上 --with、--enable、--without、--disable 等等参数对编译加以控制，你可以通过允许 ./configure --help 察看详细的说明帮助。 make 这一步就是编译，大多数的源代码包都经过这一步进行编译（当然有些perl或python编写的软件需要调用perl或python来进行编译）。如果在 make 过程中出现 error ，你就要记下错误代码（注意不仅仅是最后一行），然后你可以向开发者提交 bugreport（一般在 INSTALL 里有提交地址），或者你的系统少了一些依赖库等，这些需要自己仔细研究错误代码。 make install 这条命令来进行安装（当然有些软件需要先运行 make check 或 make test 来进行一些测试），这一步一般需要你有 root 权限（因为要向系统写入文件）。 安装完毕后你就可以删除解压目录了。采用源代码编译方式来安装软件是 Linux 系统下最常见的安装软件方法，而且这种方法使你可以更加自由地控制安装细节，所以提倡大家多使用该方法安装软件。 "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/",
	"title": "2.1. 基础教程",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.1-%E7%BB%88%E7%AB%AF%E5%BF%AB%E6%8D%B7%E9%94%AE/",
	"title": "2.1.1 终端快捷键",
	"tags": [],
	"description": "",
	"content": "终端快捷键    快捷键 说明     tab 补全   ctrl+a 移动游标到行首   ctrl+e 移动游标到行尾   ctrl+b 向左移动   ctrl+f 向右移动   ctrl+k 删除此处至末尾所有内容   ctrl+u 删除此处至开始所有内容   ctrl+d 删除当前字母   ctrl+w 删除此处到左边的单词   ctrl+y 粘贴由ctrl+u，ctrl+d，ctrl+w删除的单词   ctrl+l 相当于clear   ctrl+p 向上显示缓存命令(向上箭头)   ctrl+shift+n 新终端   ctrl+c 终止   ctrl+r 搜索你已经输入的命令   Ctrl+d 键盘输入结束或退出终端   Ctrl+s 暂停当前程序，暂停后按下任意键恢复运行   Ctrl+z 将当前程序放到后台运行，恢复到前台为命令fg   Ctrl+a 将光标移至输入行头，相当于Home键   Ctrl+e 将光标移至输入行末，相当于End键   Ctrl+k 删除从光标所在位置到行末   Alt+Backspace 向前删除一个单词   Shift+PgUp 将终端显示向上滚动   Shift+PgDn 将终端显示向下滚动    "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.2-%E9%80%9A%E9%85%8D%E7%AC%A6/",
	"title": "2.1.2 通配符",
	"tags": [],
	"description": "",
	"content": "终端快捷键    字符 含义     * 匹配 0 或多个字符   ? 匹配任意一个字符   [list] 匹配 list 中的任意单一字符   [^list] 匹配 除list 中的任意单一字符以外的字符   [c1-c2] 匹配 c1-c2 中的任意单一字符 如：[0-9] [a-z]   {string1,string2,\u0026hellip;} 匹配 string1 或 string2 (或更多)其一字符串   {c1..c2} 匹配 c1-c2 中全部字符 如{1..10}    "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.3-%E5%85%B3%E9%94%AE%E5%AD%97/",
	"title": "2.1.3 关键字",
	"tags": [],
	"description": "",
	"content": "终端快捷键 sh /var/vpn.sh 执行 sh -x vpn.sh 这将执行该脚本并显示所有变量的值。 sh -n vpn.sh 不需要执行脚本只是检查语法的模式。返回所有语法错误 #!/bin/sh #程序必须以下面的行开始（必须方在文件的第一行） 关键字 说明 描述 | 管道标识符，把“|”左边的执行结果，当作“|”右边的传入参数 echo compact status storage_0@192.168.1.101 | nc -C 127.0.0.1 10010 grep “hello” file.txt | wc -l \u0026gt;. \u0026gt;\u0026gt; 重定向：将命令的结果输出到文件，而不是标准输出（屏幕）。 \u0026gt; 写入文件并覆盖旧文件 \u0026gt;\u0026gt; 加到文件的尾部，保留旧文件内容 read 从shell中读取字符 readonly 只读变量 unset 删除变量 $unset .f function_name 删除函数 `command` 命令执行结果保存在变量 tar -zcvf lastmod.tar.gz `find . -mtime -1 -type f -print` 用反短斜线可以将一个命令的输出作为另外一个命令的一个命令行参数。 命令 说明 描述 $$ Shell本身的PID（ProcessID） $! Shell最后运行的后台Process的PID $? 最后运行的命令的结束代码（返回值） $- 使用Set命令设定的Flag一览 $* 所有参数列表。如\u0026#34;$*\u0026#34;用「\u0026#34;」括起来的情况、以\u0026#34;$1 $2 … $n\u0026#34;的形式输出所有参数。 $@所有参数列表。如\u0026#34;$@\u0026#34;用「\u0026#34;」括起来的情况、以\u0026#34;$1\u0026#34; \u0026#34;$2\u0026#34; … \u0026#34;$n\u0026#34; 的形式输出所有参数。 $# 添加到Shell的参数个数 $0 Shell本身的文件名 $1 ~ $n 添加到Shell的各参数值。$1是第1参数、$2是第2参数…。 "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.4-%E8%AF%AD%E6%B3%95/",
	"title": "2.1.4 语法",
	"tags": [],
	"description": "",
	"content": "语法 if if ... fi 语句； if ... else ... fi 语句； if ... elif ... else ... fi 语句。 ## 变量 #!/bin/sh a=10 b=20 if [ $a == $b ] then echo \u0026#34;a is equal to b\u0026#34; elif [ $a -gt $b ] then echo \u0026#34;a is greater than b\u0026#34; elif [ $a -lt $b ] then echo \u0026#34;a is less than b\u0026#34; else echo \u0026#34;None of the condition met\u0026#34; fi ## Case esac #!/bin/bash option=\u0026#34;${1}\u0026#34; case ${option} in -f) FILE=\u0026#34;${2}\u0026#34; echo \u0026#34;File name is $FILE\u0026#34; ;; -d) DIR=\u0026#34;${2}\u0026#34; echo \u0026#34;Dir name is $DIR\u0026#34; ;; *) echo \u0026#34;`basename ${0}`:usage: [-f file] | [-d directory]\u0026#34; exit 1 # Command to come out of the program with status 1 ;; esac ## for do done #!/bin/bash for FILE in $HOME/.bash* do echo $FILE done ## COUNTER=0 while [ $COUNTER -lt 5 ] do COUNTER=\u0026#39;expr $COUNTER+1\u0026#39; echo $COUNTER done ## until #循环执行一系列命令直至条件为 true 时停止。until 循环与 while 循环在处理方式上刚好相反。一般while循环优于until循环，但在某些时候，也只是极少数情况下，until 循环更加有用。 ## Break #break命令允许跳出所有循环（终止执行后面的所有循环）。 #!/bin/bash while : do echo -n \u0026#34;Input a number between 1 to 5: \u0026#34; read aNum case $aNum in 1|2|3|4|5) echo \u0026#34;Your number is $aNum!\u0026#34; ;; *) echo \u0026#34;You do not select a number between 1 to 5, game is over!\u0026#34; break ;; esac done ## Continue #不会跳出所有循环，仅仅跳出当前循环 #!/bin/bash while : do echo -n \u0026#34;Input a number between 1 to 5: \u0026#34; read aNum case $aNum in 1|2|3|4|5) echo \u0026#34;Your number is $aNum!\u0026#34; ;; *) echo \u0026#34;You do not select a number between 1 to 5!\u0026#34; continue echo \u0026#34;Game is over!\u0026#34; ;; esac done ## Function show_help() { echo \u0026#34;Usage: -h | -help show help st t default show info\u0026#34; } show_info() { ps aux | grep $NODENAME@$HOSTNAME | grep -v grep } case $1 in \u0026#39;-h\u0026#39;|\u0026#39;--help\u0026#39;) show_help ;; *) show_info ;; esac "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.5-function/",
	"title": "2.1.5 Function",
	"tags": [],
	"description": "",
	"content": "语法 #!/bin/sh  fSum 3 2; function fSum() { echo $1,$2; return $(($1+$2)); } fSum 5 7; total=$(fSum 3 2); echo $total,$?; sh testfun1.sh testfun1.sh: line 3: fSum: command not found 5,7 3,2 5 #!/bin/sh echo $(uname); declare num=1000; uname() { echo \u0026#34;test!\u0026#34;; ((num++)); return 100; } testvar() { local num=10; ((num++)); echo $num; } uname; echo $? echo $num; testvar; echo $num; sh testfun2.sh Linux test! 100 1001 11 1001 "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.6-%E8%BD%AC%E8%AF%91%E7%AC%A6/",
	"title": "2.1.6 转译符",
	"tags": [],
	"description": "",
	"content": "转译符    转义字符 含义     \\ 反斜杠   \\a 警报，响铃   \\b 退格（删除键）   \\f 换页(FF)，将当前位置移到下页开头   \\n 换行   \\r 回车   \\t 水平制表符（tab键）   \\v 垂直制表符    变量替换    形式 说明     ${var} 变量本来的值   ${var:-word} 如果变量 var 为空或已被删除(unset)，那么返回 word，但不改变 var 的值。   ${var:=word} 如果变量 var 为空或已被删除(unset)，那么返回 word，并将 var 的值设置为 word。   ${var:?message} 如果变量 var 为空或已被删除(unset)，那么将消息 message 送到标准错误输出，可以用来检测变量 var 是否可以被正常赋值。 若此替换出现在Shell脚本中，那么脚本将停止运行。   ${var:+word} 如果变量 var 被定义，那么返回 word，但不改变 var 的值。    算术运算符列表    运算符 说明 举例     + 加法 expr $a + $b 结果为 30。   - 减法 expr $a - $b 结果为 10。   * 乘法 expr $a \\* $b 结果为 200。   / 除法 expr $b / $a 结果为 2。   % 取余 expr $b % $a 结果为 0。   = 赋值 a=$b 将把变量 b 的值赋给 a。   == 相等。用于比较两个数字，相同则返回true。 [ $a == $b ] 返回 false。   != 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。    注意：条件表达式要放在方括号之间，并且要有空格，例如 [$a==$b] 是错误的，必须写成 [ $a == $b ]。\n关系运算符列表    运算符 说明 举例     -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 true。   -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。   -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。   -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。   -ge 检测左边的数是否大等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。   -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。    布尔运算符列表    运算符 说明 举例     ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。   -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。   -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。    字符串运算符列表    运算符 说明 举例     = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。   != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。   -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。   -n 检测字符串长度是否为0，不为0返回 true。 [ -z $a ] 返回 true。   str 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。    文件测试运算符列表    操作符 说明 举例     -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。   -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。   -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。   -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。   -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。   -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。   -p file 检测文件是否是具名管道，如果是，则返回 true。 [ -p $file ] 返回 false。   -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。   -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。   -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。   -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。   -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。   -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。    全部可用的重定向命令列表    命令 说明     command \u0026gt; file 将输出重定向到 file。   command \u0026lt; file 将输入重定向到 file。   command \u0026raquo; file 将输出以追加的方式重定向到 file。   n \u0026gt; file 将文件描述符为 n 的文件重定向到 file。   n \u0026raquo; file 将文件描述符为 n 的文件以追加的方式重定向到 file。   n \u0026gt;\u0026amp; m 将输出文件 m 和 n 合并。   n \u0026lt;\u0026amp; m 将输入文件 m 和 n 合并。   \u0026laquo; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。    "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.1.-%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/2.1.7-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/",
	"title": "2.1.7 数据结构",
	"tags": [],
	"description": "",
	"content": "数据结构 变量 注意，变量名和等号之间不能有空格，这可能和你熟悉的所有编程语言都不一样。同时，变量名的命名须遵循如下规则： 首个字符必须为字母（a-z，A-Z）。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。\n数组 在Shell中，用括号来表示数组，数组元素用“空格”符号分割开。定义数组的一般形式为： array_name=(value1 \u0026hellip; valuen)\narray_name[0]=value0\narray_name[1]=value1\narray_name[2]=value2\nvaluen=${array_name[2]}\n${array_name[*]} ${array_name[@]} 使用@ 或 * 可以获取数组中的所有元素\n取得数组元素的个数\nlength=${#array_name[@]}\n或者\nlength=${#array_name[*]}\n取得数组单个元素的长度\nlengthn=${#array_name[n]}\n"
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.2.-shell%E8%84%9A%E6%9C%AC/",
	"title": "2.2.Shell脚本",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.3.-makefile/",
	"title": "2.3. Makefile",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.3.-makefile/2.3.1-%E6%A1%88%E4%BE%8Bmakefile-1/",
	"title": "2.3.1 案例Makefile 1",
	"tags": [],
	"description": "",
	"content": "案例 # See LICENSE for licensing information.  DIALYZER = dialyzer REBAR = rebar APPNAME = goldrush all: app app: deps @$(REBAR) compile deps: @$(REBAR) get-deps clean: @$(REBAR) clean rm -f test/*.beam rm -f erl_crash.dump tests: clean app eunit ct eunit: @$(REBAR) -C rebar.test.config eunit skip_deps=true ct: @$(REBAR) -C rebar.test.config ct skip_deps=true build-plt: @$(DIALYZER) --build_plt --output_plt .$(APPNAME)_dialyzer.plt \\  --apps kernel stdlib sasl inets crypto public_key ssl compiler syntax_tools dialyze: @$(DIALYZER) --src src --plt .$(APPNAME)_dialyzer.plt --no_native \\  -Werror_handling -Wrace_conditions -Wunmatched_returns # -Wunderspecs docs: @$(REBAR) doc skip_deps=true =================================================================== "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/",
	"title": "4.Linux软件",
	"tags": [],
	"description": "",
	"content": "Linux软件 配置信息   ide/ IDE plugins、settings\n  etc/ 配置文件\n  linux 软件配置\n  "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.1-idea/",
	"title": "4.1 idea",
	"tags": [],
	"description": "",
	"content": "IDEA https://www.jetbrains.com/zh-cn/idea/download/ 问题 ubuntu ### ubuntu20.04下无法输入中文 -Drecreate.x11.input.method=true "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.2-vim/",
	"title": "4.2 vim",
	"tags": [],
	"description": "",
	"content": "vim syntax on filetype plugin indent on set encoding=utf-8 set sw=4 set ts=4 set paste set nu #set nopaste "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.2-vim/vim/",
	"title": "4.2.1 VIM",
	"tags": [],
	"description": "",
	"content": "http://yuez.me/jiang-ni-de-vim-da-zao-cheng-qing-qiao-qiang-da-de-ide/\nhttp://www.cnblogs.com/ribavnu/p/3874386.html\n           pathogen 管理插件 cd ~/ mkdir .vim mkdir -p ~/.vim/autoload ~/.vim/bundle cd ~/.vim/autoload/ wget https://raw.github.com/tpope/vim-pathogen/master/autoload/pathogen.vim Git:https://github.com/tpope/vim-pathogen    ~/.vimrc vim配置文件 call pathogen#infect() call pathogen#helptags() syntax onfiletype plugin indent on    vimerl  cd ~/.vim/bundlegit clone https://github.com/jimenezrick/vimerl.git vimrc中为vimerl配置文件增加以下配置 filetype plugin indent on let g:erlangManPath=\u0026rdquo;/usr/local/lib/erlang/man\u0026rdquo;    ctrlp.vim ctrl p, 提供给力的模糊文件查找. 进而可以把导航树扔掉. https://github.com/kien/ctrlp.vim    NERDTree Vim中一款给力导航树插件 – 但我很少用它，因为我在用ctrlp. https://github.com/scrooloose/nerdtree    NERDTree Tabs 将 NERDTree中打开过的文件添加到标签栏 https://github.com/jistr/vim-nerdtree-tabs    vim-vividchalk 配色 https://github.com/tpope/vim-vividchalk 需要在 $HOME/.vimrc 中增加一行命令：colo vividchalk     "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.3-lets-encrypt/",
	"title": "4.3 Let&#39;s Encrypt",
	"tags": [],
	"description": "",
	"content": "vim syntax on filetype plugin indent on set encoding=utf-8 set sw=4 set ts=4 set paste set nu #set nopaste "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.4-nginx/",
	"title": "4.4 nginx",
	"tags": [],
	"description": "",
	"content": "nginx使用 ## ubuntu sudo apt install -y libpcre3-dev ./configure --with-http_ssl_module --with-http_v2_module --with-http_gzip_static_module make sudo make install Generate Certificates cd /usr/local/nginx/conf openssl genrsa -des3 -out server.key 1024 openssl req -new -key server.key -out server.csr cp server.key server.key.org openssl rsa -in server.key.org -out server.key openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt server { server_name YOUR_DOMAINNAME_HERE; listen 443; ssl on; ssl_certificate /usr/local/nginx/conf/server.crt; ssl_certificate_key /usr/local/nginx/conf/server.key; } "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.4-nginx/4.4.1-nginxerror%E6%8E%92%E6%9F%A5/",
	"title": "4.4.1 nginxError排查",
	"tags": [],
	"description": "",
	"content": "nginxError排查 错误描述 {error, socket_closed_remotely} 复现 Leofs（分布式文件存储系统）\nGateway_0 192.168.1.16:8080\nGateway_1 192.168.1.17:8080\n100w条 每条500字节数据，由erlang httpc post到任意gateway， 所有数据存储ok\n加入nginx，放在192.168.1.16:80，负载 -\u0026gt;\n192.168.1.16:8080\n192.168.1.17:8080\n此时测试\n客户端会出现在某次post时{error, socket_closed_remotely}\n分析 a.根据错误关键字{error, socket_closed_remotely},发现可能是服务器主动关闭了socket套接字\nb.gateway没有问题，加上nginx出现问题，考虑nginx配置是否正确\nc.nginx 官方文档\nd.google，发现有人遇到类似情况http://rtbdev.com/2014/03/nginx-proxy-time_wait/\n技术点 TCP/IP的TIME_WAIT\nNginx nginx代理使用了短链接的方式和后端交互的原因，使得系统TIME_WAIT的tcp连接很多\nshell\u0026gt; ss -ant | awk \u0026lsquo;{++s[$1]} END {for(k in s) print k,s[k]}\u0026rsquo; %查看TIME_WAIT数量\nupstream { keepalive 32; }\nserver { \u0026hellip; location /http/ { proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection \u0026ldquo;\u0026quot;; \u0026hellip; } }\n错误描述 readv() failed (104: Connection reset by peer) while reading upstream 分析 1.认为是配置问题。（没有查到）\n2.检查leofs服务器，发现问题。服务器主动关闭connect，导致keep-alive出现问题\n技术点 修改成按照标准的http通讯\n"
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.4-nginx/4.4.2-nginxrewrite%E8%A7%84%E5%88%99/",
	"title": "4.4.2 nginxRewrite规则",
	"tags": [],
	"description": "",
	"content": "nginxRewrite规则 https://segmentfault.com/a/1190000002797606\nlocation正则写法 一个示例： location = / { # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ] } location / { # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ] } location /documents/ { # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ] } location ~ /documents/Abc { # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ] } location ^~ /images/ { # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ] } location ~* \\.(gif|jpg|jpeg)$ { # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ] } location /images/ { # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ] } location /images/abc { # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F与G的放置顺序是没有关系的 [ configuration G ] } location ~ /images/abc/ { # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [ configuration H ] } location ~* /js/.*/\\.js • 已=开头表示精确匹配\n如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。\n• ^~ 开头表示uri以某个常规字符串开头，不是正则匹配\n• ~ 开头表示区分大小写的正则匹配;\n• ~* 开头表示不区分大小写的正则匹配\n• / 通用匹配, 如果没有其它匹配,任何请求都会匹配到\n顺序 no优先级：\n(location =) \u0026gt; (location 完整路径) \u0026gt; (location ^~ 路径) \u0026gt; (location ~,~* 正则顺序) \u0026gt; (location 部分起始路径) \u0026gt; (/)\n上面的匹配结果\n按照上面的location写法，以下的匹配示例成立：\n• / -\u0026gt; config A\n精确完全匹配，即使/index.html也匹配不了\n• /downloads/download.html -\u0026gt; config B\n匹配B以后，往下没有任何匹配，采用B\n• /images/1.gif -\u0026gt; configuration D\n匹配到F，往下匹配到D，停止往下\n• /images/abc/def -\u0026gt; config D\n最长匹配到G，往下匹配D，停止往下\n你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序\n• /documents/document.html -\u0026gt; config C\n匹配到C，往下没有任何匹配，采用C • /documents/1.jpg -\u0026gt; configuration E\n匹配到C，往下正则匹配到E • /documents/Abc.jpg -\u0026gt; config CC\n最长匹配到C，往下正则顺序匹配到CC，不会往下到E\n实际使用建议 所以实际使用中，个人觉得至少有三个匹配规则定义，如下： # 直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。 # 这里是直接转发给后端应用服务器了，也可以是一个静态首页 # 第一个必选规则 location = / { proxy_pass http://tomcat:8080/index } # 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项 # 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用 location ^~ /static/ { root /webroot/static/; } location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ { root /webroot/res/; } #第三个规则就是通用规则，用来转发动态请求到后端应用服务器 #非静态文件请求就默认是动态请求，自己根据实际把握 #毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了 location / { proxy_pass http://tomcat:8080/ } http://tengine.taobao.org/book/chapter_02.html\nhttp://nginx.org/en/docs/http/ngx_http_rewrite_module.html\nRewrite规则 rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，\n例如 http://seanlook.com/a/we/index.php?id=1\u0026amp;u=str 只对/a/we/index.php重写。\n语法rewrite regex replacement [flag]; 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。\n表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是：\n 执行server块的rewrite指令 执行location匹配 执行选定的location中的rewrite指令 如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。  flag标志位 • last : 相当于Apache的[L]标记，表示完成rewrite • break : 停止执行当前虚拟主机的后续rewrite指令集 • redirect : 返回302临时重定向，地址栏会显示跳转后的地址 • permanent : 返回301永久重定向，地址栏会显示跳转后的地址\n因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解：\n last一般写在server和if中，而break一般使用在location中 last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 break和last都能组织继续执行后面的rewrite指令 if指令与全局变量 if判断指令 语法为if(condition){\u0026hellip;}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容： • 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false • 直接比较变量和内容时，使用=或!= • ~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配 -f和!-f用来判断是否存在文件 -d和!-d用来判断是否存在目录 -e和!-e用来判断是否存在文件或目录 -x和!-x用来判断文件是否可执行 例如：  if ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /msie/$1 break; } //如果UA包含\u0026#34;MSIE\u0026#34;，rewrite请求到/msid/目录下 if ($http_cookie ~* \u0026#34;id=([^;]+)(?:;|$)\u0026#34;) { set $id $1; } //如果cookie匹配正则，设置变量$id等于正则引用部分 if ($request_method = POST) { return 405; } //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302 if ($slow) { limit_rate 10k; } //限速，$slow可以通过 set 指令设置 if (!-f $request_filename){ break; proxy_pass \u0026lt;http://127.0.0.1\u0026gt;; } //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查 if ($args ~ post=140){ rewrite ^ \u0026lt;http://example.com/\u0026gt; permanent; } //如果query string中包含\u0026#34;post=140\u0026#34;，永久重定向到example.com location ~* \\.(gif|jpg|png|swf|flv)$ { valid_referers none blocked www.jefflei.com www.leizhenfang.com; if ($invalid_referer) { return 404; } //防盗链 } 全局变量 下面是可以用作if判断的全局变量 • $args ： #这个变量等于请求行中的参数，同$query_string • $content_length ： 请求头中的Content-length字段。 • $content_type ： 请求头中的Content-Type字段。 • $document_root ： 当前请求在root指令中指定的值。 • $host ： 请求主机头字段，否则为服务器名称。 • $http_user_agent ： 客户端agent信息 • $http_cookie ： 客户端cookie信息 • $limit_rate ： 这个变量可以限制连接速率。 • $request_method ： 客户端请求的动作，通常为GET或POST。 • $remote_addr ： 客户端的IP地址。 • $remote_port ： 客户端的端口。 • $remote_user ： 已经经过Auth Basic Module验证的用户名。 • $request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。 • $scheme ： HTTP方法（如http，https）。 • $server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 • $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 • $server_name ： 服务器名称。 • $server_port ： 请求到达服务器的端口号。 • $request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。 • $uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。 • $document_uri ： 与$uri相同。 例：\u0026lt;http://localhost:88/test1/test2/test.php\u0026gt; $host：localhost $server_port：88 $request_uri：\u0026lt;http://localhost:88/test1/test2/test.php\u0026gt; $document_uri：/test1/test2/test.php $document_root：/var/www/html $request_filename：/var/www/html/test1/test2/test.php 常用正则 • . ： 匹配除换行符以外的任意字符 • ? ： 重复0次或1次 • + ： 重复1次或更多次 • * ： 重复0次或更多次 • \\d ：匹配数字 • ^ ： 匹配字符串的开始 • $ ： 匹配字符串的介绍 • {n} ： 重复n次 • {n,} ： 重复n次或更多次 • [c] ： 匹配单个字符c • [a-z] ： 匹配a-z小写字母的任意一个 # 小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\\转义特殊字符。 rewrite实例 例1：\nhttp { # 定义image日志格式 log_format imagelog \u0026#39;[$time_local] \u0026#39; $image_file \u0026#39; \u0026#39; $image_type \u0026#39; \u0026#39; $body_bytes_sent \u0026#39; \u0026#39; $status; # 开启重写日志 rewrite_log on; server { root /home/www; location / { # 重写规则信息 error_log logs/rewrite.log notice; # 注意这里要用‘’单引号引起来，避免{} rewrite \u0026#39;^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)$\u0026#39; /data?file=$3.$4; # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行 set $image_file $3; set $image_type $4; } location /data { # 指定针对图片的日志格式，来分析图片类型和大小 access_log logs/images.log mian; root /data/images; # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里 try_files /$arg_file /image404.html; } location = /image404.html { # 图片不存在返回特定的信息 return 404 \u0026#34;image not found\\n\u0026#34;; } } 对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。\n例2：\nrewrite ^/images/(.*)_(\\d+)x(\\d+)\\.(png|jpg|gif)$ /resizer/$1.$4?width=$2\u0026amp;height=$3? last; 对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500\u0026amp;height=400地址，并会继续尝试匹配location。\n例3： 见 ssl部分页面加密 。\n参考 原文链接地址：http://seanlook.com/2015/05/17/nginx-location-rewrite/\n"
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.5-v2ray/",
	"title": "4.5 v2ray",
	"tags": [],
	"description": "",
	"content": "nginx使用 ## ubuntu sudo apt install -y libpcre3-dev ./configure --with-http_ssl_module --with-http_v2_module --with-http_gzip_static_module make sudo make install Generate Certificates cd /usr/local/nginx/conf openssl genrsa -des3 -out server.key 1024 openssl req -new -key server.key -out server.csr cp server.key server.key.org openssl rsa -in server.key.org -out server.key openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt server { server_name YOUR_DOMAINNAME_HERE; listen 443; ssl on; ssl_certificate /usr/local/nginx/conf/server.crt; ssl_certificate_key /usr/local/nginx/conf/server.key; } "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.6-docker/4.6.1-docker-dockerfile/",
	"title": "4.6.1 Docker-Dockerfile",
	"tags": [],
	"description": "",
	"content": "docker 仓库（registry） # 私有服务：创建私有仓库 docker run -d -p 5000:5000 --restart=always --name registry -v /opt/myregistry:/var/lib/registry registry #重启docker让修改生效 systemctl restart docker.service #Dockerfile打包镜像 https://www.docker.org.cn/docker/docker-206.html vim Dockerfile ---------------------------------------------------------------- FROM nginx #指定基础镜像，FROM必须为Dockerfile非注释行的第一行。 MAINTAINER Fisher \u0026#34;fisher@sudops.com\u0026#34; #设置镜像标签 #ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;此方法一次只能设置一个 #ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... 该方法一次可以设置多个环境变量 #例：ENV JAVA_HOME=/home/jdk-8 RUN /bin/echo \u0026#39;root:123456\u0026#39; |chpasswd RUN useradd runoob RUN /bin/echo \u0026#39;runoob:123456\u0026#39; |chpasswd RUN /bin/echo -e \u0026#34;LANG=\\\u0026#34;en_US.UTF-8\\\u0026#34;\u0026#34; \u0026gt;/etc/default/local USER root #指定运行容器的用户 WORKDIR /home #工作目录，进入容器后，以 WORKDIR 为当前路径 COPY /usr/local/nginx/html /usr/share/nginx/html EXPOSE 22 #说明容器暴露的端口，默认协议为 tcp ，若是 udp 协议，则需要在后面添加 udp ，如 80/udp EXPOSE 80 VOLUME /var/log #设置挂载点，将容器内的路径挂载到宿主机，该挂载方式是将容器内的路径挂载到docker数据路径下 CMD /usr/sbin/sshd -D #设置容器启动后默认执行的命令，CMD命令会被docker run的参数覆盖。 ENTRYPOINT /usr/local/apache-tomcat-8.5.33/bin/startup.sh #和CMD一样，设置容器启动后默认执行的命令，但是该命令不会被docker run覆盖，会始终执行，CMD会被docker run传入的命令覆盖。 ---------------------------------------------------------------- docker build -t test-static ./test #打包新镜像 #-t ：指定要创建的目标镜像名 #./test ：Dockerfile 文件所在目录，可以指定Dockerfile 的绝对路径 docker tag nginx:latest 127.0.0.1:5000/htjicon/nginx docker images docker push 127.0.0.1:5000/htjicon/nginx #推送到私有仓库 #将新打标签的镜像上传镜像到仓库 docker push 192.168.1.68:5000/clsn/busybox # 增量打包镜像 docker ps -a #查看本地容器 docker run -it -d centos /bin/bash #启动容器，并进入容器内部系统 docker exec -it 7b88d2a5edc2 /bin/bash # 进入容器内部系统 CONTAINER_ID echo \u0026#34;test\u0026#34; \u0026gt; test.txt #修改容器内容 docker cp custom.conf 容器名称:/etc/nginx/conf.d/ docker commit -m=\u0026#34;has update\u0026#34; -a=\u0026#34;runoob\u0026#34; 7b88d2a5edc2 127.0.0.1:5000/htjicon/nginx:v1.3.1 # 产生新的镜像，commit CONTAINER_ID， tag #-m: 提交的描述信息 #-a: 指定镜像作者 #7b88d2a5edc2 ID #127.0.0.1:5000/htjicon/nginx:v1.3.1: 指定要创建的目标镜像名 docker image ls # 查看镜像 docker push 127.0.0.1:5000/htjicon/nginx:v1.3.1 #新镜像 推送到私有仓库 "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.6-docker/4.6.2-docker/",
	"title": "4.6.2 Docker",
	"tags": [],
	"description": "",
	"content": "docker 安装 wget -qO- https://get.docker.com/ | sh sudo service docker start sudo docker run hello-world 镜像控制 docker image list docker image ls # 查看镜像 docker image save centos \u0026gt; docker-centos.tar.gz #导出镜像 docker image rm centos:latest #删除镜像 docker image load -i docker-centos.tar.gz #导入镜像 docker image inspect centos #查看镜像的详细信息 搜索镜像：docker search [OPTIONS] TERM docker search centos #搜索官方仓库镜像 上传镜像：docker push [OPTIONS] NAME[:TAG] docker push 192.168.0.91:5000/htjicon/nginx:v1.3.1 #新镜像 推送到私有仓库 下载镜像：docker pull [OPTIONS] NAME[:TAG] docker pull centos #获取镜像 docker pull training/webapp # 载入镜像 提交镜像：docker commit [OPTIONS] CONTAINER NAME[:TAG] docker commit -m=\u0026#34;has update\u0026#34; -a=\u0026#34;runoob\u0026#34; 7b88d2a5edc2 192.168.0.91:5000/htjicon/nginx:v1.3.1 # 产生新的镜像，commit CONTAINER_ID tag #-m: 提交的描述信息 #-a: 指定镜像作者 #7b88d2a5edc2 ID #192.168.0.91:5000/htjicon/nginx:v1.3.1: 指定要创建的目标镜像名 构建镜像：docker build [OPTIONS] PATH 删除镜像：docker rmi [OPTIONS] IMAGE [IMAGE...] 增加镜像标签：docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] 查看所有镜像：docker images [OPTIONS] [REPOSITORY[:TAG]] a） 运行容器 docker run -dit -p 8080:80 --name Nginx nginx b） 修改容器（这里我只是做个演示，所以就复制一下文件，具体修改需要根据你实际情况） docker cp custom.conf Nginx:/etc/nginx/conf.d/ c） 将容器保存为新的镜像 docker commit Nginx zwx/nginx 容器控制 启动/重启容器：docker start/restart CONTAINER docker start | stop | restart tag|CONTAINER ID|NAMES 停止/强停容器：docker stop/ kill CONTAINER 删除容器：docker rm [OPTIONS] CONTAINER [CONTAINER...] docker rm bf08b7f2cd89 # docker rm -f `docker ps -a -q` #删除所有容器 重命名容器：docker rename CONTAINER CONTAINER_NEW 进入容器：docker attach CONTAINER docker attach 1bf0f43c4d2f 执行容器命令：docker exec CONTAINER COMMAND docker exec -it 1bf0f43c4d2f /bin/bash #exec 进入容器方法（推荐使用） ps -ef 查看容器日志：docker logs [OPTIONS] CONTAINER docker logs -f bf08b7f2cd89 查看容器列表：docker ps [OPTIONS] docker ps -a # 查看你所有容器 -l %查询最后一次创建的容器 -a %所有容器 docker container kill CONTAINER ID #停止容器 docker container inspect 60cbfbc74f8a # 详细信息 docker port bf08b7f2cd89 docker top bf08b7f2cd89 docker inspect bf08b7f2cd89 容器启动 docker run -it nginx:latest /bin/bash #进入容器方法 docker run -d -P training/webapp python app.py # -d:让容器在后台运行 -P:将容器内部使用的网络端口映射到我们使用的主机上 docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py # -p 是容器内部端口绑定到指定的主机端口 docker run -d -P --name runoob training/webapp python app.py #--name 容器命名 -d : 后台运行容器，并返回容器ID -i：以交互模式运行容器，通常与 -t 同时使用 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 -v：绑定挂载目录 --name=\u0026#34;mycontainer\u0026#34;: 为容器指定一个名称 --net=\u0026#34;bridge\u0026#34;: 指定容器的网络连接类型，支持如下： 其他命令 docker cp custom.conf 容器名称:/etc/nginx/conf.d/ 查看docker信息：docker info docker命令帮助：docker run --help 复制文件到容器：docker cp custom.conf Nginx:/etc/nginx/conf.d/ 更新容器启动项：docker container update --restart=always nginx 查看docker日志：tail -f /var/log/messages 容器启动进行端口映射 docker run -d -p 8888:80 nginx:latest #启动时进行端口映射 -p hostPort:containerPort #端口映射 -p 8080:80 -p ip:hostPort:containerPort #配置监听地址 -p 10.0.0.100:8080:80 -p ip::containerPort #随机分配端口-p 10.0.0.100::80 -p hostPort:containerPort:udp #指定协议-p 8080:80:tcp -p 81:80 -p 443:443 #指定多个 netstat -lntup #查看使用的端口 容器数据卷的管理 docker run -d -p 80:80 -v /data:/usr/share/nginx/html nginx:latest #挂载卷 docker run -d -p 8080:80 -v /data:/usr/share/nginx/html nginx:latest #设置共享卷，使用同一个卷启动一个新的容器 docker volume ls #查看卷列表 #创建卷后挂载 docker volume create docker volume ls docker volume inspect 1bf0f43c4d2f docker run -d -p 9000:80 -v clsn:/usr/share/nginx/html nginx:latest #使用卷创建 docker run -d -P --volumes-from 079786c1e297 nginx:latest #设置卷 "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.6-docker/4.6.4-docker-compose/",
	"title": "4.6.4 Docker Compose",
	"tags": [],
	"description": "",
	"content": "docker compose 配置文件 version:\u0026#34;3\u0026#34;services:htzx:image:127.0.0.1:15000/htzx/iot-device-access-service#指定容器运行的镜像。tty:truecontainer_name:\u0026#34;iot-device-access-service\u0026#34;#自定义容器名称，而不是生成的默认名称。privileged:trueenvironment:# 添加环境变量- TZ=Asia/Shanghaiports:- \u0026#34;15020:8080\u0026#34;extra_hosts:# 添加主机名映射。类似 docker client --add-host。- \u0026#34;consul:192.168.0.1\u0026#34;env_file:# 从文件添加环境变量。可以是单个值或列表的多个值。- ../env/common.envcontext:./dir# 上下文路径。dockerfile:Dockerfile-alternate# 指定构建镜像的 Dockerfile 文件名。args:# 添加构建参数，这是只能在构建过程中访问的环境变量。buildno:1labels:# 设置构建镜像的标签。- \u0026#34;com.example.description=Accounting webapp\u0026#34;- \u0026#34;com.example.department=Finance\u0026#34;- \u0026#34;com.example.label-with-empty-value\u0026#34;target:prod# 多层构建，可以指定构建哪一层。volumes:#将主机的数据卷或着文件挂载到容器里。- \u0026#34;/localhost/postgres.sock:/var/run/postgres/postgres.sock\u0026#34;- \u0026#34;/localhost/data:/var/lib/postgresql/data\u0026#34;networks:default:external:name:hangtian运行命令 docker-compose up -d # 后台执行服务 "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.6-docker/4.6.5-docker-%E7%BD%91%E7%BB%9C/",
	"title": "4.6.5 Docker-网络",
	"tags": [],
	"description": "",
	"content": "docker 网络 docker network create -d bridge test-net # -d：参数指定 Docker 网络类型，有 bridge、overlay。 docker run -itd --name test1 --network test-net ubuntu /bin/bash #运行一个容器并连接到新建的 test-net 网络 docker run -itd --name test2 --network test-net ubuntu /bin/bash #打开新的终端，再运行一个容器并加入到 test-net 网络: "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.7-git/",
	"title": "4.7 git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.7-git/gitea/",
	"title": "Gitea",
	"tags": [],
	"description": "",
	"content": "install # https://gitea.io/zh-cn/ # 初始化数据库 # 下载 wget -O gitea https://dl.gitea.io/gitea/1.16.0/gitea-1.16.0-linux-amd64 chmod +x gitea ./gitea web "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/ntp/",
	"title": "Ntp",
	"tags": [],
	"description": "",
	"content": "ntpd ntpd服务的相关设置文件如下：\n1./etc/ntp.conf：这个是NTP daemon的主要设文件，也是 NTP 唯一的设定文件。\n2./usr /share/zoneinfo/:在这个目录下的文件其实是规定了各主要时区的时间设定文件，例如北京地区的时区设定文件在/usr/share/zoneinfo/Asia/Beijing 就是了。这个目录里面的文件与底下要谈的两个文件(clock 与localtime)是有关系的。\n3./etc/sysconfig/clock：这个文件其实也不包含在NTP 的 daemon 当中，因为这个是linux的主要时区设定文件。每次开机后，Linux 会自动的读取这个文件来设定自己系统所默认要显示的时间。\n4./etc /localtime：这个文件就是“本地端的时间配置文件”。刚刚那个clock 文件里面规定了使用的时间设置文件(ZONE) 为/usr/share/zoneinfo/Asia/Beijing ，所以说，这就是本地端的时间了，此时， Linux系统就会将Beijing那个文件另存为一份/etc/localtime文件，所以未来我们的时间显示就会以Beijing那个时间设定文件为准。\n5./etc/timezone：系统时区文件\n下面重点说说 /etc/ntp.conf文件的设置。在 NTP Server 的设定上面，其实最好不要对 Internet 无限制的开放，尽量仅提供您自己内部的 Client 端联机进行网络校时就好。此外， NTP Server 总也是需要网络上面较为准确的主机来自行更新自己的时间啊，所以在我们的 NTP Server 上面也要找一部最靠近自己的 Time Server 来进行自我校正。事实上， NTP 这个服务也是Server/Client 的一种模式。  命令 \\cp -r /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 时区设置为东八区 #Debian系统安装NTP校时包： sudo apt-get install -y ntpdate ntp #CentOS系统安装NTP校时包： yum -y install ntpdate ntp #安装ntp vim /etc/ntp.conf server cn.pool.ntp.org restrict default nomodifynotrapnoquery restrict 127.0.0.1　# 开启内部递归网络接口 lo restrict 192.168.9.0 mask 255.255.255.0 nomodify notrap #在内部子网里面的客户端可以 进行网络校时，但不能修改NTP服务器的时间参数 ntpdate cn.pool.ntp.org \u0026amp;\u0026amp; hwclock -w # 通过对时服务器核对时间，并写入硬件 # 对时服务器 # cn.pool.ntp.org us.pool.ntp.org # time.windows.com # ntpupdate.tencentyun.com #!/bin/bash #备份源文件 mv /etc/localtime /etc/localtimebak #修改时区为东八区 ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #安装ntp服务 yum -y install ntpdate ntp #修改/etc/ntp.conf cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; /etc/ntp.conf server cn.pool.ntp.org server time-a.nist.gov server time.windows.com server time.nist.gov EOF #调试查看时间差异 ntpdate -d cn.pool.ntp.org #同步时间 ntpdate cn.pool.ntp.org \u0026amp;\u0026amp; echo \u0026#34;SYNC_HWCLOCK=yes\u0026#34; \u0026gt;\u0026gt;/etc/sysconfig/ntpd || echo \u0026#34;Setting Filed!\u0026#34; #自启动 chkconfig --levels 235 ntpd on /etc/init.d/ntpd start echo `date` "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/1.%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/1.1-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/",
	"title": "1.1. 文件管理",
	"tags": [],
	"description": "",
	"content": "tar tar -czf a.tar.gz a/ tar -xzf a.tar.gz # -z 是否同时具有 gzip 的属性？亦即是否需要用 gzip 压缩或解压？ 一般格式为xx.tar.gz或xx. tgz # -j 是否同时具有 bzip2 的属性？亦即是否需要用 bzip2 压缩或解压？一般格式为xx.tar.bz2 # -v 压缩的过程中显示文件 # -f 使用档名，请留意，在 f 之后要立即接档名喔！不要再加其他参数！ # -p 使用原文件的原来属性（属性不会依据使用者而变） # -x 从归档文件中解出文件 #-c 建立新的归档文件 lsof #列出当前系统打开文件的工具 lsof -i:3306 lsof abc.txt 显示开启文件abc.txt的进程 lsof -c abc 显示abc进程现在打开的文件 lsof -c -p 1234 列出进程号为1234的进程所打开的文件 lsof -g gid 显示归属gid的进程情况 lsof +d /usr/local/ 显示目录下被进程开启的文件 lsof +D /usr/local/ 同上，但是会搜索目录下的目录，时间较长 lsof -d 4 显示使用fd为4的进程 lsof -i 用以显示符合条件的进程情况 lsof -i[46] [protocol][@hostname|hostaddr][:service|port] 46 --\u0026gt; IPv4 or IPv6 protocol --\u0026gt; TCP or UDP hostname --\u0026gt; Internet host name hostaddr --\u0026gt; IPv4地址 service --\u0026gt; /etc/service中的 service name (可以不止一个) port --\u0026gt; 端口号 (可以不止一个) 挂载 ls -l /dev/disk/by-uuid mkdir /media/yj/d mkdir /media/yj/e vim /etc/fstab /dev/sdb1 /media/yj/d auto auto 0 0 UUID= /media/yj/e auto auto 0 0 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/1.%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/1.2-%E7%9B%AE%E5%BD%95/",
	"title": "1.2. 目录",
	"tags": [],
	"description": "",
	"content": "cd cd - cd ./ cd ls ls -F ls -l ls -a ls *[0-9]* ls -lSr |more 以尺寸大小排列文件和目录 ls -d pwd pwd basename basename file 返回不包含路径的文件名比如： basename /bin/tux将返回 tux dirname dirname file 返回文件所在路径比如：dirname /bin/tux将返回 /bin "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/1.%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/1.3-%E6%9D%83%E9%99%90/",
	"title": "1.3 权限",
	"tags": [],
	"description": "",
	"content": "权限 ls lrwxrwxrwx 1 yujian yujian 16 12月 11 11:11 .vimrc -\u0026gt; git/config/vimrc drwxr-xr-x 2 yujian yujian 4096 12月 4 15:52 .wireshark/ l rwx rwx rwx 表示是一个链接 第一组字符(2-4)表示文件所有者的权限 第二组字符(5-7)表示文件所属用户组的权限 第三组字符(8-10)表示所有其他用户的权限 d rwx r-x r-x 表示是文件夹 (2-4)表示文件所有者的权限 (5-7)表示文件所属用户组的权限 (8-10)表示所有其他用户的权限 文件权限是Linux系统的第一道安全防线，基本的权限有读取(r)、写入(w)和执行(x)： 读取(r)：用户能够读取文件信息，查看文件内容。 写入(w)：用户可以编辑文件，可以向文件写入内容，也可以删除文件内容。 执行(x)：用户可以将文件作为程序来运行。 目录访问模式 目录的访问模式和文件类似，但是稍有不同： 读取：用户可以查看目录中的文件 写入：用户可以在当前目录中删除文件或创建文件 执行：执行权限赋予用户遍历目录的权利，例如执行 cd 和 ls 命令。 chmod    符号 说明 例     + 为文件或目录增加权限 chmod o+wx testfile o+表示所属用户组   - 删除文件或目录的权限 chmod u-x testfile u表示文件所有者   = 设置指定的权限 chmod g=rx testfile g表示所有其他用户    chmod o+wx,u-x,g=rx testfile 除了符号，也可以使用八进制数字来指定具体权限，如下表所示： | 数字 | 说明 | 权限 | | :\u0026mdash; | :\u0026mdash; | :\u0026mdash;\u0026mdash; | | 0 | 没有任何权限 | \u0026mdash; | | 1 | 执行权限 | \u0026ndash;x | | 2 | 写入权限 | -w- | | 3 | 执行权限和写入权限：1 (执行) + 2 (写入) = 3 | -wx | | 4 | 读取权限 | r\u0026ndash; | | 5 | 读取和执行权限：4 (读取) + 1 (执行) = 5 | r-x | | 6 | 读取和写入权限：4 (读取) + 2 (写入) = 6 | rw- | | 7 | 所有权限: 4 (读取) + 2 (写入) + 1 (执行) = 7 | rwx |\nchmod 755 testfile chown：chown 命令是\u0026quot;change owner\u0026quot;的缩写，用来改变文件的所有者。\nchgrp：chgrp 命令是\u0026quot;change group\u0026quot;的缩写，用来改变文件所在的群组。\nchmod 644 -R * 等价于：find /path -type f -exec chmod 644 {} \\ ; chmod 755 `find -type d` 等价于：find /path -type d -exec chmod 755 {} \\; find ./ -name *.php -exec chmod 644 {} \\; ls -lh 显示权限 ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示 chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限 chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限 chown user1 file1 改变一个文件的所有人属性 chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性 chgrp group1 file1 改变文件的群组 chown user1:group1 file1 改变一个文件的所有人和群组属性 find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件 chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限 chmod u-s /bin/file1 禁用一个二进制文件的 SUID位 chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的 chmod g-s /home/public 禁用一个目录的 SGID 位 chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件 chmod o-t /home/public 禁用一个目录的 STIKY 位 文件的特殊属性 - 使用 \u0026#34;+\u0026#34; 设置权限，使用 \u0026#34;-\u0026#34; 用于取消 chattr +a file1 只允许以追加方式读写文件 chattr +c file1 允许这个文件能被内核自动压缩/解压 chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件 chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接 chattr +s file1 允许一个文件被安全地删除 chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘 chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件 lsattr 显示特殊的属性 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/1.%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/1.4-%E5%8E%8B%E7%BC%A9/",
	"title": "1.4 压缩",
	"tags": [],
	"description": "",
	"content": "压缩 tar -zcvf /home/xahot.tar.gz /xahot 把/xahot文件夹打包后生成一个/home/xahot.tar.gz的文件 tar -zcvf this.tar.gz ./*.txt 将当前目录下所有.txt文件打包并压缩归档到文件this.tar.gz tar -zcf this.tar.gz ./*.txt -c 建立新的归档文件 -r 向归档文件末尾追加文件 -x 从归档文件中解出文件 -O 将文件解开到标准输出 -v 处理过程中输出相关信息 -f 对普通文件操作 -z 调用gzip来压缩归档文件，与-x联用时调用gzip完成解压缩 -Z 调用compress来压缩归档文件，与-x联用时调用compress完成解压缩 --exclude=tomcat/logs 这里大家要注意的时候，在我们使用tar 的--exclude 命令排除打包的时候，不能加“/”，否则还是会把logs目录以及其下的文件打包进去 rar e file.rar //解压rar unzip file.zip //解压zip 7z gzip .gz gzip /home/file -\u0026gt; file.gz bzip2 .bz2 *.tar.gz tar -xzvf tar -xzf *.tar.xz tar xvJf *.tar.bz2 tar -xjvf tar -xjf *.tar.Z tar -xZvf *.tar tar -xvf *.tar.Z tar -xZf *.rar unrar e *.zip unzip bunzip2 file1.bz2 解压一个叫做 \u0026#39;file1.bz2\u0026#39;的文件 bzip2 file1 压缩一个叫做 \u0026#39;file1\u0026#39; 的文件 gunzip file1.gz 解压一个叫做 \u0026#39;file1.gz\u0026#39;的文件 gzip file1 压缩一个叫做 \u0026#39;file1\u0026#39;的文件 gzip -9 file1 最大程度压缩 rar a file1.rar test_file 创建一个叫做 \u0026#39;file1.rar\u0026#39; 的包 rar a file1.rar file1 file2 dir1 同时压缩 \u0026#39;file1\u0026#39;, \u0026#39;file2\u0026#39; 以及目录 \u0026#39;dir1\u0026#39; rar x file1.rar 解压rar包 unrar x file1.rar 解压rar包 tar -cvf archive.tar file1 创建一个非压缩的 tarball tar -cvf archive.tar file1 file2 dir1 创建一个包含了 \u0026#39;file1\u0026#39;, \u0026#39;file2\u0026#39; 以及 \u0026#39;dir1\u0026#39;的档案文件 tar -tf archive.tar 显示一个包中的内容 tar -xvf archive.tar 释放一个包 tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下 tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包 tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包 tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包 tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包 unzip file1.zip 解压一个zip格式压缩包 "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.2.-shell%E8%84%9A%E6%9C%AC/%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%90%8E%E6%93%8D%E4%BD%9C/",
	"title": "1.安装系统",
	"tags": [],
	"description": "",
	"content": "安装 配置 ssh 证书登录 关闭密码和 root 登录。SSH 登录必须 KEY ，禁用掉密码登录，禁用 ROOT 远程 fail2ban + 防火墙 检测状态 开 ssh 端口访问 数据库除了 bind ，也要用防火墙限制。 所有端口改成非默认 不是必须的话不开放外网服务端口, 数据库，缓存这些都只开 127 或者局域网 IP 进程尽量不以 root 启动 关注自己网站所用的程序的漏洞 关注自己所用的开源程序的漏洞 及时更新版本 实例 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.1-%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/",
	"title": "2.1 文档编辑",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.10-wc/",
	"title": "2.10 wc",
	"tags": [],
	"description": "",
	"content": "wc wc -lcw rebar.config rebar.config.script find . -name \u0026#34;*.erl\u0026#34; -or -name \u0026#34;*.hrl\u0026#34;|xargs cat|wc -l #查看所有文件行数 # -c 统计字节数 # -l 统计行数 # -w 统计字数 ls -l | grep \u0026#34;^-\u0026#34; | wc -l # 1、统计当前目录下文件的个数（不包括目录） ls -lR| grep \u0026#34;^-\u0026#34; | wc -l # 2、统计当前目录下文件的个数（包括子目录） ls -lR | grep \u0026#34;^d\u0026#34; | wc -l # 3、查看某目录下文件夹(目录)的个数（包括子目录） find . -name filename | wc -l # 4、统计当前文件夹下叫某某的文件的数量 find -name \u0026#34;*.js\u0026#34; | wc -l # 例如这里需要找 js 文件的数量 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.2-sed/",
	"title": "2.2 sed",
	"tags": [],
	"description": "",
	"content": "sed http://man.linuxde.net/sed\nsed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等\n# Sed是一个基本的查找替换程序。可以从标准输入（比如命令管道）读入文本，并将结果输出到标准输出（屏幕）。该命令采用正则表达式（见参考）进行搜索。不要和shell中的通配符相混淆。 sed [options] \u0026#39;command\u0026#39; file(s) sed [options] -f scriptfile file(s) -e\u0026lt;script\u0026gt;或--expression=\u0026lt;script\u0026gt;：以选项中的指定的script来处理输入的文本文件； -f\u0026lt;script文件\u0026gt;或--file=\u0026lt;script文件\u0026gt;：以选项中指定的script文件来处理输入的文本文件； -h或--help：显示帮助； -n或--quiet或——silent：仅显示script处理后的结果； -V或--version：显示版本信息。 # 比如：将linuxfocus替换为 LinuxFocus cat text.file | sed ’s/linuxfocus/LinuxFocus/’ \u0026gt;newtext.fileawk: awk # 用来从文本文件中提取字段。缺省地，字段分割符格，可以使用-F指定其他分割符。 sed -i \u0026#34;s/book/books/g\u0026#34; file -i 直接修改文件内容，会匹配file文件中每一行的第一个book替换为books sed -i \u0026#34;s/127.0.0.1/192.168.1.16/\u0026#34; priv/docroot/index.html 把index.html 中的127.0.0.1替换成192.168.1.6 sed \u0026#34;s/book\\\u0026#34;\\//books\\\u0026#34;\\//\u0026#34; file 替换文本中的字符串 sed -n \u0026#34;s/test/TEST/p\u0026#34; file -n选项和p命令一起使用表示只打印那些发生替换的行 sed \u0026#34;s/book/books/g\u0026#34; file 使用后缀 /g 标记会替换每一行中的所有匹配 sed -i \u0026#39;s/ -Werror//g\u0026#39; `grep -rl \u0026#34; -Werror\u0026#34; ./` "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.3-awk/",
	"title": "2.3 awk",
	"tags": [],
	"description": "",
	"content": "awk echo \u0026#39;Adam Bor, 34, IndiaKerryMiller, 22, USA\u0026#39; | awk -F \u0026#39;,\u0026#39; \u0026#39;{print $1 , $3}\u0026#39; ifconfig eth0 |awk -F \u0026#39;inet | netmask \u0026#39; \u0026#39;{print $2}\u0026#39; 获取网卡eth0的ip地址 grep \u0026#39;release\u0026#39; rebar.config | awk -F \u0026#39;\u0026#34;\u0026#39; \u0026#39;{print $2}\u0026#39; "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.4-uniq/",
	"title": "2.4 uniq",
	"tags": [],
	"description": "",
	"content": "uniq # 删除重复的行比如： sort file.txt | uniq uniq [-cdu][-f\u0026lt;栏位\u0026gt;][-s\u0026lt;字符位置\u0026gt;][-w\u0026lt;字符位置\u0026gt;][--help][--version][输入文件][输出文件] -c或--count 在每列旁边显示该行重复出现的次数。 -d或--repeated 仅显示重复出现的行列。 -f\u0026lt;栏位\u0026gt;或--skip-fields=\u0026lt;栏位\u0026gt; 忽略比较指定的栏位。 -s\u0026lt;字符位置\u0026gt;或--skip-chars=\u0026lt;字符位置\u0026gt; 忽略比较指定的字符。 -u或--unique 仅显示出一次的行列。 -w\u0026lt;字符位置\u0026gt;或--check-chars=\u0026lt;字符位置\u0026gt; 指定要比较的字符。 --help 显示帮助。 --version 显示版本信息。 [输入文件] 指定已排序好的文本文件。如果不指定此项，则从标准读取数据； [输出文件] 指定输出的文件。如果不指定此选项，则将内容显示到标准输出设备（显示终端）。 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.5-sort/",
	"title": "2.5 sort",
	"tags": [],
	"description": "",
	"content": "sort file.txt 对file.txt文件中的行进行排序 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.6-grep/",
	"title": "2.6 grep",
	"tags": [],
	"description": "",
	"content": "grep grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。\n选项 -a 不要忽略二进制数据。 -A\u0026lt;显示列数\u0026gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。 -b 在显示符合范本样式的那一行之外，并显示该行之前的内容。 -c 计算符合范本样式的列数。 -C\u0026lt;显示列数\u0026gt;或-\u0026lt;显示列数\u0026gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。 -d\u0026lt;进行动作\u0026gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。 -e\u0026lt;范本样式\u0026gt; 指定字符串作为查找文件内容的范本样式。 -E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。 -f\u0026lt;范本文件\u0026gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。 -F 将范本样式视为固定字符串的列表。 -G 将范本样式视为普通的表示法来使用。 -h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。 -H 在显示符合范本样式的那一列之前，标示该列的文件名称。 -i 忽略字符大小写的差别。 -l 列出文件内容符合指定的范本样式的文件名称。 -L 列出文件内容不符合指定的范本样式的文件名称。 -n 在显示符合范本样式的那一列之前，标示出该列的编号。 -q 不显示任何信息。 -R/-r 此参数的效果和指定“-d recurse”参数相同。 -s 不显示错误信息。 -v 反转查找。 -w 只显示全字符合的列。 -x 只显示全列符合的列。 -y 此参数效果跟“-i”相同。 -o 只输出文件中匹配到的部分。 grep递归搜索文件 grep -ir \u0026#39;\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;../js/main.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026#39; # 当前目录下查找字符串 grep \u0026#34;text\u0026#34; . -r -n # .表示当前目录。 echo \u0026#34;hello world\u0026#34; | grep -i \u0026#34;HELLO\u0026#34; #忽略匹配样式中的字符大小写 echo this is a text line | grep -e \u0026#34;is\u0026#34; -e \u0026#34;line\u0026#34; -o # 选项 -e 制动多个匹配样式 grep \u0026#34;main()\u0026#34; . -r --include *.{php,html} # 只在目录中所有的.php和.html文件中递归搜索字符\u0026#34;main()\u0026#34; grep \u0026#34;main()\u0026#34; . -r --exclude \u0026#34;README\u0026#34; # 在搜索结果中排除所有README文件 grep \u0026#34;main()\u0026#34; . -r --exclude-from filelist # 在搜索结果中排除filelist文件列表里的文件 seq 10 | grep \u0026#34;5\u0026#34; -A 3 # 显示匹配某个结果之后的3行，使用 -A 选项： seq 10 | grep \u0026#34;5\u0026#34; -B 3 # 显示匹配某个结果之前的3行，使用 -B 选项 seq 10 | grep \u0026#34;5\u0026#34; -C 3 # 显示匹配某个结果的前三行和后三行，使用 -C 选项： echo -e \u0026#34;a\\nb\\nc\\na\\nb\\nc\u0026#34; | grep a -A 1 # 如果匹配结果有多个，会用“--”作为各匹配结果之间的分隔符： grep命令常见用法 grep \u0026#34;match_pattern\u0026#34; file_name grep \u0026#34;match_pattern\u0026#34; file_1 file_2 file_3 ... grep -v \u0026#34;match_pattern\u0026#34; file_name #标记匹配颜色 --color=auto 选项 grep \u0026#34;match_pattern\u0026#34; file_name --color=auto #使用正则表达式 -E 选项 grep -E \u0026#34;[1-9]+\u0026#34; #或 egrep \u0026#34;[1-9]+\u0026#34; #统计文件或者文本中包含匹配字符串的行数 -c 选项 grep -c \u0026#34;text\u0026#34; file_name #输出包含匹配字符串的行数 -n 选项 grep \u0026#34;text\u0026#34; -n file_1 file_2 #打印样式匹配所位于的字符或字节偏移 #一行中字符串的字符便宜是从该行的第一个字符开始计算，起始值为0。选项 -b -o 一般总是配合使用。 echo gun is not unix | grep -b -o \u0026#34;not\u0026#34; "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.7-tail/",
	"title": "2.7 tail",
	"tags": [],
	"description": "",
	"content": "简介 Linux命令：显示文件结尾\n命令格式 tail[必要参数][选择参数][文件]\n命令功能 用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。\n功能,用法 标准语法 tail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ] 命令参数： -f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c\u0026lt;数目\u0026gt; 显示的字节数 -n\u0026lt;行数\u0026gt; 显示行数 --pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, --quiet, --silent 从不输出给出文件名的首部 -s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.8-find/",
	"title": "2.8 find",
	"tags": [],
	"description": "",
	"content": "find命令 find命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。\n语法 find [指定查找目录] [查找规则] [查找完后执行的action]\n选项 -o:逻辑或,两个条件只要满足一个即可 -a:逻辑与,两个条件必须同时满足 -amin\u0026lt;分钟\u0026gt;：查找在指定时间曾被存取过的文件或目录，单位以分钟计算； -anewer\u0026lt;参考文件或目录\u0026gt;：查找其存取时间较指定文件或目录的存取时间更接近现在的文件或目录； -atime\u0026lt;24小时数\u0026gt;：查找在指定时间曾被存取过的文件或目录，单位以24小时计算； -cmin\u0026lt;分钟\u0026gt;：查找在指定时间之时被更改过的文件或目录； -cnewer\u0026lt;参考文件或目录\u0026gt;查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录； -ctime\u0026lt;24小时数\u0026gt;：查找在指定时间之时被更改的文件或目录，单位以24小时计算； -daystart：从本日开始计算时间； -depth：从指定目录下最深层的子目录开始查找； -expty：寻找文件大小为0 Byte的文件，或目录下没有任何子目录或文件的空目录； -exec\u0026lt;执行指令\u0026gt;：假设find指令的回传值为True，就执行该指令； -false：将find指令的回传值皆设为False； -fls\u0026lt;列表文件\u0026gt;：此参数的效果和指定“-ls”参数类似，但会把结果保存为指定的列表文件； -follow：排除符号连接； -fprint\u0026lt;列表文件\u0026gt;：此参数的效果和指定“-print”参数类似，但会把结果保存成指定的列表文件； -fprint0\u0026lt;列表文件\u0026gt;：此参数的效果和指定“-print0”参数类似，但会把结果保存成指定的列表文件； -fprintf\u0026lt;列表文件\u0026gt;\u0026lt;输出格式\u0026gt;：此参数的效果和指定“-printf”参数类似，但会把结果保存成指定的列表文件； -fstype\u0026lt;文件系统类型\u0026gt;：只寻找该文件系统类型下的文件或目录； -gid\u0026lt;群组识别码\u0026gt;：查找符合指定之群组识别码的文件或目录； -group\u0026lt;群组名称\u0026gt;：查找符合指定之群组名称的文件或目录； -help或——help：在线帮助； -ilname\u0026lt;范本样式\u0026gt;：此参数的效果和指定“-lname”参数类似，但忽略字符大小写的差别； -iname\u0026lt;范本样式\u0026gt;：此参数的效果和指定“-name”参数类似，但忽略字符大小写的差别； -inum\u0026lt;inode编号\u0026gt;：查找符合指定的inode编号的文件或目录； -ipath\u0026lt;范本样式\u0026gt;：此参数的效果和指定“-path”参数类似，但忽略字符大小写的差别； -iregex\u0026lt;范本样式\u0026gt;：此参数的效果和指定“-regexe”参数类似，但忽略字符大小写的差别； -links\u0026lt;连接数目\u0026gt;：查找符合指定的硬连接数目的文件或目录； -iname\u0026lt;范本样式\u0026gt;：指定字符串作为寻找符号连接的范本样式； -ls：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出； -maxdepth\u0026lt;目录层级\u0026gt;：设置最大目录层级； -mindepth\u0026lt;目录层级\u0026gt;：设置最小目录层级； -mmin\u0026lt;分钟\u0026gt;：查找在指定时间曾被更改过的文件或目录，单位以分钟计算； -mount：此参数的效果和指定“-xdev”相同； -mtime\u0026lt;24小时数\u0026gt;：查找在指定时间曾被更改过的文件或目录，单位以24小时计算； -name\u0026lt;范本样式\u0026gt;：指定字符串作为寻找文件或目录的范本样式； -newer\u0026lt;参考文件或目录\u0026gt;：查找其更改时间较指定文件或目录的更改时间更接近现在的文件或目录； -nogroup：找出不属于本地主机群组识别码的文件或目录； -noleaf：不去考虑目录至少需拥有两个硬连接存在； -nouser：找出不属于本地主机用户识别码的文件或目录； -ok\u0026lt;执行指令\u0026gt;：此参数的效果和指定“-exec”类似，但在执行指令之前会先询问用户，若回答“y”或“Y”，则放弃执行命令； -path\u0026lt;范本样式\u0026gt;：指定字符串作为寻找目录的范本样式； -perm\u0026lt;权限数值\u0026gt;：查找符合指定的权限数值的文件或目录； -print：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为每列一个名称，每个名称前皆有“./”字符串； -print0：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式为全部的名称皆在同一行； -printf\u0026lt;输出格式\u0026gt;：假设find指令的回传值为Ture，就将文件或目录名称列出到标准输出。格式可以自行指定； -prune：不寻找字符串作为寻找文件或目录的范本样式; -regex\u0026lt;范本样式\u0026gt;：指定字符串作为寻找文件或目录的范本样式； -size\u0026lt;文件大小\u0026gt;：查找符合指定的文件大小的文件； -true：将find指令的回传值皆设为True； -type\u0026lt;文件类型\u0026gt;：只寻找符合指定的文件类型的文件； -uid\u0026lt;用户识别码\u0026gt;：查找符合指定的用户识别码的文件或目录； -used\u0026lt;日数\u0026gt;：查找文件或目录被更改之后在指定时间曾被存取过的文件或目录，单位以日计算； -user\u0026lt;拥有者名称\u0026gt;：查找符和指定的拥有者名称的文件或目录； -version或——version：显示版本信息； -xdev：将范围局限在先行的文件系统中； -xtype\u0026lt;文件类型\u0026gt;：此参数的效果和指定“-type”参数类似，差别在于它针对符号连接检查。 实例 #列出当前目录及子目录下所有文件和文件夹 find . find /home -name \u0026#34;*.txt\u0026#34; find /home -iname \u0026#34;*.txt\u0026#34; find . -name \u0026#34;*.txt\u0026#34; -o -name \u0026#34;*.pdf\u0026#34; #当前目录及子目录下查找所有以.txt和.pdf结尾的文件 find /usr/ -path \u0026#34;*local*\u0026#34; #匹配文件路径或者文件 find . -regex \u0026#34;.*\\(\\.txt\\|\\.pdf\\)$\u0026#34; #基于正则表达式匹配文件路径 find . -iregex \u0026#34;.*\\(\\.txt\\|\\.pdf\\)$\u0026#34; find /home ! -name \u0026#34;*.txt\u0026#34; #找出/home下不是以.txt结尾的文件 find . -name \u0026#34;*.erl\u0026#34; -or -name \u0026#34;*.hrl\u0026#34;|xargs cat|wc -l #查看所有文件行数 # @doc 文本操作 find xargs sed find . -name rebar.config|xargs sed -i \u0026#39;s/require_otp_vsn,\\s\\+\u0026#34;\\(.\\+\\)\u0026#34;/require_otp_vsn, \u0026#34;R15B03|R16B*|17|18\u0026#34;/g\u0026#39; find . -type 类型参数 #类型参数 f 普通文件 l 符号连接 d 目录 c 字符设备 b 块设备 s 套接字 p Fifo find . -maxdepth 3 -type f #向下最大深度限制为3 find . -mindepth 2 -type f #搜索出深度距离当前目录至少2个子目录的所有文件 find . -type f 时间戳 #UNIX/Linux文件系统每个文件都有三种时间戳： 访问时间（-atime/天，-amin/分钟）：用户最近一次访问时间。 修改时间（-mtime/天，-mmin/分钟）：文件最后一次修改时间。 变化时间（-ctime/天，-cmin/分钟）：文件数据元（例如权限等）最后一次修改时间。 find . -type f -newer file.log #找出比file.log修改时间更长的所有文件 #根据文件大小进行匹配 find . -type f -size 文件大小单元 find . -type f -size +10k #搜索大于10KB的文件 find . -type f -size -10k #搜索小于10KB的文件 find . -type f -size 10k #搜索等于10KB的文件 #文件大小单元 b —— 块（512字节） c —— 字节 w —— 字（2字节） k —— 千字节 M —— 兆字节 G —— 吉字节 #删除当前目录下所有.txt文件 find . -type f -name \u0026#34;*.txt\u0026#34; -delete #根据文件权限/所有权进行匹配 find . -type f -perm 777 #当前目录下搜索出权限为777的文件 find . -type f -name \u0026#34;*.php\u0026#34; ! -perm 644 #找出当前目录下权限不是644的php文件 find . -type f -user tom #找出当前目录用户tom拥有的所有文件 find . -type f -group sunk #找出当前目录用户组sunk拥有的所有文件 -user 用户名:根据文件的属主名查找文件。 -group 组名:根据文件的属组名查找文件。 -uid n:根据文件属主的 UID 进行查找文件。 -gid n:根据文件属组的 GID 进行查找文件。 -nouser:查询文件属主在/etc/passwd 文件中不存在的文件。 -nogroup:查询文件属组在/etc/group 文件中不存在的文件。 借助-exec选项与其他命令结合使用 find .-type f -user root -exec chown tom {} \\; #找出当前目录下所有root的文件，并把所有权更改为用户tom #上例中，{} 用于与-exec选项结合使用来匹配所有文件，然后会被替换为相应的文件名。 #找出自己家目录下所有的.txt文件并删除 find $HOME/. -name \u0026#34;*.txt\u0026#34; -ok rm {} \\; #查找当前目录下所有.txt文件并把他们拼接起来写入到all.txt文件中 find . -type f -name \u0026#34;*.txt\u0026#34; -exec cat {} \\;\u0026gt; all.txt #将30天前的.log文件移动到old目录中 find . -type f -mtime +30 -name \u0026#34;*.log\u0026#34; -exec cp {} old \\; #找出当前目录下所有.txt文件并以“File:文件名”的形式打印出来 find . -type f -name \u0026#34;*.txt\u0026#34; -exec printf \u0026#34;File: %s\\n\u0026#34; {} \\; #因为单行命令中-exec参数中无法使用多个命令，以下方法可以实现在-exec之后接受多条命令 -exec ./text.sh {} \\; find . -maxdepth 1 -name *.jpg -print -exec convert \u0026#34;{}\u0026#34; -resize 80x60 \u0026#34;thumbs/{}\u0026#34; \\; 搜索但跳出指定的目录 #查找当前目录或者子目录下所有.txt文件，但是跳过子目录sk find . -path \u0026#34;./sk\u0026#34; -prune -o -name \u0026#34;*.txt\u0026#34; -print find其他技巧收集 #要列出所有长度为零的文件 find . -empty "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/2.9-iconv/",
	"title": "2.9 iconv",
	"tags": [],
	"description": "",
	"content": "使用iconv库，转换文件编码 #!/bin/sh  FILES=$(find . -type f -name \u0026#39;*.*\u0026#39;) for f in $FILES do if test -f $f; then CHARSET=\u0026#34;$( file -bi \u0026#34;$f\u0026#34;|awk -F \u0026#34;=\u0026#34; \u0026#39;{print $2}\u0026#39;)\u0026#34; if [ \u0026#34;$CHARSET\u0026#34; != utf-8 ]; then echo -e \u0026#34;\\nConverting $ffrom $CHARSETto utf-8\u0026#34; # iconv -f \u0026#34;$CHARSET\u0026#34; -t utf-8 \u0026#34;$f\u0026#34; -o \u0026#34;$f.temp\u0026#34; iconv -f GBK -t UTF-8 \u0026#34;$f\u0026#34; -o \u0026#34;$f.temp\u0026#34; mv -f \u0026#34;$f.temp\u0026#34; $f fi else echo -e \u0026#34;\\nSkipping $f- it\u0026#39;s a regular file\u0026#34;; fi done #!/bin/bash  // batch_change_GB2312_to_UTF-8 cd directory find ./ -type f -name \u0026#34;*.java\u0026#34; | while read line;do echo $line iconv -f GB2312 -t UTF-8 $line \u0026gt; ${line}.utf8 mv $line ${line}.gb2312 mv ${line}.utf8 $line done find . -name *.java -exec sh -c \u0026#34;iconv -f GBK -t UTF8 {} \u0026gt; /tmp/iconv.tmp\u0026#34; \\; -exec mv /tmp/iconv.tmp \u0026#39;{}\u0026#39; \\; ```bash "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/3.%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/3.1-crontab/",
	"title": "3.1 crontab",
	"tags": [],
	"description": "",
	"content": "crontab 每次编辑完某个用户的cron设置后，cron自动在/var/spool/cron下生成一个与此用户同名的文件，\n此用户的cron信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用crontab -e 来编辑。\ncron启动后每过一份钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务。\n编辑/etc/crontab 文件配置cron\ncron服务每分钟不仅要读一次/var/spool/cron内的所有文件，还需要读一次/etc/crontab,因此我们配置这个文件也能运用 cron服务做一些事情。用crontab配置是针对某个用户的，而编辑/etc/crontab是针对系统的任务。\ncat /etc/crontab %系统任务调度的配置文件\n前四行是用来配置crond任务运行的环境变量，\n第一行SHELL变量指定了系统要使用哪个shell，这里是bash，\n第二行PATH变量指定了系统执行命令的路径，\n第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，\n第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。\n用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。\n01 ** ** root run-parts /etc/cron.hourly //每小时执行/etc/cron.hourly内的脚本 02 4 ** * root run-parts /etc/cron.daily //每天执行/etc/cron.daily内的脚本 22 4* *0 root run-parts /etc/cron.weekly //每星期执行/etc/cron.weekly内的脚本 42 4 1* * root run-parts /etc/cron.monthly //每月去执行/etc/cron.monthly内的脚本 大家注意\u0026quot;run-parts\u0026quot;这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是文件夹名了。\ncrontab文件的含义：\n用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：\nminute hour day month week command\n其中：\nminute： 表示分钟，可以是从0到59之间的任何整数。\nhour：表示小时，可以是从0到23之间的任何整数。\nday：表示日期，可以是从1到31之间的任何整数。\nmonth：表示月份，可以是从1到12之间的任何整数。\nweek：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。\ncommand：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。\n在以上各个字段中，还可以使用以下特殊字符：\n星号（）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。\n逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”\n中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”\n正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如/10，如果用在minute字段，表示每十分钟执行一次。\nCrontab命令详解 crontab -u # 设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数 crontab -l # 列出某个用户cron服务的详细内容 crontab -r # 删除某个用户的cron服务 crontab -e # 编辑某个用户的cron服务 比如说root查看自己的cron设置：crontab -u root -l 再例如，root想删除fred的cron设置：crontab -u fred -r 在编辑cron服务时，编辑的内容有一些格式和约定，输入：crontab -u root -e # 每天早上6点 0 6 ***echo \u0026#34;Good morning.\u0026#34; \u0026gt;\u0026gt; /tmp/test.txt # 注意单纯echo，从屏幕上看不到任何输出，因为cron把任何输出都email到root的信箱了。 # 每两个小时 0 */2** *echo \u0026#34;Have a break now.\u0026#34; \u0026gt;\u0026gt; /tmp/test.txt # 晚上11点到早上8点之间每两个小时，早上八点 0 23-7/2，8* **echo \u0026#34;Have a good dream：）\u0026#34; \u0026gt;\u0026gt; /tmp/test.txt # 每天4:30 30 4** *sh /root/backup.sh \u0026gt;\u0026gt; /dev/null 2\u0026gt;\u0026amp;1 # 每晚的21:30 30 21* **/usr/local/etc/rc.d/lighttpd restart # 每月1、10、22日的4 : 45 45 4 1,10,22** /usr/local/etc/rc.d/lighttpd restart # 在每天18 : 00至23 : 00之间每隔30分钟 0,30 18-23 ***/usr/local/etc/rc.d/lighttpd restart # 每星期六的11 : 00 pm 0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart # 每一小时 * */1*** /usr/local/etc/rc.d/lighttpd restart # 晚上11点到早上7点之间，每隔一小时 *23-7/1* ** /usr/local/etc/rc.d/lighttpd restart # 每月的4号与每周一到周三的11点 0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart # 一月一号的4点 0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart # 忽略日志输出 0 */3* ** /usr/local/apache2/apachectl restart \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 # “/dev/null 2\u0026gt;\u0026amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/3.%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/3.2-nohup/",
	"title": "3.2 nohup",
	"tags": [],
	"description": "",
	"content": "nohup 用途：不挂断地运行命令。\n　语法：nohup Command [ Arg \u0026hellip; ] [　\u0026amp; ]\n描述：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 \u0026amp; （ 表示\u0026quot;and\u0026quot;的符号）到命令的尾部。\nnohup /usr/bin/lantern \u0026amp; nohup /home/yujian/files/idea-IC-143.1184.17/bin/idea.sh \u0026amp; "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/3.%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/3.3-xclip/",
	"title": "3.3 xclip",
	"tags": [],
	"description": "",
	"content": "xclip xclip剪切板与终端的通道\n"
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/3.%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/3.4-tmux/",
	"title": "3.4 tmux",
	"tags": [],
	"description": "",
	"content": "tmux tmux ls tmux attach 1 tmux new -s session tmux new -s session -d #在后台建立会话 tmux ls #列出会话 tmux attach -t session #进入某个会话 查看/切换session ctrl+b s 离开Session ctrl+b d 重命名当前Session ctrl+b $ 关闭 ctrl+b \u0026amp;    分类 操作 说明     Ctrl+b  激活控制台；此时以下按键生效   系统操作 ? 列出所有快捷键；按q返回    d 脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话    D 选择要脱离的会话；在同时开启了多个会话时使用    Ctrl+z 挂起当前会话    r 强制重绘未脱离的会话    s 选择并切换会话；在同时开启了多个会话时使用    : 进入命令行模式；此时可以输入支持的命令，例如kill-server可以关闭服务器    [ 进入复制模式；此时的操作与vi/emacs相同，按q/Esc退出    ~ 列出提示信息缓存；其中包含了之前tmux返回的各种提示信息   窗口操作 c 创建新窗口    \u0026amp; 关闭当前窗口    数字键 切换至指定窗口    p 切换至上一窗口    n 切换至下一窗口    l 在前后两个窗口间互相切换    w 通过窗口列表切换窗口    , 重命名当前窗口；这样便于识别    . 修改当前窗口编号；相当于窗口重新排序    f 在所有窗口中查找指定文本   面板操作 ” 将当前面板平分为上下两块    % 将当前面板平分为左右两块    x 关闭当前面板    ! 将当前面板置于新窗口；即新建一个窗口，其中仅包含当前面板    Ctrl+方向键 以1个单元格为单位移动边缘以调整当前面板大小    Alt+方向键 以5个单元格为单位移动边缘以调整当前面板大小    Space 在预置的面板布局中循环切换；依次包括even-horizontal、even-vertical、main-horizontal、main-vertical、tiled    q 显示面板编号    o 在当前窗口中选择下一面板    方向键 移动光标以选择面板    { 向前置换当前面板    } 向后置换当前面板    Alt+o 逆时针旋转当前窗口的面板    Ctrl+o 顺时针旋转当前窗口的面板    "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/3.%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/3.5-systemd/",
	"title": "3.5 systemd",
	"tags": [],
	"description": "",
	"content": "systemd 开机执行shell脚本 sudo vim /home/yujian/tool/exec-shell.service [Unit] Description=exec shell After=network.target [Service] ExecStart=/home/yujian/tool/test.sh [Install] WantedBy=multi-user.target systemctl enable /home/yujian/tool/exec-shell.service # service文件移入系统目录 systemctl start exec-shell.service systemctl stop exec-shell.service systemctl status exec-shell.service systemctl is-active exec-shell.service systemctl disable exec-shell.service # 移除service文件 systemctl daemon-reload exec-shell.service # 修改service文件后需要刷新缓存 让我们看一下Linux系统在使用systemd作为引导程序时的开机启动过程的结构性细节。为了简单，我们将在下面按步骤列出来这个过程：\n  当你打开电源后电脑所做的第一件事情就是BIOS初始化。BIOS会读取引导设备设定，定位并传递系统控制权给MBR（假设硬盘是第一引导设备）。\n  MBR从Grub或LILO引导程序读取相关信息并初始化内核。接下来将由Grub或LILO继续引导系统。如果你在grub配置文件里指定了systemd作为引导管理程序，之后的引导过程将由systemd完成。Systemd使用“target”来处理引导和服务管理过程。这些systemd里的“target”文件被用于分组不同的引导单元以及启动同步进程。\n  systemd执行的第一个目标是default.target。但实际上default.target是指向graphical.target的软链接。Linux里的软链接用起来和Windows下的快捷方式一样。文件Graphical.target的实际位置是/usr/lib/systemd/system/graphical.target。在下面的截图里显示了graphical.target文件的内容。\n  在这个阶段，会启动multi-user.target而这个target将自己的子单元放在目录“/etc/systemd/system/multi-user.target.wants”里。这个target为多用户支持设定系统环境。非root用户会在这个阶段的引导过程中启用。防火墙相关的服务也会在这个阶段启动。\u0026ldquo;multi-user.target\u0026quot;会将控制权交给另一层“basic.target”。\n  \u0026ldquo;basic.target\u0026quot;单元用于启动普通服务特别是图形管理服务。它通过/etc/systemd/system/basic.target.wants目录来决定哪些服务会被启动，basic.target之后将控制权交给sysinit.target.\n  \u0026ldquo;sysinit.target\u0026quot;会启动重要的系统服务例如系统挂载，内存交换空间和设备，内核补充选项等等。sysinit.target在启动过程中会传递给local-fs.target。这个target单元的内容如下面截图里所展示。\n  local-fs.target，这个target单元不会启动用户相关的服务，它只处理底层核心服务。这个target会根据/etc/fstab和/etc/inittab来执行相关操作。\n  Systemd 支持的 12 种 Unit 文件类型\n .automount：用于控制自动挂载文件系统，相当于 SysV-init 的 autofs 服务\n.device：对于 /dev 目录下的设备，主要用于定义设备之间的依赖关系\n.mount：定义系统结构层次中的一个挂载点，可以替代过去的 /etc/fstab 配置文件\n.path：用于监控指定目录或文件的变化，并触发其它 Unit 运行\n.scope：这种 Unit 文件不是用户创建的，而是 Systemd 运行时产生的，描述一些系统服务的分组信息\n.service：封装守护进程的启动、停止、重启和重载操作，是最常见的一种 Unit 文件\n.slice：用于表示一个 CGroup 的树，通常用户不会自己创建这样的 Unit 文件\n.snapshot：用于表示一个由 systemctl snapshot 命令创建的 Systemd Units 运行状态快照\n.socket：监控来自于系统或网络的数据消息，用于实现基于数据自动触发服务启动\n.swap：定义一个用户做虚拟内存的交换分区\n.target：用于对 Unit 文件进行逻辑分组，引导其它 Unit 的执行。它替代了 SysV-init 运行级别的作用，并提供更灵活的基于特定设备事件的启动方式\n.timer：用于配置在特定时间触发的任务，替代了 Crontab 的功能\n /etc/systemd/system：系统或用户自定义的配置文件\n/run/systemd/system：软件运行时生成的配置文件\n/usr/lib/systemd/system：系统或第三方软件安装时添加的配置文件。\nsystemd-analyze time # 用于显示内核和普通用户空间启动时所花的时间。 systemd-analyze blame # 会列出所有正在运行的单元，按从初始化开始到当前所花的时间排序，通过这种方式你就知道哪些服务在引导过程中要花较长时间来启动。 systemd-analyze verify # 显示在所有系统单元中是否有语法错误。 systemd-analyze plot # 可以用来把整个引导过程写入一个SVG格式文件里。整个引导过程非常长不方便阅读，所以通过这个命令我们可以把输出写入一个文件，之后再查看和分析。下面这个命令就是做这个。 Unit 文件结构 busybox1.service\n[Unit] Description=Hello World After=docker.service Requires=docker.service [Service] TimeoutStartSec=0 ExecStartPre=-/usr/bin/docker kill busybox1 ExecStartPre=-/usr/bin/docker rm busybox1 ExecStartPre=/usr/bin/docker pull busybox ExecStart=/usr/bin/docker run --name busybox1 busybox /bin/ sh -c \u0026#34;while true; do echo Hello World; sleep 1; done\u0026#34; ExecStop=\u0026#34;/usr/bin/docker stop busybox1\u0026#34; ExecStopPost=\u0026#34;/usr/bin/docker rm busybox1\u0026#34; [Install] WantedBy=multi-user.target Unit 管理 查看当前系统的所有 Unit\n# 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service # 查看 Unit 配置文件的内容 $ systemctl cat docker.service 查看 Unit 的状态 enabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有 [Install] 部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接 # 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ ystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service Unit 的管理 # 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 查看 Unit 的依赖关系 # 列出一个 Unit 的所有依赖，默认不会列出 target 类型 $ systemctl list-dependencies nginx.service # 列出一个 Unit 的所有依赖，包括 target 类型 $ systemctl list-dependencies --all nginx.service 服务的生命周期 当一个新的 Unit 文件被放入 /etc/systemd/system/ 或 /usr/lib/systemd/system/ 目录中时，它是不会被自识识别的。\n# 服务的激活 systemctl enable：在 /etc/systemd/system/ 建立服务的符号链接，指向 /usr/lib/systemd/system/ 中 systemctl start：依次启动定义在 Unit 文件中的 ExecStartPre、ExecStart 和 ExecStartPost 命令 # 服务的启动和停止 systemctl start：依次启动定义在 Unit 文件中的 ExecStartPre、ExecStart 和 ExecStartPost 命令 systemctl stop：依次停止定义在 Unit 文件中的 ExecStopPre、ExecStop 和 ExecStopPost 命令 systemctl restart：重启服务 systemctl kill：立即杀死服务 # 服务的开机启动和取消 systemctl enable：除了激活服务以外，也可以置服务为开机启动 systemctl disable：取消服务的开机启动 # 服务的修改和移除 systemctl daemon-reload # Systemd 会将 Unit 文件的内容写到缓存中，因此当 Unit 文件被更新时，需要告诉Systemd 重新读取所有的 Unit 文件 systemctl reset-failed # 移除标记为丢失的 Unit 文件。在删除 Unit 文件后，由于缓存的关系，即使通过 daemon-reload 更新了缓存，在 list-units 中依然会显示标记为 not-found 的 Unit。 日志管理 Systemd 通过其标准日志服务 Journald 提供的配套程序 journalctl 将其管理的所有后台进程打印到 std:out（即控制台）的输出重定向到了日志文件。\nSystemd 的日志文件是二进制格式的，必须使用 Journald 提供的 journalctl 来查看，默认不带任何参数时会输出系统和所有后台进程的混合日志。\n默认日志最大限制为所在文件系统容量的 10%，可以修改 /etc/systemd/journald.conf 中的 SystemMaxUse 来指定该最大限制。\n# 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志）：--dmesg 或 -k $ sudo journalctl -k # 查看系统本次启动的日志（其中包括了内核日志和各类系统服务的控制台输出）：--system 或 -b $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定服务的日志：--unit 或 -u $ sudo journalctl -u docker.servcie # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定时间的日志 $ sudo journalctl --since=\u0026#34;2012-10-30 18:17:16\u0026#34; $ sudo journalctl --since \u0026#34;20 min ago\u0026#34; $ sudo journalctl --since yesterday $ sudo journalctl --since \u0026#34;2015-01-10\u0026#34; --until \u0026#34;2015-01-11 03:00\u0026#34; $ sudo journalctl --since 09:00 --until \u0026#34;1 hour ago\u0026#34; # 显示尾部的最新 10 行日志：--lines 或 -n $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 将最新的日志显示在前面 $ sudo journalctl -r -u docker.service # 改变输出的格式：--output 或 -o $ sudo journalctl -r -u docker.service -o json-pretty # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /usr/bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有 8 级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years Systemd 工具集 systemctl：用于检查和控制各种系统服务和资源的状态\nbootctl：用于查看和管理系统启动分区\nhostnamectl：用于查看和修改系统的主机名和主机信息\njournalctl：用于查看系统日志和各类应用服务日志\nlocalectl：用于查看和管理系统的地区信息\nloginctl：用于管理系统已登录用户和 Session 的信息\nmachinectl：用于操作 Systemd 容器\ntimedatectl：用于查看和管理系统的时间和时区信息\nsystemd-analyze 显示此次系统启动时运行每个服务所消耗的时间，可以用于分析系统启动过程中的性能瓶颈\nsystemd-ask-password：辅助性工具，用星号屏蔽用户的任意输入，然后返回实际输入的内容\nsystemd-cat：用于将其他命令的输出重定向到系统日志\nsystemd-cgls：递归地显示指定 CGroup 的继承链\nsystemd-cgtop：显示系统当前最耗资源的 CGroup 单元\nsystemd-escape：辅助性工具，用于去除指定字符串中不能作为 Unit 文件名的字符\nsystemd-hwdb：Systemd 的内部工具，用于更新硬件数据库\nsystemd-delta：对比当前系统配置与默认系统配置的差异\nsystemd-detect-virt：显示主机的虚拟化类型\nsystemd-inhibit：用于强制延迟或禁止系统的关闭、睡眠和待机事件\nsystemd-machine-id-setup：Systemd 的内部工具，用于给 Systemd 容器生成 ID\nsystemd-notify：Systemd 的内部工具，用于通知服务的状态变化\nsystemd-nspawn：用于创建 Systemd 容器\nsystemd-path：Systemd 的内部工具，用于显示系统上下文中的各种路径配置\nsystemd-run：用于将任意指定的命令包装成一个临时的后台服务运行\nsystemd-stdio- bridge：Systemd 的内部 工具，用于将程序的标准输入输出重定向到系统总线\nsystemd-tmpfiles：Systemd 的内部工具，用于创建和管理临时文件目录\nsystemd-tty-ask-password-agent：用于响应后台服务进程发出的输入密码请求\nsystemctl # 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze # 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流 $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl # 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname rhel7 timedatectl # 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl # 列出当前 session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/4.%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/4.1-du/",
	"title": "4.1 du",
	"tags": [],
	"description": "",
	"content": "du du -h --max-depth=1 du -h --max-depth=0 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/4.%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/4.2-mount/",
	"title": "4.2 mount",
	"tags": [],
	"description": "",
	"content": "mount mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 \u0026#39;/ mnt/hda2\u0026#39; 已经存在 mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrom mount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrom mount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrom mount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件 mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统 mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备 mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享磁盘空间 mount -a # 会/etc/fstab中的项全部挂载，如果有错，则会提示错误，然后根据错误找出原因修改。 umount umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 \u0026#39;/mnt/hda2\u0026#39; 退出 umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用 fuser fuser -km /mnt/hda2 当设备繁忙时强制卸载 自动挂载盘 sudo fdisk -l 查看目前拥有的盘符 sudo vim /etc/fstab 修改fstab文件 设备名称 挂载点 分区类型 挂载选项 dump选项 fsck选项 /dev/sdb6 none swap sw 0 0 /dev/sdb1 /xp auto auto 0 0 /dev/sda7 /work auto auto 0 0 /dev/sdb2 /movie auto auto 0 0 (1)设备名称 /dev/device就是需要挂载的设备，/hda2就是第一个IDE插槽上的主硬盘的第二个分区。如果是第二个IDE插槽主硬盘的第三个分区，那就是dev/hdc3，具体可以在linux下使用fdisk -l 查看。 (2)挂载点 mountpoint 就是挂载点。/、 /usr、 swap 都是系统安装时分区的默认挂载点。 如果你要挂载一个新设备，你就要好好想想了，因为这个新设备将作为文件系统永久的一部分，需要根据FSSTND（文件系统标准），以及它的用，用户需求来决定。比如你想把它做为一个共享资源，放在/home下面就是一个不错选择。 (3)分区类型 type 是指文件系统类型，下面列举几个常用的： Linux file systems: ext2, ext3, jfs, reiserfs, reiser4, xfs, swap. Windows: vfat = FAT 32, FAT 16 ntfs= NTFS Note: For NTFS rw ntfs-3g CD/DVD/iso: iso9660 Network file systems: nfs: server:/shared_directory /mnt/nfs nfs \u0026lt;options\u0026gt; 0 0 smb: //win_box/shared_folder /mnt/samba smbfs rw,credentials=/home/user_name/winbox-credentials.txt 0 0 auto: The file system type (ext3, iso9660, etc) it detected automatically. Usually works. Used for removabledevices (CD/DVD, Floppy drives, or USB/Flash drives) as the file system may vary on thesedevices. (4)挂载选项 rules 是指挂载时的规则。下面列举几个常用的： auto 开机自动挂载 default 按照大多数永久文件系统的缺省值设置挂载定义 noauto 开机不自动挂载 nouser 只有超级用户可以挂载 ro 按只读权限挂载 rw 按可读可写权限挂载 user 任何用户都可以挂载 请注意光驱和软驱只有在装有介质时才可以进行挂载，因此它是noauto (5)dump选项 这一项为0，就表示从不备份。如果上次用dump备份，将显示备份至今的天数。 (6)fsck选项 order 指fsck（启动时fsck检查的顺序）。为0就表示不检查，（/）分区永远都是1，其它的分区只能从2开始，当数字相同就同时检查（但能有两1）。 如果我要把第二个IDE插槽主硬盘上的windows C 区挂到文件系统中，那么数据项是： /dev/hdc1 /c vfat defaults 0 0 (/c 是事先建立的文件夹，作为c盘的挂载点。) "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.3-lets-encrypt/4.3.1-acme/",
	"title": "4.3.1 acme",
	"tags": [],
	"description": "",
	"content": "acme.sh #!/bin/sh ##crontab -uroot -e ##30 4 * * * sh /root/cron/daily.sh \u0026gt; /root/cron/log_daily.log ## acme.sh curl https://get.acme.sh | sh export Ali_Key=\u0026#34;aaa\u0026#34; export Ali_Secret=\u0026#34;bbb\u0026#34; acme.sh --issue --dns dns_ali -d 01cs.cc -d *.01cs.cc # 手动 dns 方式, 手动在域名上添加一条 txt 解析记录, 验证域名所有权. # 然后 acme.sh 会生成相应的解析记录显示出来, 你只需要在你的域名管理面板中添加这条 txt 记录即可. #等待解析完成之后, 重新生成证书: acme.sh --issue -d htjicon.com -d *.htjicon.com --yes-I-know-dns-manual-mode-enough-go-ahead-please --dns acme.sh --renew -d htjicon.com -d *.htjicon.com --yes-I-know-dns-manual-mode-enough-go-ahead-please acme.sh --renew -d htjicon.com -d *.htjicon.com --yes-I-know-dns-manual-mode-enough-go-ahead-please --force # 自动更新 acme.sh --installcert --force -d 01cs.cc -d *.01cs.cc --key-file /usr/local/nginx/conf/01cs.cc/01cs.cc.key --fullchain-file /usr/local/nginx/conf/01cs.cc/fullchain.cer --reloadcmd \u0026#34;service nginx force-reload\u0026#34; #nginx使用证书 ssl_certificate_key .acme.sh/htjicon.com/htjicon.com.key ssl_certificate .acme.sh/htjicon.com/fullchain.cer ## 软件更新新版本 acme.sh --upgrade acme.sh --upgrade --auto-upgrade #自动升级 acme.sh --upgrade --auto-upgrade 0 #关闭自动更新 "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.4.4-svn/",
	"title": "4.4.4 svn",
	"tags": [],
	"description": "",
	"content": "svn ## 安装svnserver yum -y install subversion ## 初始化 cd project mkdir svn cd svn svnadmin create project_svn ## 启动 svnserve -d -r /root/project/svn svnserve -d -r /root/project/svn --listen-port 8086 svnserve -d -r /root/project/svn checkout svn checkout svn://127.0.0.1/ project_svn ## Vim passwd yujian = enter123 huyuwei = enter123 Vim authz [groups] admin_group = gm,admin,yujian,wumanyu [haowenjiao:/Client] @client = rw [[project]:/] @admin_group = rw * = ## 所有权限 [/] * = rw Vim svnserve.conf anon-access = none auth-access = write password-db = passwd authz-db = authz realm = /svn/the_repository "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/6.1-tcpdump/",
	"title": "6.1 tcpdump",
	"tags": [],
	"description": "",
	"content": "tcpdump sudo tcpdump -i lo port 8080 and \u0026#39;tcp[tcpflags] \u0026amp; (tcp-syn|tcp-fin) !=0\u0026#39; -nn 查看本机8080端口的流量 sudo tcpdump -i lo \u0026#39;port 42442\u0026#39; -vvv -XX "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/6.2-curl/",
	"title": "6.2 curl",
	"tags": [],
	"description": "",
	"content": "curl linux curl是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称url为下载工具。\n   命令 说明     -c/\u0026ndash;cookie-jar file 操作结束后把cookie写入到这个文件中   -C/\u0026ndash;continue-at offset 断点续转   -d/\u0026ndash;data data HTTP POST方式传送数据   \u0026ndash;data-binary data 以二进制的方式post数据   -F/\u0026ndash;form name=content 模拟http表单提交数据   -form-string name=string 模拟http表单提交数据   -i/\u0026ndash;include 输出时包括protocol头信息   -I/\u0026ndash;head 只显示文档信息   -o/\u0026ndash;output \u0026lt;http.txt\u0026gt; 把输出写到该文件中   -O url get 文件   -# 进度条    # 常用curl实例 # 上传 %正常的表单提交 curl -d \u0026#34;user=nickwolfe\u0026amp;password=test\u0026#34; url # %multipart/form-data curl -H \u0026#34;a:b\u0026#34; -F \u0026#34;filename=@text.txt\u0026#34; -i url # %文件二进制上传 curl -X PUT -H \u0026#34;Content-Type:image/png\u0026#34; \\--data-binary @test.jpg -i -o response.html url -i 显示header信息 -o response.html 把结果写入response.html get curl -o home.html url %模拟表单信息，模拟登录，保存cookie信息 curl -c ./cookie_c.txt -F log=aaaa -F pwd=****** \u0026lt;url\u0026gt; curl -D ./cookie_D.txt -F log=aaaa -F pwd=****** \u0026lt;url\u0026gt; % -c(小写)产生的cookie和-D里面的cookie是不一样的 通过ftp下载文件 curl -u 用户名:密码 -O \u0026lt;url\u0026gt; curl -O ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files/style.css 通过ftp上传 curl -T test.sql ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files/ "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/6.3-ssh/",
	"title": "6.3 ssh",
	"tags": [],
	"description": "",
	"content": "ssh # 安装 yum install SSH apt install openssl vim /etc/ssh/sshd_config systemctl restart sshd Port 22 #端口 添加一行：Port 23 #多个ssh连接端口 PasswordAuthentication no #禁用密码验证 RSAAuthentication yes #启用密钥验证 PubkeyAuthentication yes AuthorsizedKeysFile .ssh/authorized_keys #指定公钥数据库文件 ssh localhost -p port #测试 ssh –l user –p 22 britepic.org ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; # 创建一个默认密钥 ssh-copy-id -i ali.pub one@120.24.100.174 # 远程添加密钥 scp file host:/home/user/path ssh -V # debug模式 ssh-add ~/.ssh/id_rsa # 添加默认密钥 ssh-keygen ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; eval \u0026#34;$(ssh-agent -s)\u0026#34; 别名登陆 vim ~/.ssh/config \u0026gt;ssh 别名 Host ali #别名 HostName 120.24.100.174 #主机名 Port 端口 User root #用户名 PreferredAuthentications publickey IdentityFile ~/.ssh/ali #密钥文件的路径 ssh 穿透内网 ssh -NfR 远端主机listen port:远端连回时导向的主机 : 远端连回本地主机时导向主机的port 帐号@远端主机 外网服务器:115.159.22.131 内网服务器：localhost 内网命令 systemctl start ssh ssh -v -fCNR 63095:localhost:22 root@115.159.22.131 autossh -M 5678 -NR 63095:localhost:22 root@115.159.22.131 外网命令 ssh-keygen -t rsa 复制 .pub到内网authorized_keys ssh -i ~/.ssh/yj_work/115_159_22_131 yj@localhost -p 63095 -1：强制使用ssh协议版本1； -2：强制使用ssh协议版本2； -4：强制使用IPv4地址； -6：强制使用IPv6地址； -A：开启认证代理连接转发功能； -a：关闭认证代理连接转发功能； -b：使用本机指定地址作为对应连接的源ip地址； -C：请求压缩所有数据； -F：指定ssh指令的配置文件； -f：后台执行ssh指令； -g：允许远程主机连接主机的转发端口； -i：指定身份文件； -l：指定连接远程服务器登录用户名； -N：不执行远程指令； -o：指定配置选项； -p：指定远程服务器上的端口； -q：静默模式； -X：开启X11转发功能； -x：关闭X11转发功能； -y：开启信任X11转发功能。 安装 yum install SSH sudo apt install openssl systemctl restart sshd 配置 vim /etc/ssh/sshd_config Port 22 #端口 Port 23 #多个ssh连接端口 添加一行 PasswordAuthentication no #禁用密码验证 RSAAuthentication yes #启用密钥验证 PubkeyAuthentication yes AuthorsizedKeysFile .ssh/authorized_keys #指定公钥数据库文件 UseDNS no #在最后添加下面一行,关闭 SSH 的 DNS 反解析 GSSAPIAuthentication yes #改成 no gssapi-with-mic GatewayPorts clientspecified || yes # 让中继服务器上的 sshd 不仅转发回环地址上的端口，还要转发外部主机的端口。这通过指定中继服务器上运行的 sshd 的 GatewayPorts 实现 PermitRootLogin no #禁止ROOT远程SSH登录 实例 ssh localhost -p port ssh -l user -p 22 host ssh-keygen -t rsa # 创建一个默认密钥 ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; eval \u0026#34;$(ssh-agent -s)\u0026#34; ssh-copy-id -i ali.pub one@120.24.100.174 # 远程添加密钥 scp file host:/home/user/path ssh -vvvv #debug模式 ssh-add ~/.ssh/id_rsa #添加默认密钥 #别名登陆 vim ~/.ssh/config yj@yj:~$ssh aaa Host aaa #别名 HostName 120.24.100.174 #主机名 Port 22 #端口 User root #用户名 PreferredAuthentications publickey IdentityFile ~/.ssh/ali #密钥文件的路径 #反向SSH隧道,只能远端主机登陆 ssh -fN -R [远端主机port]:[远端连回时导向的主机]:[远端连回本地主机时的port] [帐号@远端主机] yj@yj:~$ssh -fN -R 63095:localhost:22 root@118.24.189.248 root@118.24.189.248:~$netstat -nap | grep 63095 root@118.24.189.248:~$ssh -p 63095 yj@localhost #反向SSH隧道,所有主机登陆 yj@yj:~$ssh -fN -R 118.24.189.248:63095:localhost:22 root@118.24.189.248 其他服务器:~$ssh -p 63095 yj@118.24.189.248 #永久反向 SSH 隧道 autossh yj@yj:~$autossh -M 10900 -fN -o \u0026#34;PubkeyAuthentication=yes\u0026#34; -o \u0026#34;StrictHostKeyChecking=false\u0026#34; -o \u0026#34;PasswordAuthentication=no\u0026#34; -o \u0026#34;ServerAliveInterval 60\u0026#34; -o \u0026#34;ServerAliveCountMax 3\u0026#34; -R 118.24.189.248:63095:localhost:22 root@118.24.189.248 #-M 10900 选项指定中继服务器上的监视端口，用于交换监视 SSH 会话的测试数据。中继服务器上的其它程序不能使用这个端口。 #-fN 选项传递给 ssh 命令，让 SSH 隧道在后台运行。 #-o XXXX 选项让 ssh： #使用密钥验证，而不是密码验证。 #自动接受（未知）SSH 主机密钥。 #每 60 秒交换 keep-alive 消息。 #没有收到任何响应时最多发送 3 条 keep-alive 消息。 创建服务器证书密钥 openssl genrsa -des3 -out ssl.key 2048 #没有密码的key openssl rsa -in server.key -out server.key #创建服务器证书的申请文件server.csr openssl req -new -key server.key -out server.csr #创建自当前日期起有效期为期两年的服务器证书server.crt openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAserial root.srl -CAcreateserial -in server.csr -out server.crt #创建客户端证书密钥文件client.key openssl genrsa -des3 -out client.key 2048 生成ssl签名步骤 openssl genrsa -des3 -out server.key 1024 #用于生成rsa私钥文件 openssl req -new -key server.key -out server.csr #openssl req 用于生成证书请求 openssl rsa -in server.key -out server_nopwd.key #利用openssl进行RSA为公钥加密 openssl x509 -req -days 365 -in server.csr -signkey server_nopwd.key -out server.crt 客户端配置 ssh_config # 每30秒发送一次心跳检测 ServerAliveInterval 30 # 超过10次都没有成功，就主动断开与服务器的连接 ServerAliveCountMax 10 服务端配置 sudo vim /etc/ssh/sshd_config ClientAliveInterval 30 #ClientAliveInterval表示每隔多少秒，服务器端向客户端发送心跳，是的，你没看错。 ClientAliveCountMax 6 #下面的ClientAliveInterval表示上述多少次心跳无响应之后，会认为Client已经断开。 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/6.4-tc/",
	"title": "6.4 tc",
	"tags": [],
	"description": "",
	"content": "基本用法 tc qdisc show # 显示 tc qdisc add dev eth0 root ...... # 加入 tc qdisc change dev eth0 root ...... # 修改存在的 qdisc ,记的,加入同一条后只能用 change 来修改 tc qdisc del dev eth0 root # 删除 tc qdisc add dev eth0 root netem delay 3000ms 延时模拟3000ms tc qdisc add dev eth0 root netem delay 3000ms 2000ms 延时模拟3000ms+-2000ms tc qdisc change dev eth0 root netem loss 50% 设置丢包 50% tc qdisc change dev eth0 root netem loss 50% 80% 设置丢包 50%-80%之间 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/6.5-firewall/",
	"title": "6.5 firewall",
	"tags": [],
	"description": "",
	"content": "firewall-cmd firewall-cmd提供了一个动态管理的防火墙，支持网络/防火墙区域来定义网络连接或接口的信任级别。它支持IPv4、IPv6防火墙设置和以太网网桥，并将运行时和永久配置选项分开。它还支持服务或应用程序直接添加防火墙规则的接口。\n使用firewalld的好处可以在运行时环境中立即进行更改，不需要重新启动服务或守护程序；使用firewalld D-Bus接口，服务，应用程序和用户都可以轻松调整防火墙设置。界面完整，用于防火墙配置工具firewall-cmd，firewall-config和firewall-applet。\nfirewall-cmd 是 firewalld的字符界面管理工具，firewalld是centos7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念。\nfirewalld跟iptables比起来至少有两大好处：\n firewalld可以动态修改单条规则，而不需要像iptables那样，在修改了规则后必须得全部刷新才可以生效。 firewalld在使用上要比iptables人性化很多，即使不明白“五张表五条链”而且对TCP/IP协议也不理解也可以实现大部分功能。  firewalld自身并不具备防火墙的功能，而是和iptables一样需要通过内核的netfilter来实现，也就是说firewalld和 iptables一样，他们的作用都是用于维护规则，而真正使用规则干活的是内核的netfilter，只不过firewalld和iptables的结构以及使用方法不一样罢了。\n基本用法 https://linux.cn/article-8098-1.html#3_2383\n# 安装firewalld yum install firewalld firewall-config # 服务 service firewalld start systemctl start ||enable || stop || disable firewalld firewall-cmd --version # 查看版本 firewall-cmd --help # 查看帮助 man firewall-cmd ##查看帮助 # 常用命令介绍 firewall-cmd --state ##查看防火墙状态，是否是running firewall-cmd --reload ##重新载入配置，比如添加规则之后，需要执行此命令 （持久化行该命令后生效） firewall-cmd --get-zones ##列出支持的zone firewall-cmd --get-services ##列出支持的服务，在列表中的服务是放行的 firewall-cmd --query-service ftp ##查看ftp服务是否支持，返回yes或者no firewall-cmd --add-service=ftp ##临时开放ftp服务 firewall-cmd --add-service=ftp --permanent ##永久开放ftp服务 firewall-cmd --remove-service=ftp --permanent ##永久移除ftp服务 firewall-cmd --add-port=80/tcp --permanent ##永久添加80端口 iptables -L -n ##查看规则，这个命令是和iptables的相同的 # 重新加载配置 --permanent firewall-cmd --zone=public --add-service=http --permanent(持久化) firewall-cmd --zone=public --add-service=http(运行时) firewall-cmd --zone=public --add-service=http --permanent(持久化) firewall-cmd --get-default-zone # 默认区域 firewall-cmd --set-default-zone=internal # 修改默认区域 firewall-cmd --get-active-zones # 网络接口使用的区域 firewall-cmd --zone=public --list-all # 特定区域的所有配置 firewall-cmd --list-all-zones 所有区域的配置 firewall-cmd --get-services # 默认的可用服务 实例 firewall-cmd --zone=public --add-service=http --permanent # 启用或禁用 HTTP 服务 firewall-cmd --zone=public --remove-service=http --permanent firewall-cmd --zone=public --add-port=12345-12388/tcp --permanent # 允许或者拒绝任意端口/协议 firewall-cmd --zone=public --remove-port=12345-12388/tcp --permanent firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=12345 # 端口转发（在同一台服务器上将 80 端口的流量转发到 12345 端口） firewall-cmd --zone=public --add-masquerade # 将端口转发到另外一台服务器上 # 添加转发规则，将本地的 80 端口的流量转发到 IP 地址为 ：123.456.78.9 的远程服务器上的 8080 端口 firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=8080:toaddr=123.456.78.9 firewall-cmd --zone=public --remove-masquerade 配置firewalld firewall-cmd --version # 查看版本 firewall-cmd --help # 查看帮助 # 查看设置： firewall-cmd --state # 显示状态 firewall-cmd --get-active-zones # 查看区域信息 firewall-cmd --get-zone-of-interface=eth0 # 查看指定接口所属区域 firewall-cmd --panic-on # 拒绝所有包 firewall-cmd --panic-off # 取消拒绝状态 firewall-cmd --query-panic # 查看是否拒绝 firewall-cmd --reload # 更新防火墙规则 firewall-cmd --complete-reload # 两者的区别就是第一个无需断开连接，就是firewalld特性之一动态添加规则，第二个需要断开连接，类似重启服务 # 将接口添加到区域，默认接口都在public firewall-cmd --zone=public --add-interface=eth0 # 永久生效再加上 --permanent 然后reload防火墙 # 设置默认接口区域，立即生效无需重启 firewall-cmd --set-default-zone=public # 查看所有打开的端口： firewall-cmd --zone=dmz --list-ports # 加入一个端口到区域： firewall-cmd --zone=dmz --add-port=8080/tcp # 若要永久生效方法同上 # 打开一个服务，类似于将端口可视化，服务需要在配置文件中添加，/etc/firewalld 目录下有services文件夹，这个不详细说了，详情参考文档 firewall-cmd --zone=work --add-service=smtp # 移除服务 firewall-cmd --zone=work --remove-service=smtp # 显示支持的区域列表 firewall-cmd --get-zones # 设置为家庭区域 firewall-cmd --set-default-zone=home # 查看当前区域 firewall-cmd --get-active-zones # 设置当前区域的接口 firewall-cmd --get-zone-of-interface=enp03s # 显示所有公共区域（public） firewall-cmd --zone=public --list-all # 临时修改网络接口（enp0s3）为内部区域（internal） firewall-cmd --zone=internal --change-interface=enp03s # 永久修改网络接口enp03s为内部区域（internal） firewall-cmd --permanent --zone=internal --change-interface=enp03s 服务管理\n# 显示服务列表 Amanda, FTP, Samba和TFTP等最重要的服务已经被FirewallD提供相应的服务，可以使用如下命令查看： firewall-cmd --get-services # 允许SSH服务通过 firewall-cmd --enable service=ssh # 禁止SSH服务通过 firewall-cmd --disable service=ssh # 打开TCP的8080端口 firewall-cmd --enable ports=8080/tcp # 临时允许Samba服务通过600秒 firewall-cmd --enable service=samba --timeout=600 # 显示当前服务 firewall-cmd --list-services # 添加HTTP服务到内部区域（internal） firewall-cmd --permanent --zone=internal --add-service=http firewall-cmd --reload # 在不改变状态的条件下重新加载防火墙 端口管理\n# 打开443/TCP端口 firewall-cmd --add-port=443/tcp # 永久打开3690/TCP端口 firewall-cmd --permanent --add-port=3690/tcp # 永久打开端口不需要reload # 临时打开端口后, 执行reload命令本次操作命令会被还原 firewall-cmd --reload # 查看防火墙，添加的端口也可以看到 firewall-cmd --list-all 直接模式\n# FirewallD包括一种直接模式，使用它可以完成一些工作，例如打开TCP协议的9999端口 firewall-cmd --direct -add-rule ipv4 filter INPUT 0 -p tcp --dport 9000 -j ACCEPT firewall-cmd --reload firewall-cmd --add-port=3306/tcp --permanent firewall-cmd --reload firewall-cmd --list-ports 控制端口 / 服务 可以通过两种方式控制端口的开放，一种是指定端口号另一种是指定服务名。虽然开放 http 服务就是开放了 80 端口，但是还是不能通过端口号来关闭，也就是说通过指定服务名开放的就要通过指定服务名关闭；通过指定端口号开放的就要通过指定端口号关闭。还有一个要注意的就是指定端口的时候一定要指定是什么协议，tcp 还是 udp。知道这个之后以后就不用每次先关防火墙了，可以让防火墙真正的生效。\nfirewall-cmd --add-service=mysql # 开放mysql端口 firewall-cmd --remove-service=http # 阻止http端口 firewall-cmd --list-services # 查看开放的服务 firewall-cmd --add-port=3306/tcp # 开放通过tcp访问3306 firewall-cmd --remove-port=80tcp # 阻止通过tcp访问3306 firewall-cmd --add-port=233/udp # 开放通过udp访问233 firewall-cmd --list-ports # 查看开放的端口 伪装 IP\nfirewall-cmd --query-masquerade # 检查是否允许伪装IP firewall-cmd --add-masquerade # 允许防火墙伪装IP firewall-cmd --remove-masquerade# 禁止防火墙伪装IP 端口转发 端口转发可以将指定地址访问指定的端口时，将流量转发至指定地址的指定端口。转发的目的如果不指定 ip 的话就默认为本机，如果指定了 ip 却没指定端口，则默认使用来源端口。 如果配置好端口转发之后不能用，可以检查下面两个问题： 1.比如我将 80 端口转发至 8080 端口，首先检查本地的 80 端口和目标的 8080 端口是否开放监听了 2.其次检查是否允许伪装 IP，没允许的话要开启伪装 IP\nservice firewalld start firewall-cmd --add-forward-port=port=80:proto=tcp:toport=8080 # 将80端口的流量转发至8080 firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.0.1 # 将80端口的流量转发至192.168.0.1 firewall-cmd --add-forward-port=port=80:proto=tcp:toaddr=192.168.0.1:toport=8080 # 将80端口的流量转发至192.168.0.1的8080端口 firewall-cmd --zone=public --add-masquerade firewall-cmd --permanent --zone=public --add-forward-port=port=26199:proto=tcp:toport=3306:toaddr=10.66.195.156 firewall-cmd --permanent --zone=public --add-forward-port=port=26000-26200/tcp firewall-cmd --zone=public --remove-masquerade  当我们想把某个端口隐藏起来的时候，就可以在防火墙上阻止那个端口访问，然后再开一个不规则的端口，之后配置防火墙的端口转发，将流量转发过去。 端口转发还可以做流量分发，一个防火墙拖着好多台运行着不同服务的机器，然后用防火墙将不同端口的流量转发至不同机器。  "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.3.4-frp/",
	"title": "frp",
	"tags": [],
	"description": "",
	"content": "frp内网穿透 资料 https://github.com/fatedier/frp\n配置 命令 # 通过 ssh 访问内网机器，假设用户名为 test： ssh -i ~/.ssh/id_rsa -oPort=60000 yj@127.0.0.1 安全地暴露内网服务 服务端 [common] bind_port = 44099 # kcp 绑定的是 udp 端口，可以和 bind_port 一样 kcp_bind_port = 44099 max_pool_count = 2 # 身分验证 privilege_token = 1234567890 客户端1-要登陆的内网服务器 # frpc.ini [common] server_addr = x.x.x.x server_port = 63095 pool_count = 8 protocol = kcp [secret_ssh] type = stcp # 只有 sk 一致的用户才能访问到此服务 sk = abcdefg local_ip = 127.0.0.1 local_port = 22 客户端2-服务器端启动-安全地暴露内网服务 # frpc.ini [common] server_addr = 127.0.0.1 server_port = 44099 pool_count = 2 protocol = kcp # 身分验证 privilege_token = e4399ea4b6f256fa0e3224bd6dc098ec [secret_ssh_visitor] type = stcp # stcp 的访问者 role = visitor # 要访问的 stcp 代理的名字 server_name = secret_ssh sk = dfa703bab2bc19d631cfde114f4807b1 bind_addr = 127.0.0.1 bind_port = 60000 连接池 # frps.ini [common] max_pool_count = 5 # frpc.ini [common] pool_count = 1 "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.7-git/git/",
	"title": "git",
	"tags": [],
	"description": "",
	"content": "安装 ubuntu sudo apt-get install git #常用命令 git config git clone url git clone \u0026lt;repository::指定远程数据库的 URL\u0026gt; \u0026lt;directory::指定新目录的名称\u0026gt; %克隆 git pull %从服务器获取文件，使用 pull 指令进行拉取操作。省略数据库名称的话，会在名为 origin 的数据库进行 pull git add %现在需要同步的文件 git add -A git commit %添加到本地数据库 git commit -m \u0026#34;msg\u0026#34; git push %同步到网络服务器,把本地服务器中的文件同步到网络服务器，push 之前需要 commit git remote -h 修改服务端仓库 git remote rm origin git remote add origin git@git.oschina.net:fuhu/aya.git git remote -v 获取服务端仓库 # 分支branch git branch name %新建分支 git checkout name %进入该分支 git push --set-upstream origin branch_name git push origin --delete \u0026lt;branchName\u0026gt; %删除远程分支 git branch -d \u0026lt;branchName\u0026gt; %%删除本地分支 ## 标签tag git tag git tag -l \u0026#34;v1.8.5*\u0026#34; git show v1.4 git tag -a v1.0.0 -m \u0026#34;my version 1.0.0\u0026#34; git push origin v1.0.0 git push origin --tags git push origin --delete tag \u0026lt;tagname\u0026gt; %删除服务端 tag git tag -d \u0026lt;tagname\u0026gt; 删除本地 tag git reset --hard V1.1 本地代码重置到某个 tag ## branch和tag 重复 git push origin :notmaster git push origin :refs/heads/\u0026lt;branch\u0026gt; git remote show origin git remote prune origin ## 合并 git merge git checkout master git merge develop git push ## 检出 checkout git checkout master git checkout -b version2 v2.0.0 git checkout -b branch_name tag_name ## 撤销 reset git reset --hard %重置本地所有改动，保持和服务器版本一致 git reset --soft HEAD^ 撤回 commit 操作，保留代码 git reset --hard commit_id 撤回 commit 操作，重置到 commit_id 版本，改动代码也被重置 git reset --mixed HEAD^ 不删除工作空间改动代码，撤销 commit，并且撤销 git add . 操作 --soft 不删除工作空间改动代码，撤销 commit，不撤销 git add . --hard 删除工作空间改动代码，撤销 commit，撤销 git add . 注意完成这个操作后，就恢复到了上一次的 commit 状态。 git commit --amend 修改注释 ## 回退 revert 公共远程分支版本回退 自己的分支回滚直接用 reset 公共分支回滚用 revert git revert HEAD //撤销最近一次提交 git revert HEAD~1 //撤销上上次的提交，注意：数字从 0 开始 git revert 0ffaacc //撤销 0ffaacc 这次提交 错的太远了直接将代码全部删掉，用正确代码替代 ## 服务端部署 服务端创建一个空仓库 git --bare init game.git # 客户端 git clone root@115.159.22.131:~/git/game.git git config --global user.name \u0026#34;YOUR NAME\u0026#34; git config --global user.email \u0026#34;YOUR EMAIL ADDRESS\u0026#34; git init 初始化 git branch -a 查看分支，列出的分支中，带有*的为本地分支，其他为远程分支 git remote -v git remote remove origin git remote add origin root@115.159.22.131:~/git/game.git git push origin master ## git stash git stash: 备份当前的工作区的内容，从最近的一次提交中读取相关内容，让工作区保证和上次提交的内容一致。同时，将当前的工作区内容保存到 Git 栈中。 git stash %把当前改动复制一个版本后，重置本地改动到服务器最新版本 git pull origin master %1.更新最新代码（包含冲突文件）2.手动改动代码 3.提交到服务端 git stash pop %复制的版本和最新版本对比。 git log master -n 1 --pretty=commit:%H \u0026gt; git_version %生成版本号 git stash pop: 从 Git 栈中读取最近一次保存的内容，恢复工作区的相关内容。由于可能存在多个 Stash 的内容，所以用栈来管理，pop 会从最近的一个 stash 中读取内容并恢复。 git stash list: 显示 Git 栈内的所有备份，可以利用这个列表来决定从那个地方恢复。 git stash clear: 清空 Git 栈。此时使用 gitg 等图形化工具会发现，原来 stash 的哪些节点都消失了。 # cherry-pick git cherry-pick 4c805e2 复制一个特定的提交到当前分支 ## git log %log 指令来确认历史记录是否已更新 git log --oneline --graph –author=“Alex Kras” ——只显示某个用户的提交任务 –name-only ——只显示变更文件的名称 –oneline——将提交信息压缩到一行显示 –graph ——显示所有提交的依赖树 –reverse ——按照逆序显示提交记录（最先提交的在最前面） –after ——显示某个日期之后发生的提交 –before ——显示发生某个日期之前的提交 git -log -p filename git log -L 1,1:some-file.txt git log --no-merges master.. || it show --no-merges master.. 或者 git log -p --no-merges master.. git log -n 1 --pretty=format:\u0026#34;%h\u0026#34; git reflog%用来记录你每一次执行的命令 "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/nc/",
	"title": "nc",
	"tags": [],
	"description": "",
	"content": "nc 功能说明：功能强大的网络工具 语　法：nc [-hlnruz][-g\u0026lt;网关\u0026hellip;\u0026gt;][-G\u0026lt;指向器数目\u0026gt;][-i\u0026lt;延迟秒数\u0026gt;][-o\u0026lt;输出文件\u0026gt;][-p\u0026lt;通信端口\u0026gt;][-s\u0026lt;来源位址\u0026gt;][-v\u0026hellip;][-w\u0026lt;超时秒数\u0026gt;][主机名称][通信端口\u0026hellip;] 参　数： -g\u0026lt;网关\u0026gt; 设置路由器跃程通信网关，最丢哦可设置8个。 -G\u0026lt;指向器数目\u0026gt; 设置来源路由指向器，其数值为4的倍数。 -h 在线帮助。 -i\u0026lt;延迟秒数\u0026gt; 设置时间间隔，以便传送信息及扫描通信端口。 -l 使用监听模式，管控传入的资料。 -n 直接使用IP地址，而不通过域名服务器。 -o\u0026lt;输出文件\u0026gt; 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存。 -p\u0026lt;通信端口\u0026gt; 设置本地主机使用的通信端口。 -r 乱数指定本地与远端主机的通信端口。 -s\u0026lt;来源位址\u0026gt; 设置本地主机送出数据包的IP地址。 -u 使用UDP传输协议。 -v 显示指令执行过程。 -w\u0026lt;超时秒数\u0026gt; 设置等待连线的时间。 -z 使用0输入/输出模式，只在扫描通信端口时使用。\n#端口扫描 nc -v -w 2 192.168.2.34 -z 21-24 #从192.168.2.33拷贝文件到192.168.2.34 #在192.168.2.34上： nc -l 1234 \u0026gt; test.txt #在192.168.2.33上： nc 192.168.2.34 \u0026lt; test.txt #简单聊天工具 #在192.168.2.34上： nc -l 1234 #在192.168.2.33上： nc 192.168.2.34 1234 "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.3.5-protobuf/",
	"title": "protobuf",
	"tags": [],
	"description": "",
	"content": "google protocol buffer 例子 syntax = \u0026#34;proto3\u0026#34;;// 注释 message SearchRequest { // 分配标识号 [1,15] 1byte [16,2047] 2byte 1-2^29=536,870,911 [19000－19999]不可用 (从FieldDescriptor::kFirstReservedNumber 到 FieldDescriptor::kLastReservedNumber)  // singular：一个格式良好的消息应该有0个或者1个这种字段（但是不能超过1个）。  // repeated：在一个格式良好的消息中，这种字段可以重复任意多次（包括0次）。重复的值的顺序会被保留。  // reserved:保留标识符 reserved 2, 15, 9 to 11; reserved \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;;  string query = 1; int32 page_number = 2; int32 result_per_page = 3;}标量数值类型    .proto Type Notes C++ Type Java Type Python Type[2] Go Type Ruby Type C# Type PHP Type     double double double float float64 Float double float    float float float float float32 Float float float    int32 使用变长编码，对于负值的效率很低，如果你的域有可能有负值，请使用sint64替代 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integer   uint32 使用变长编码 uint32 int int/long uint32 Fixnum 或者 Bignum（根据需要） uint integer   uint64 使用变长编码 uint64 long int/long uint64 Bignum ulong integer/string   sint32 使用变长编码，这些编码在负值时比int32高效的多 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integer   sint64 使用变长编码，有符号的整型值。编码时比通常的int64高效。 int64 long int/long int64 Bignum long integer/string   fixed32 总是4个字节，如果数值总是比总是比228大的话，这个类型会比uint32高效。 uint32 int int uint32 Fixnum 或者 Bignum（根据需要） uint integer   fixed64 总是8个字节，如果数值总是比总是比256大的话，这个类型会比uint64高效。 uint64 long int/long uint64 Bignum ulong integer/string   sfixed32 总是4个字节 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integer   sfixed64 总是8个字节 int64 long int/long int64 Bignum long integer/string   bool bool boolean bool bool TrueClass/FalseClass bool boolean    string 一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。 string String str/unicode string String (UTF-8) string string   bytes 可能包含任意顺序的字节数据。 string ByteString str []byte String (ASCII-8BIT) ByteString string    默认值 对于string，默认是一个空string 对于bytes，默认是一个空的bytes 对于bool，默认是false 对于数值类型，默认是0 对于枚举，默认是第一个定义的枚举值，必须为0; 对于消息类型（message），域没有被设置，确切的消息是根据语言确定的，详见generated code guide 枚举 // corpus的值可能是UNIVERSAL，WEB，IMAGES，LOCAL，NEWS，PRODUCTS或VIDEO中的一个 // 每个枚举类型必须将其第一个类型映射为0 // 枚举常量必须在32位整型值的范围内,因为enum值是使用可变编码方式的，对负数不够高效，因此不推荐在enum中使用负数 // 将不同的枚举常量指定位相同的值。如果这样做你需要将allow_alias设定位true enum EnumAllowingAlias { option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1;}message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; enum Corpus { UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; } Corpus corpus = 4;}使用其他消息类型 // 你可以将其他消息类型用作字段类型。 message SearchResponse { repeated Result results = 1;}message Result { string url = 1; string title = 2; repeated string snippets = 3;}导入定义 import \u0026#34;myproject/other_protos.proto\u0026#34;;vim fun3.proto import public \u0026#34;fun1.proto\u0026#34;; import \u0026#34;fun2.proto\u0026#34;;vim fun4.proto import \u0026#34;fun3.proto\u0026#34;; // 可以直接使用fun3.proto和 fun1.proto 嵌套类型 message SearchResponse { message Result { string url = 1; string title = 2; repeated string snippets = 3; } repeated Result results = 1;}message SomeOtherMessage { SearchResponse.Result result = 1;}message Outer { // Level 0  message MiddleAA { // Level 1  message Inner { // Level 2  int64 ival = 1; bool booly = 2; } } message MiddleBB { // Level 1  message Inner { // Level 2  int32 ival = 1; bool booly = 2; } }}更新一个消息类型 如果一个已有的消息格式已无法满足新的需求——如，要在消息中添加一个额外的字段——但是同时旧版本写的代码仍然可用。不用担心！更新消息而不破坏已有代码是非常简单的。在更新时只要记住以下的规则即可。 不要更改任何已有的字段的数值标识。 如果你增加新的字段，使用旧格式的字段仍然可以被你新产生的代码所解析。你应该记住这些元素的默认值这样你的新代码就可以以适当的方式和旧代码产生的数据交互。相似的，通过新代码产生的消息也可以被旧代码解析：只不过新的字段会被忽视掉。注意，未被识别的字段会在反序列化的过程中丢弃掉，所以如果消息再被传递给新的代码，新的字段依然是不可用的（这和proto2中的行为是不同的，在proto2中未定义的域依然会随着消息被序列化） 非required的字段可以移除——只要它们的标识号在新的消息类型中不再使用（更好的做法可能是重命名那个字段，例如在字段前添加“OBSOLETE_”前缀，那样的话，使用的.proto文件的用户将来就不会无意中重新使用了那些不该使用的标识号）。 int32, uint32, int64, uint64,和bool是全部兼容的，这意味着可以将这些类型中的一个转换为另外一个，而不会破坏向前、 向后的兼容性。如果解析出来的数字与对应的类型不相符，那么结果就像在C++中对它进行了强制类型转换一样（例如，如果把一个64位数字当作int32来 读取，那么它就会被截断为32位的数字）。 sint32和sint64是互相兼容的，但是它们与其他整数类型不兼容。 string和bytes是兼容的——只要bytes是有效的UTF-8编码。 嵌套消息与bytes是兼容的——只要bytes包含该消息的一个编码过的版本。 fixed32与sfixed32是兼容的，fixed64与sfixed64是兼容的。 枚举类型与int32，uint32，int64和uint64相兼容（注意如果值不相兼容则会被截断），然而在客户端反序列化之后他们可能会有不同的处理方式，例如，未识别的proto3枚举类型会被保留在消息中，但是他的表示方式会依照语言而定。int类型的字段总会保留他们的 Any // Any类型消息允许你在没有指定他们的.proto定义的情况下使用消息作为一个嵌套类型。一个Any类型包括一个可以被序列化bytes类型的任意消息，以及一个URL作为一个全局标识符和解析消息类型。为了使用Any类型，你需要导入import google/protobuf/any.proto。 import \u0026#34;google/protobuf/any.proto\u0026#34;;message ErrorStatus { string message = 1; repeated google.protobuf.Any details = 2;}Map map\u0026lt;key_type, value_type\u0026gt; map_field = N;map\u0026lt;string, Project\u0026gt; projects = 3;Map的字段可以是repeated。 序列化后的顺序和map迭代器的顺序是不确定的，所以你不要期望以固定顺序处理Map当为.proto文件产生生成文本格式的时候，map会按照key 的顺序排序，数值化的key会按照数值排序。 从序列化中解析或者融合时，如果有重复的key则后一个key不会被使用，当从文本格式中解析map时，如果存在重复的key。 Package 定义服务(Service) service SearchService { rpc Search (SearchRequest) returns (SearchResponse);}"
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.7-ubuntu/ubuntu-%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8/",
	"title": "ubuntu 开机启动",
	"tags": [],
	"description": "",
	"content": "ubuntu18.04 /lib/systemd/system sudo vim rc.local.service [Install] WantedBy=multi-user.target Alias=rc-local.service sudo ln -s rc.local.service /etc/systemd/system/ sudo vim /etc/rc.local #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will \u0026#34;exit 0\u0026#34; on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. echo \u0026#34;看到这行字，说明添加自启动脚本成功。\u0026#34; \u0026gt; /home/yj/test.log exit 0 sudo reboot "
},
{
	"uri": "https://linux.01cs.cc/1.%E5%9F%BA%E7%A1%80/1.7-ubuntu/ubuntu-%E6%94%B6%E8%97%8F%E5%A4%B9-%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F/",
	"title": "ubuntu 收藏夹 快捷方式",
	"tags": [],
	"description": "",
	"content": "收藏夹 #应用程序 cd /usr/share/applications vim app.desktop # [Desktop Entry] # Version=1.0 # Type=Application # Name=脑图 # Icon = /home/yj/tool/DesktopNaotu-linux-x64/resources/app/favicon.png # Exec = \u0026#34;/home/yj/tool/DesktopNaotu-linux-x64/DesktopNaotu\u0026#34; # Comment=脑图 # Categories=Development;IDE; # Terminal=false "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.3.6-wget/",
	"title": "wget",
	"tags": [],
	"description": "",
	"content": "网络管理命令 # 下载整个网页 无法下载通过js引用的文件 wget -r -p -np -k https://developer.zuoshouyisheng.com/ ##=curl==================================================== curl -X PUT -v -d \u0026#39;{}\u0026#39; \u0026#34;http://192.168.67.12:63001/config?a=b\u0026#34; # ss # netstat "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/1.%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/",
	"title": "1.文件管理",
	"tags": [],
	"description": "",
	"content": "1、文件管理 cat chattr chgrp chmod chown cksum cmp diff diffstat file find git gitview indent cut ln less locate lsattr mattrib mc mdel mdir mktemp more mmove mread mren mtools mtoolstest mv od paste patch rcp rm slocate split tee tmpwatch touch umask which cp whereis mcopy mshowfat rhmask scp awk read updatedb 常用命令    命令 说明     cat    chown    diffstat    gitview    less 查看文件的全部内容，可以分页显示，比more命令要强大   mc    more    mtools    paste    touch touch file.txt touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm) 文件不存在时创建一个空文件，存在时修改文件时间戳   whereis    scp    chattr    cksum    file    indent    locate 命令用于查找符合条件的文档   mdel    mmove    mtoolstest    patch    split    umask    mcopy    awk    chgrp    cmp    find    cut    lsattr    mdir mkdir dir1 dir 2 mkdir -p path/dir1/dir2   mread    mv    rcp    tee    which    mshowfat    read    chmod    diff    git    ln ln -s 源地址 目标地址 ln -s /usr/local/erlang/bin/erlc /usr/sbin/erlc   mattrib    mktemp    mren    od    rm rm -r file1 rm -rf dir1 rm -rf 关键字   tmpwatch    cp cp file1 file2 cp -a /path/dir1 . cp -r /path/dir1 /path/dir2   rhmask    updatedb     "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/2.%E6%96%87%E6%A1%A3%E7%BC%96%E8%BE%91/",
	"title": "2.文档编辑",
	"tags": [],
	"description": "",
	"content": "文档编辑 col colrm comm csplit ed egrep ex fgrep fmt fold grep ispell jed joe join look mtype pico rgrep sed sort spell tr expr uniq wc let    命令 说明     col    ed    fmt    jed    mtype    sort    uniq    colrm    egrep    fold    joe    pico    spell    wc    comm    ex    grep    join    rgrep    tr    let    csplit    fgrep    ispell    look    sed    expr    head file 打印文本文件开头几行   tail file 打印文本文件末尾几行   iconv iconv -l iconv -f find . -name *.java -exec sh -c \u0026ldquo;iconv -f GBK -t UTF8 {} \u0026gt; /tmp/iconv.tmp\u0026rdquo; ; -exec mv /tmp/iconv.tmp \u0026lsquo;{}\u0026rsquo; ;    "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/",
	"title": "3.Linux 命令",
	"tags": [],
	"description": "",
	"content": "Linux 命令大全 1、文件管理 cat chattr chgrp chmod chown cksum cmp diff diffstat file find git gitview indent cut ln less locate lsattr mattrib mc mdel mdir mktemp more mmove mread mren mtools mtoolstest mv od paste patch rcp rm slocate split tee tmpwatch touch umask which cp whereis mcopy mshowfat rhmask scp awk read updatedb 2、文档编辑 col colrm comm csplit ed egrep ex fgrep fmt fold grep ispell jed joe join look mtype pico rgrep sed sort spell tr expr uniq wc let 3、文件传输 lprm lpr lpq lpd bye ftp uuto uupick uucp uucico tftp ncftp ftpshut ftpwho ftpcount 4、磁盘管理 cd df dirs du edquota eject mcd mdeltree mdu mkdir mlabel mmd mrd mzip pwd quota mount mmount rmdir rmt stat tree umount ls quotacheck quotaoff lndir repquota quotaon 5、磁盘维护 badblocks cfdisk dd e2fsck ext2ed fsck fsck.minix fsconf fdformat hdparm mformat mkbootdisk mkdosfs mke2fs mkfs.ext2 mkfs.msdos mkinitrd mkisofs mkswap mpartition swapon symlinks sync mbadblocks mkfs.minix fsck.ext2 fdisk losetup mkfs sfdisk swapoff 6、网络通讯 apachectl arpwatch dip getty mingetty uux telnet uulog uustat ppp-off netconfig nc httpd ifconfig minicom mesg dnsconf wall netstat ping pppstats samba setserial talk traceroute tty newaliases uuname netconf write statserial efax pppsetup tcpdump ytalk cu smbd testparm smbclient shapecfg 7、系统管理 adduser chfn useradd date exit finger fwhios sleep suspend groupdel groupmod halt kill last lastb login logname logout ps nice procinfo top pstree reboot rlogin rsh sliplogin screen shutdown rwho sudo gitps swatch tload logrotate uname chsh userconf userdel usermod vlock who whoami whois newgrp renice su skill w id groupadd free 8、系统设置 reset clear alias dircolors aumix bind chroot clock crontab declare depmod dmesg enable eval export pwunconv grpconv rpm insmod kbdconfig lilo liloconfig lsmod minfo set modprobe ntsysv mouseconfig passwd pwconv rdate resize rmmod grpunconv modinfo time setup sndconfig setenv setconsole timeconfig ulimit unset chkconfig apmd hwclock mkkickstart fbset unalias SVGATextMode gpasswd 9、备份压缩 ar bunzip2 bzip2 bzip2recover gunzip unarj compress cpio dump uuencode gzexe gzip lha restore tar uudecode unzip zip zipinfo 10、设备管理 setleds loadkeys rdev dumpkeys MAKEDEV poweroff "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/3.%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/",
	"title": "3.系统管理",
	"tags": [],
	"description": "",
	"content": "系统管理 系统的整体性能取决于各种资源的平衡，类似木桶理论，某种资源的耗尽会严重阻碍系统的性能。\nLinux中需要监控的资源主要有 CPU、主存（内存）、硬盘空间、I/O时间、网络时间、应用程序等。\n影响系统性能的主要因素有： | 因素 | 说明 | | :\u0026mdash; | :\u0026mdash; | | 用户态CPU | CPU在用户态运行用户程序所花费的时间，包括库调用，但是不包括内核花费的时间。 | | 内核态CPU | CPU在内核态运行系统服务所花费的时间。所有的 I/O 操作都需要调用系统服务，程序员可以通过阻塞 I/O 传输来影响这部分 |的时间。 | I | O 时间和网络时间 响应 I/O 请求、处理网络连接所花费的时间。 | | 内存 | 切换上下文和交换数据（虚拟内存页导入和导出）花费的时间。 | | 应用程序 | 程序等待运行的时间——CPU正在运行其他程序，等待切换到当前程序。 |\n说明：一般认为用户态CPU和内核态CPU花费的时间小于70%时是良好状态。\n下面的命令可以用来监控系统性能并作出相应调整： | 命令 | 说明 | | :\u0026mdash; | :\u0026mdash; | | nice | 启动程序时指定进程优先级。 | | renice | 调整现有进程的优先级。 | | netstat | 显示各种网络相关信息，包括网络连接情况、路由表、接口状态(Interface Statistics)、masquerade 连接、多播成员(Multicast Memberships)等。实际上，netstat 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。 | | time | 检测一个命令运行时间以及资源（CPU、内存、I/O等）使用情况。 | | uptime | 查看系统负载情况。 | | ps | 查看系统中进程的资源使用情况（瞬时状态，不是动态监控）。 | | vmstat | 报告虚拟内存使用情况。 | | gprof | 精确分析程序的性能，能给出函数调用时间、调用次数、调用关系等。 | | top | 实时监控系统中各个进程资源的资源使用情况。 |\n常用命令组合：\nvmstat、sar、mpstat检测是否存在CPU瓶颈；\nvmstat、free检测是否存在内存瓶颈；\niostat检测是否存在磁盘I/O瓶颈；\nnetstat检测是否存在网络I/O瓶颈。\nps -a 显示所有用户的所有进程。 -x 显示无终端的进程。 -u 显示更多信息，类似于 -f 选项。 -e 显示所有进程。 ps -ef|grep mysql 查看带有mysql的进程 kill kill -9 ps kill -9 [PID] -9 表示强迫进程立即停止 系统信息 free -m 将结果以M为单位输出 查看系统中使用和剩馀的内存情况。 top 运行着的进程和系统资源，包括 CPU、内存以及交换分区使用情况和运行着的任务的总的数量 uname 命令的 -a 参数用来查看系统的所有信息，包括 机器名，内核名称 \u0026amp; 版本 和一些其它的细节。 -m 显示机器的处理器架构 -r 显示正在使用的内核版本 lsb_release -a 参数查看当前运行的linux的版本信息 ifconfig 显示当前系统的网络接口信息 arch 显示机器的处理器架构 dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI) hdparm -i /dev/hda 罗列一个磁盘的架构特性 hdparm -tT /dev/sda 在磁盘上执行测试性读取操作 lspci -tv 罗列 PCI 设备 lsusb -tv 显示 USB 设备 adduser newuser 添加新用户 useradd 添加用户 usermod 修改用户信息 userdel 删除用户 groupadd 添加用户组 groupmod 修改用户组信息 groupdel 删除用户组 passwd newuser 为新用户 newuser 创建一个密码 passwd 修改密码 man man intro －查看 \u0026#34;用户命令介绍\u0026#34;，是一份很简介的linux命令的介绍 man into 它通常比man 还深入。输入\u0026#34;info info\u0026#34; 命令可得到info页的介绍 man -k foo 会搜索关于foo的man文件。试试看\u0026#34;man -k nautilus\u0026#34; 是怎样的 man -f foo 仅仅搜所系统man文件的标题 whatis users、who、w 查看当前在线用户 whoami 查看当前用户信息 logout 退出登录 注销 shutdown 安全关闭系统 -r –r 10 \u0026#34;message\u0026#34; 将系统服务停掉然后重启 -h –h +5 –h 18:00 将系统服务停掉,然后关机 -c 取消已经在运行的 shutdown 命令内容 reboot 重新启动系统 poweroff 通过断电来关闭系统 halt 直接关闭系统 init 0 使用预先定义的脚本关闭系统，关闭前可以清理和更新有关信息 init 6 重新启动系统 date 显示系统日期 date 设置系统时钟时间 设置时间为下午14点36分。 # date -s 14:36:00 设置时间为1999年11月28号。 # date -s 991128 设置时间伟2008年8月8号12:00 # date -s \u0026#34;2008-08-08 12:00:00\u0026#34; 修改完后,记得执行clock -w，把系统时间写入CMOS(硬件) hwclock --show 查看计算机硬件时间 tzselect 设置时区 hwcolock -w保存 设置硬件时钟 ntpdate us.pool.ntp.org 同步时间 clock -w 将时间修改保存到 BIOS hostname 修改主机名称 列 描述 UID 进程所属用户的ID，即哪个用户创建了该进程。 PID 进程ID。 PPID 父进程ID，创建该进程的进程称为父进程。 C CPU使用率。 STIME 进程被创建的时间。 TTY 与进程有关的终端类型。 TIME 进程所使用的CPU时间。 CMD 创建该进程的命令。 常用命令    命令 说明     adduser    exit    suspend    kill    logname    procinfo    rlogin    shutdown    swatch    chsh    vlock    newgrp    w    chfn    finger    groupdel    last    logout    top    rsh    rwho    tload    userconf    who    renice    id    useradd    fwhios    groupmod    lastb    ps    pstree    sliplogin    sudo    logrotate    userdel    whoami    su    free    date    sleep    halt    login    nice    reboot    screen    gitps    uname    usermod    whois    skill     "
},
{
	"uri": "https://linux.01cs.cc/4.linux%E8%BD%AF%E4%BB%B6/4.6-docker/",
	"title": "4.6 Docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/4.%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/",
	"title": "4.磁盘管理",
	"tags": [],
	"description": "",
	"content": "磁盘管理    命令 说明     cd    edquota    mdu    mrd    mount    stat    quotacheck    quotaon    df    eject    mkdir    mzip    mmount    tree    quotaoff    dirs    mcd    mlabel    pwd    rmdir    umount    lndir    du    mdeltree    mmd    quota    rmt    ls    repquota     磁盘维护    命令 说明     badblocks    ext2ed    fdformat    mkdosfs    mkinitrd    swapon    mkfs .minix   mkfs    cfdisk    fsck    hdparm    mke2fs    mkisofs    symlinks    fsck .ext2   sfdisk    dd    fsck .minix   mformat    mkfs .ext2   mkswap    sync    fdisk    swapoff    e2fsck    fsconf    mkbootdisk    mkfs .msdos   mpartition    mbadblocks    losetup     "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/5.%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93/",
	"title": "5.文件传输",
	"tags": [],
	"description": "",
	"content": "文件传输    命令 说明     lprm    lpr    lpq    lpd    bye    ftp    uuto    uupick    uucp    uucico    tftp    ncftp    ftpshut    ftpwho    ftpcount     "
},
{
	"uri": "https://linux.01cs.cc/3.linux-%E5%91%BD%E4%BB%A4/6.%E7%BD%91%E7%BB%9C%E9%80%9A%E8%AE%AF/",
	"title": "6.网络通讯",
	"tags": [],
	"description": "",
	"content": "磁盘维护    命令 说明     apachectl    mingetty    uustat    httpd    dnsconf    pppstats    traceroute    netconf    pppsetup    smbd    arpwatch    uux    ppp-off    ifconfig    wall    samba    tty    write    tcpdump    testparm    dip    telnet    netconfig    minicom    netstat    setserial    newaliases    statserial    ytalk    smbclient    getty    uulog    nc    mesg    ping    talk    uuname    efax    cu    shapecfg     "
},
{
	"uri": "https://linux.01cs.cc/",
	"title": "Linux系统",
	"tags": [],
	"description": "",
	"content": "好记性不如烂笔头 linux笔记 "
},
{
	"uri": "https://linux.01cs.cc/2.shell-%E6%95%99%E7%A8%8B/2.2.-shell%E8%84%9A%E6%9C%AC/shtools/readme/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "tmux-session : tmux-session save and tmux-session restore\n"
},
{
	"uri": "https://linux.01cs.cc/etc_/cpp/project_tpl/readme/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 依赖 运行 联系 wuyanyi09@gmail.com\n"
},
{
	"uri": "https://linux.01cs.cc/etc_/readme/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "personal etc "
},
{
	"uri": "https://linux.01cs.cc/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linux.01cs.cc/etc_/",
	"title": "Etc_s",
	"tags": [],
	"description": "",
	"content": ""
}]